{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "housing-prices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv5BX-QdqVcN",
        "colab_type": "text"
      },
      "source": [
        "# 1. Prepare the environment for Python 3 with Tensorflow and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgMqJJohqM5J",
        "colab_type": "code",
        "outputId": "0d3acfdd-148f-41c3-9719-9999a3ca9a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "#Print Python's version:\n",
        "!python --version\n",
        "\n",
        "#Import Tensorflow and Keras:\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgGENPwZq90Z",
        "colab_type": "text"
      },
      "source": [
        "# 2. Download and prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o68szfJcrFCa",
        "colab_type": "code",
        "outputId": "fe156ef3-fcb9-42c1-d929-1c9df9ef4cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "#Get access to Google Drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlUvY2nrzBr",
        "colab_type": "code",
        "outputId": "8aaa693a-b598-4033-b118-d55b6bce4e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "#Obtain the attributes and the labels:\n",
        "import pandas as pd\n",
        "attributes = pd.read_csv(\"/content/drive/My Drive/OceanProximityPreparedCleanAttributes.csv\")\n",
        "labels = pd.read_csv(\"/content/drive/My Drive/OceanProximityOneHotEncodedClasses.csv\")\n",
        "print(attributes.columns)\n",
        "print(labels.columns)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
            "       'total_bedrooms', 'population', 'households', 'median_income',\n",
            "       'median_house_value'],\n",
            "      dtype='object')\n",
            "Index(['<1H OCEAN', 'INLAND', 'NEAR BAY', 'NEAR OCEAN'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8z39dh6tb7K",
        "colab_type": "code",
        "outputId": "1a2a0a7f-91b9-47ea-8ebe-1d0d5a511ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Data split:\n",
        "print(labels.head(10))\n",
        "#The data is already ramdomnized, so there is no doing for that.\n",
        "\n",
        "#Split the data in the following way:\n",
        "#80% -> training dataset\n",
        "#10% -> validation dataset\n",
        "#10% -> testing dataset\n",
        "l = labels.shape[0]\n",
        "print(l)\n",
        "training_instances = int(l*0.8)\n",
        "validation_instances = int(training_instances + l*0.1)\n",
        "\n",
        "tr_attributes = attributes[0:training_instances]\n",
        "tr_labels = labels[0:training_instances]\n",
        "val_attributes = attributes[training_instances:validation_instances]\n",
        "val_labels = labels[training_instances:validation_instances]\n",
        "test_attributes = attributes[validation_instances:]\n",
        "test_labels = labels[validation_instances:]\n",
        "print(\"Data split done!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   <1H OCEAN  INLAND  NEAR BAY  NEAR OCEAN\n",
            "0        0.0     0.0       0.0         1.0\n",
            "1        0.0     0.0       1.0         0.0\n",
            "2        0.0     1.0       0.0         0.0\n",
            "3        1.0     0.0       0.0         0.0\n",
            "4        0.0     0.0       0.0         1.0\n",
            "5        0.0     1.0       0.0         0.0\n",
            "6        1.0     0.0       0.0         0.0\n",
            "7        1.0     0.0       0.0         0.0\n",
            "8        0.0     1.0       0.0         0.0\n",
            "9        1.0     0.0       0.0         0.0\n",
            "20428\n",
            "Data split done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPIvCBJ3HrHz",
        "colab_type": "text"
      },
      "source": [
        "# 3. The Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tUsre29IdqL",
        "colab_type": "code",
        "outputId": "740d8f12-6613-486e-b356-49d23c220612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "input_shape = tr_attributes.shape[1]\n",
        "num_classes = tr_labels.shape[1]\n",
        "\n",
        "mlp = Sequential() \n",
        "mlp.add(Dense(1000, input_shape = (input_shape,)))\n",
        "mlp.add(Activation('relu'))\n",
        "mlp.add(Dropout(0.3))\n",
        "mlp.add(Dense(750))\n",
        "mlp.add(Activation('relu'))\n",
        "mlp.add(Dropout(0.3))\n",
        "mlp.add(Dense(250))\n",
        "mlp.add(Activation('relu'))\n",
        "mlp.add(Dropout(0.3))\n",
        "mlp.add(Dense(num_classes))\n",
        "mlp.add(Activation('softmax'))\n",
        "\n",
        "opt = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "mlp.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 1000)              10000     \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 750)               750750    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 750)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 250)               187750    \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 1004      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 4)                 0         \n",
            "=================================================================\n",
            "Total params: 949,504\n",
            "Trainable params: 949,504\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jjqTjP5KFY1",
        "colab_type": "code",
        "outputId": "448d44c7-5245-4630-eebc-9115b36ab6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "data = mlp.fit(tr_attributes,\n",
        "               tr_labels,\n",
        "               batch_size=2048, \n",
        "               epochs=4096,\n",
        "               verbose=1,\n",
        "               validation_data=(val_attributes, val_labels))\n",
        "\n",
        "start = time()\n",
        "loss, acc = mlp.evaluate(test_attributes, test_labels, verbose=0)\n",
        "end = time()\n",
        "print('ffNN took ' + str(end - start) + ' seconds')\n",
        "print('Test loss: ' + str(loss) + ' - Accuracy: ' + str(acc))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0948 - acc: 0.9594 - val_loss: 0.1010 - val_acc: 0.9618\n",
            "Epoch 1599/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0947 - acc: 0.9596 - val_loss: 0.1065 - val_acc: 0.9574\n",
            "Epoch 1600/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0898 - acc: 0.9632 - val_loss: 0.0995 - val_acc: 0.9643\n",
            "Epoch 1601/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0917 - acc: 0.9614 - val_loss: 0.1143 - val_acc: 0.9589\n",
            "Epoch 1602/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0935 - acc: 0.9608 - val_loss: 0.1005 - val_acc: 0.9623\n",
            "Epoch 1603/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0908 - acc: 0.9623 - val_loss: 0.0994 - val_acc: 0.9643\n",
            "Epoch 1604/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0971 - acc: 0.9589 - val_loss: 0.1038 - val_acc: 0.9608\n",
            "Epoch 1605/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0916 - acc: 0.9614 - val_loss: 0.0973 - val_acc: 0.9638\n",
            "Epoch 1606/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0983 - acc: 0.9585 - val_loss: 0.0972 - val_acc: 0.9628\n",
            "Epoch 1607/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0944 - acc: 0.9611 - val_loss: 0.1017 - val_acc: 0.9633\n",
            "Epoch 1608/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0939 - acc: 0.9602 - val_loss: 0.0982 - val_acc: 0.9633\n",
            "Epoch 1609/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0925 - acc: 0.9604 - val_loss: 0.1006 - val_acc: 0.9608\n",
            "Epoch 1610/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0925 - acc: 0.9594 - val_loss: 0.1013 - val_acc: 0.9613\n",
            "Epoch 1611/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0918 - acc: 0.9611 - val_loss: 0.1004 - val_acc: 0.9623\n",
            "Epoch 1612/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.1001 - acc: 0.9582 - val_loss: 0.1004 - val_acc: 0.9633\n",
            "Epoch 1613/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0920 - acc: 0.9616 - val_loss: 0.1005 - val_acc: 0.9638\n",
            "Epoch 1614/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0941 - acc: 0.9603 - val_loss: 0.1020 - val_acc: 0.9628\n",
            "Epoch 1615/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0923 - acc: 0.9616 - val_loss: 0.1099 - val_acc: 0.9598\n",
            "Epoch 1616/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0947 - acc: 0.9591 - val_loss: 0.0997 - val_acc: 0.9623\n",
            "Epoch 1617/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0924 - acc: 0.9609 - val_loss: 0.1127 - val_acc: 0.9584\n",
            "Epoch 1618/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0932 - acc: 0.9610 - val_loss: 0.0998 - val_acc: 0.9638\n",
            "Epoch 1619/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0927 - acc: 0.9616 - val_loss: 0.0985 - val_acc: 0.9662\n",
            "Epoch 1620/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0953 - acc: 0.9600 - val_loss: 0.0980 - val_acc: 0.9647\n",
            "Epoch 1621/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0929 - acc: 0.9607 - val_loss: 0.1015 - val_acc: 0.9589\n",
            "Epoch 1622/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0914 - acc: 0.9606 - val_loss: 0.1078 - val_acc: 0.9603\n",
            "Epoch 1623/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0952 - acc: 0.9601 - val_loss: 0.0986 - val_acc: 0.9623\n",
            "Epoch 1624/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0905 - acc: 0.9617 - val_loss: 0.0974 - val_acc: 0.9662\n",
            "Epoch 1625/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0937 - acc: 0.9610 - val_loss: 0.0990 - val_acc: 0.9628\n",
            "Epoch 1626/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0933 - acc: 0.9620 - val_loss: 0.1006 - val_acc: 0.9608\n",
            "Epoch 1627/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0891 - acc: 0.9626 - val_loss: 0.1113 - val_acc: 0.9579\n",
            "Epoch 1628/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0940 - acc: 0.9602 - val_loss: 0.1057 - val_acc: 0.9589\n",
            "Epoch 1629/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0933 - acc: 0.9606 - val_loss: 0.0972 - val_acc: 0.9628\n",
            "Epoch 1630/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0906 - acc: 0.9606 - val_loss: 0.1027 - val_acc: 0.9608\n",
            "Epoch 1631/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0915 - acc: 0.9622 - val_loss: 0.1056 - val_acc: 0.9608\n",
            "Epoch 1632/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0939 - acc: 0.9590 - val_loss: 0.0974 - val_acc: 0.9633\n",
            "Epoch 1633/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0924 - acc: 0.9611 - val_loss: 0.1060 - val_acc: 0.9608\n",
            "Epoch 1634/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0902 - acc: 0.9605 - val_loss: 0.1053 - val_acc: 0.9589\n",
            "Epoch 1635/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0911 - acc: 0.9616 - val_loss: 0.1038 - val_acc: 0.9613\n",
            "Epoch 1636/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0937 - acc: 0.9597 - val_loss: 0.1061 - val_acc: 0.9574\n",
            "Epoch 1637/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0943 - acc: 0.9588 - val_loss: 0.1083 - val_acc: 0.9589\n",
            "Epoch 1638/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0893 - acc: 0.9627 - val_loss: 0.0971 - val_acc: 0.9647\n",
            "Epoch 1639/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0945 - acc: 0.9597 - val_loss: 0.0996 - val_acc: 0.9628\n",
            "Epoch 1640/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0958 - acc: 0.9599 - val_loss: 0.0981 - val_acc: 0.9633\n",
            "Epoch 1641/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0909 - acc: 0.9599 - val_loss: 0.0953 - val_acc: 0.9652\n",
            "Epoch 1642/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0953 - acc: 0.9586 - val_loss: 0.0962 - val_acc: 0.9657\n",
            "Epoch 1643/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0892 - acc: 0.9622 - val_loss: 0.1022 - val_acc: 0.9638\n",
            "Epoch 1644/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0899 - acc: 0.9620 - val_loss: 0.0986 - val_acc: 0.9628\n",
            "Epoch 1645/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0927 - acc: 0.9615 - val_loss: 0.1098 - val_acc: 0.9554\n",
            "Epoch 1646/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0927 - acc: 0.9608 - val_loss: 0.0971 - val_acc: 0.9657\n",
            "Epoch 1647/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0924 - acc: 0.9607 - val_loss: 0.1037 - val_acc: 0.9603\n",
            "Epoch 1648/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0882 - acc: 0.9624 - val_loss: 0.1032 - val_acc: 0.9618\n",
            "Epoch 1649/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0874 - acc: 0.9641 - val_loss: 0.1103 - val_acc: 0.9574\n",
            "Epoch 1650/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0958 - acc: 0.9591 - val_loss: 0.1061 - val_acc: 0.9603\n",
            "Epoch 1651/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0957 - acc: 0.9593 - val_loss: 0.1031 - val_acc: 0.9584\n",
            "Epoch 1652/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0914 - acc: 0.9613 - val_loss: 0.0940 - val_acc: 0.9643\n",
            "Epoch 1653/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0920 - acc: 0.9623 - val_loss: 0.0992 - val_acc: 0.9643\n",
            "Epoch 1654/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0936 - acc: 0.9611 - val_loss: 0.1041 - val_acc: 0.9584\n",
            "Epoch 1655/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0933 - acc: 0.9606 - val_loss: 0.0980 - val_acc: 0.9623\n",
            "Epoch 1656/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0904 - acc: 0.9635 - val_loss: 0.1135 - val_acc: 0.9569\n",
            "Epoch 1657/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0917 - acc: 0.9611 - val_loss: 0.0974 - val_acc: 0.9652\n",
            "Epoch 1658/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0901 - acc: 0.9611 - val_loss: 0.1016 - val_acc: 0.9594\n",
            "Epoch 1659/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0951 - acc: 0.9593 - val_loss: 0.0938 - val_acc: 0.9677\n",
            "Epoch 1660/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0891 - acc: 0.9618 - val_loss: 0.1048 - val_acc: 0.9608\n",
            "Epoch 1661/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0927 - acc: 0.9599 - val_loss: 0.0987 - val_acc: 0.9638\n",
            "Epoch 1662/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0923 - acc: 0.9611 - val_loss: 0.1000 - val_acc: 0.9638\n",
            "Epoch 1663/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0954 - acc: 0.9598 - val_loss: 0.1010 - val_acc: 0.9628\n",
            "Epoch 1664/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0910 - acc: 0.9604 - val_loss: 0.0947 - val_acc: 0.9638\n",
            "Epoch 1665/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0914 - acc: 0.9610 - val_loss: 0.1034 - val_acc: 0.9613\n",
            "Epoch 1666/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0911 - acc: 0.9611 - val_loss: 0.1029 - val_acc: 0.9584\n",
            "Epoch 1667/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0919 - acc: 0.9617 - val_loss: 0.1035 - val_acc: 0.9598\n",
            "Epoch 1668/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0937 - acc: 0.9613 - val_loss: 0.0966 - val_acc: 0.9652\n",
            "Epoch 1669/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0919 - acc: 0.9603 - val_loss: 0.1009 - val_acc: 0.9643\n",
            "Epoch 1670/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0942 - acc: 0.9617 - val_loss: 0.0989 - val_acc: 0.9628\n",
            "Epoch 1671/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0943 - acc: 0.9602 - val_loss: 0.1026 - val_acc: 0.9613\n",
            "Epoch 1672/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0943 - acc: 0.9613 - val_loss: 0.1103 - val_acc: 0.9564\n",
            "Epoch 1673/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0890 - acc: 0.9629 - val_loss: 0.0971 - val_acc: 0.9638\n",
            "Epoch 1674/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0928 - acc: 0.9611 - val_loss: 0.0942 - val_acc: 0.9672\n",
            "Epoch 1675/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0911 - acc: 0.9616 - val_loss: 0.0996 - val_acc: 0.9643\n",
            "Epoch 1676/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0923 - acc: 0.9609 - val_loss: 0.1010 - val_acc: 0.9623\n",
            "Epoch 1677/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0919 - acc: 0.9608 - val_loss: 0.0984 - val_acc: 0.9638\n",
            "Epoch 1678/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0918 - acc: 0.9618 - val_loss: 0.0998 - val_acc: 0.9667\n",
            "Epoch 1679/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0916 - acc: 0.9610 - val_loss: 0.1115 - val_acc: 0.9564\n",
            "Epoch 1680/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0916 - acc: 0.9607 - val_loss: 0.0937 - val_acc: 0.9672\n",
            "Epoch 1681/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0958 - acc: 0.9596 - val_loss: 0.0989 - val_acc: 0.9623\n",
            "Epoch 1682/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0922 - acc: 0.9600 - val_loss: 0.1099 - val_acc: 0.9584\n",
            "Epoch 1683/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0906 - acc: 0.9630 - val_loss: 0.1091 - val_acc: 0.9589\n",
            "Epoch 1684/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0907 - acc: 0.9611 - val_loss: 0.1079 - val_acc: 0.9598\n",
            "Epoch 1685/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0877 - acc: 0.9630 - val_loss: 0.0962 - val_acc: 0.9667\n",
            "Epoch 1686/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0915 - acc: 0.9613 - val_loss: 0.0997 - val_acc: 0.9643\n",
            "Epoch 1687/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0935 - acc: 0.9622 - val_loss: 0.1003 - val_acc: 0.9638\n",
            "Epoch 1688/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0936 - acc: 0.9608 - val_loss: 0.1037 - val_acc: 0.9623\n",
            "Epoch 1689/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0921 - acc: 0.9610 - val_loss: 0.1025 - val_acc: 0.9638\n",
            "Epoch 1690/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0918 - acc: 0.9610 - val_loss: 0.0988 - val_acc: 0.9638\n",
            "Epoch 1691/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0910 - acc: 0.9618 - val_loss: 0.0969 - val_acc: 0.9662\n",
            "Epoch 1692/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0906 - acc: 0.9606 - val_loss: 0.0957 - val_acc: 0.9657\n",
            "Epoch 1693/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0919 - acc: 0.9603 - val_loss: 0.0988 - val_acc: 0.9618\n",
            "Epoch 1694/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0930 - acc: 0.9596 - val_loss: 0.1044 - val_acc: 0.9608\n",
            "Epoch 1695/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0945 - acc: 0.9617 - val_loss: 0.1081 - val_acc: 0.9574\n",
            "Epoch 1696/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0927 - acc: 0.9622 - val_loss: 0.0989 - val_acc: 0.9643\n",
            "Epoch 1697/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0913 - acc: 0.9608 - val_loss: 0.1128 - val_acc: 0.9598\n",
            "Epoch 1698/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0922 - acc: 0.9604 - val_loss: 0.0973 - val_acc: 0.9657\n",
            "Epoch 1699/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0900 - acc: 0.9627 - val_loss: 0.1022 - val_acc: 0.9623\n",
            "Epoch 1700/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0913 - acc: 0.9612 - val_loss: 0.1081 - val_acc: 0.9603\n",
            "Epoch 1701/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0878 - acc: 0.9621 - val_loss: 0.1001 - val_acc: 0.9643\n",
            "Epoch 1702/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0903 - acc: 0.9621 - val_loss: 0.0998 - val_acc: 0.9652\n",
            "Epoch 1703/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0942 - acc: 0.9599 - val_loss: 0.1003 - val_acc: 0.9667\n",
            "Epoch 1704/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0875 - acc: 0.9635 - val_loss: 0.1074 - val_acc: 0.9603\n",
            "Epoch 1705/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0901 - acc: 0.9624 - val_loss: 0.1080 - val_acc: 0.9603\n",
            "Epoch 1706/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0912 - acc: 0.9609 - val_loss: 0.1003 - val_acc: 0.9623\n",
            "Epoch 1707/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0925 - acc: 0.9623 - val_loss: 0.1079 - val_acc: 0.9589\n",
            "Epoch 1708/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0879 - acc: 0.9623 - val_loss: 0.0986 - val_acc: 0.9623\n",
            "Epoch 1709/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0921 - acc: 0.9605 - val_loss: 0.1057 - val_acc: 0.9608\n",
            "Epoch 1710/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0877 - acc: 0.9631 - val_loss: 0.0950 - val_acc: 0.9662\n",
            "Epoch 1711/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0888 - acc: 0.9627 - val_loss: 0.0968 - val_acc: 0.9672\n",
            "Epoch 1712/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0888 - acc: 0.9614 - val_loss: 0.1017 - val_acc: 0.9613\n",
            "Epoch 1713/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0943 - acc: 0.9600 - val_loss: 0.0986 - val_acc: 0.9628\n",
            "Epoch 1714/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0859 - acc: 0.9629 - val_loss: 0.1055 - val_acc: 0.9569\n",
            "Epoch 1715/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0877 - acc: 0.9620 - val_loss: 0.1010 - val_acc: 0.9628\n",
            "Epoch 1716/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0912 - acc: 0.9621 - val_loss: 0.1008 - val_acc: 0.9643\n",
            "Epoch 1717/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9626 - val_loss: 0.0949 - val_acc: 0.9662\n",
            "Epoch 1718/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0905 - acc: 0.9631 - val_loss: 0.1028 - val_acc: 0.9608\n",
            "Epoch 1719/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0928 - acc: 0.9614 - val_loss: 0.0947 - val_acc: 0.9643\n",
            "Epoch 1720/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0879 - acc: 0.9632 - val_loss: 0.0974 - val_acc: 0.9647\n",
            "Epoch 1721/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0888 - acc: 0.9613 - val_loss: 0.1047 - val_acc: 0.9608\n",
            "Epoch 1722/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0914 - acc: 0.9602 - val_loss: 0.0955 - val_acc: 0.9647\n",
            "Epoch 1723/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0909 - acc: 0.9619 - val_loss: 0.0995 - val_acc: 0.9623\n",
            "Epoch 1724/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0909 - acc: 0.9607 - val_loss: 0.0997 - val_acc: 0.9613\n",
            "Epoch 1725/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0904 - acc: 0.9611 - val_loss: 0.0976 - val_acc: 0.9623\n",
            "Epoch 1726/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0894 - acc: 0.9628 - val_loss: 0.1159 - val_acc: 0.9554\n",
            "Epoch 1727/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9635 - val_loss: 0.1116 - val_acc: 0.9579\n",
            "Epoch 1728/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0914 - acc: 0.9613 - val_loss: 0.0993 - val_acc: 0.9633\n",
            "Epoch 1729/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0920 - acc: 0.9615 - val_loss: 0.1123 - val_acc: 0.9559\n",
            "Epoch 1730/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0900 - acc: 0.9622 - val_loss: 0.0990 - val_acc: 0.9603\n",
            "Epoch 1731/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0869 - acc: 0.9628 - val_loss: 0.0950 - val_acc: 0.9638\n",
            "Epoch 1732/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0899 - acc: 0.9624 - val_loss: 0.0961 - val_acc: 0.9652\n",
            "Epoch 1733/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0902 - acc: 0.9613 - val_loss: 0.1014 - val_acc: 0.9598\n",
            "Epoch 1734/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0885 - acc: 0.9619 - val_loss: 0.1033 - val_acc: 0.9608\n",
            "Epoch 1735/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0906 - acc: 0.9624 - val_loss: 0.0972 - val_acc: 0.9667\n",
            "Epoch 1736/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0881 - acc: 0.9621 - val_loss: 0.0986 - val_acc: 0.9618\n",
            "Epoch 1737/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0910 - acc: 0.9616 - val_loss: 0.0972 - val_acc: 0.9623\n",
            "Epoch 1738/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0868 - acc: 0.9641 - val_loss: 0.1084 - val_acc: 0.9559\n",
            "Epoch 1739/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0905 - acc: 0.9621 - val_loss: 0.0954 - val_acc: 0.9647\n",
            "Epoch 1740/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0885 - acc: 0.9635 - val_loss: 0.0959 - val_acc: 0.9647\n",
            "Epoch 1741/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0853 - acc: 0.9646 - val_loss: 0.1003 - val_acc: 0.9652\n",
            "Epoch 1742/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0886 - acc: 0.9637 - val_loss: 0.0998 - val_acc: 0.9633\n",
            "Epoch 1743/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0925 - acc: 0.9603 - val_loss: 0.0960 - val_acc: 0.9652\n",
            "Epoch 1744/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0902 - acc: 0.9618 - val_loss: 0.0967 - val_acc: 0.9633\n",
            "Epoch 1745/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0913 - acc: 0.9600 - val_loss: 0.0972 - val_acc: 0.9647\n",
            "Epoch 1746/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0885 - acc: 0.9626 - val_loss: 0.0989 - val_acc: 0.9628\n",
            "Epoch 1747/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0901 - acc: 0.9614 - val_loss: 0.0979 - val_acc: 0.9647\n",
            "Epoch 1748/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0918 - acc: 0.9622 - val_loss: 0.1012 - val_acc: 0.9647\n",
            "Epoch 1749/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0880 - acc: 0.9619 - val_loss: 0.1144 - val_acc: 0.9554\n",
            "Epoch 1750/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9618 - val_loss: 0.1000 - val_acc: 0.9643\n",
            "Epoch 1751/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0898 - acc: 0.9624 - val_loss: 0.1035 - val_acc: 0.9598\n",
            "Epoch 1752/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0902 - acc: 0.9624 - val_loss: 0.0999 - val_acc: 0.9608\n",
            "Epoch 1753/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0873 - acc: 0.9637 - val_loss: 0.1001 - val_acc: 0.9584\n",
            "Epoch 1754/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0871 - acc: 0.9627 - val_loss: 0.1042 - val_acc: 0.9643\n",
            "Epoch 1755/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0850 - acc: 0.9642 - val_loss: 0.0971 - val_acc: 0.9618\n",
            "Epoch 1756/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0895 - acc: 0.9620 - val_loss: 0.0944 - val_acc: 0.9638\n",
            "Epoch 1757/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0882 - acc: 0.9650 - val_loss: 0.1000 - val_acc: 0.9638\n",
            "Epoch 1758/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0850 - acc: 0.9630 - val_loss: 0.0987 - val_acc: 0.9643\n",
            "Epoch 1759/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0884 - acc: 0.9618 - val_loss: 0.0917 - val_acc: 0.9672\n",
            "Epoch 1760/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0885 - acc: 0.9621 - val_loss: 0.1007 - val_acc: 0.9643\n",
            "Epoch 1761/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0888 - acc: 0.9622 - val_loss: 0.0988 - val_acc: 0.9608\n",
            "Epoch 1762/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0881 - acc: 0.9618 - val_loss: 0.0958 - val_acc: 0.9662\n",
            "Epoch 1763/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0908 - acc: 0.9625 - val_loss: 0.1001 - val_acc: 0.9647\n",
            "Epoch 1764/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0904 - acc: 0.9623 - val_loss: 0.0930 - val_acc: 0.9667\n",
            "Epoch 1765/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0888 - acc: 0.9615 - val_loss: 0.0965 - val_acc: 0.9643\n",
            "Epoch 1766/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0907 - acc: 0.9629 - val_loss: 0.1002 - val_acc: 0.9608\n",
            "Epoch 1767/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0879 - acc: 0.9625 - val_loss: 0.0998 - val_acc: 0.9628\n",
            "Epoch 1768/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0897 - acc: 0.9621 - val_loss: 0.1002 - val_acc: 0.9603\n",
            "Epoch 1769/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0896 - acc: 0.9617 - val_loss: 0.0973 - val_acc: 0.9643\n",
            "Epoch 1770/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0875 - acc: 0.9621 - val_loss: 0.1025 - val_acc: 0.9598\n",
            "Epoch 1771/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0848 - acc: 0.9642 - val_loss: 0.0971 - val_acc: 0.9652\n",
            "Epoch 1772/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0862 - acc: 0.9632 - val_loss: 0.1052 - val_acc: 0.9623\n",
            "Epoch 1773/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0918 - acc: 0.9618 - val_loss: 0.1000 - val_acc: 0.9623\n",
            "Epoch 1774/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0899 - acc: 0.9618 - val_loss: 0.0980 - val_acc: 0.9633\n",
            "Epoch 1775/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0879 - acc: 0.9621 - val_loss: 0.1007 - val_acc: 0.9623\n",
            "Epoch 1776/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0884 - acc: 0.9629 - val_loss: 0.0981 - val_acc: 0.9623\n",
            "Epoch 1777/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0885 - acc: 0.9626 - val_loss: 0.1006 - val_acc: 0.9628\n",
            "Epoch 1778/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0897 - acc: 0.9630 - val_loss: 0.1015 - val_acc: 0.9598\n",
            "Epoch 1779/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0907 - acc: 0.9624 - val_loss: 0.1011 - val_acc: 0.9628\n",
            "Epoch 1780/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0905 - acc: 0.9615 - val_loss: 0.1233 - val_acc: 0.9545\n",
            "Epoch 1781/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0899 - acc: 0.9619 - val_loss: 0.0934 - val_acc: 0.9643\n",
            "Epoch 1782/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0864 - acc: 0.9623 - val_loss: 0.0976 - val_acc: 0.9623\n",
            "Epoch 1783/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0874 - acc: 0.9624 - val_loss: 0.1027 - val_acc: 0.9652\n",
            "Epoch 1784/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0896 - acc: 0.9614 - val_loss: 0.0949 - val_acc: 0.9643\n",
            "Epoch 1785/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0856 - acc: 0.9636 - val_loss: 0.1103 - val_acc: 0.9545\n",
            "Epoch 1786/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0860 - acc: 0.9660 - val_loss: 0.0992 - val_acc: 0.9662\n",
            "Epoch 1787/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0869 - acc: 0.9628 - val_loss: 0.1053 - val_acc: 0.9613\n",
            "Epoch 1788/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0918 - acc: 0.9614 - val_loss: 0.1099 - val_acc: 0.9603\n",
            "Epoch 1789/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0909 - acc: 0.9629 - val_loss: 0.1093 - val_acc: 0.9579\n",
            "Epoch 1790/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0893 - acc: 0.9628 - val_loss: 0.1096 - val_acc: 0.9594\n",
            "Epoch 1791/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0915 - acc: 0.9619 - val_loss: 0.0928 - val_acc: 0.9662\n",
            "Epoch 1792/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0847 - acc: 0.9655 - val_loss: 0.0968 - val_acc: 0.9652\n",
            "Epoch 1793/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0895 - acc: 0.9623 - val_loss: 0.0975 - val_acc: 0.9628\n",
            "Epoch 1794/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9635 - val_loss: 0.0959 - val_acc: 0.9657\n",
            "Epoch 1795/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0885 - acc: 0.9628 - val_loss: 0.0969 - val_acc: 0.9638\n",
            "Epoch 1796/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0894 - acc: 0.9627 - val_loss: 0.1003 - val_acc: 0.9608\n",
            "Epoch 1797/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0887 - acc: 0.9629 - val_loss: 0.0966 - val_acc: 0.9638\n",
            "Epoch 1798/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0858 - acc: 0.9654 - val_loss: 0.1017 - val_acc: 0.9579\n",
            "Epoch 1799/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0871 - acc: 0.9630 - val_loss: 0.1044 - val_acc: 0.9613\n",
            "Epoch 1800/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0867 - acc: 0.9634 - val_loss: 0.0998 - val_acc: 0.9652\n",
            "Epoch 1801/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0887 - acc: 0.9624 - val_loss: 0.0970 - val_acc: 0.9647\n",
            "Epoch 1802/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9643 - val_loss: 0.1009 - val_acc: 0.9672\n",
            "Epoch 1803/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0850 - acc: 0.9634 - val_loss: 0.0922 - val_acc: 0.9667\n",
            "Epoch 1804/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9643 - val_loss: 0.1032 - val_acc: 0.9603\n",
            "Epoch 1805/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0893 - acc: 0.9619 - val_loss: 0.1002 - val_acc: 0.9608\n",
            "Epoch 1806/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0857 - acc: 0.9644 - val_loss: 0.1036 - val_acc: 0.9598\n",
            "Epoch 1807/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0888 - acc: 0.9616 - val_loss: 0.0964 - val_acc: 0.9657\n",
            "Epoch 1808/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0867 - acc: 0.9635 - val_loss: 0.0996 - val_acc: 0.9598\n",
            "Epoch 1809/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0895 - acc: 0.9614 - val_loss: 0.0962 - val_acc: 0.9647\n",
            "Epoch 1810/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0895 - acc: 0.9616 - val_loss: 0.0957 - val_acc: 0.9618\n",
            "Epoch 1811/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0870 - acc: 0.9637 - val_loss: 0.0914 - val_acc: 0.9677\n",
            "Epoch 1812/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0859 - acc: 0.9646 - val_loss: 0.0908 - val_acc: 0.9672\n",
            "Epoch 1813/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0915 - acc: 0.9622 - val_loss: 0.0943 - val_acc: 0.9647\n",
            "Epoch 1814/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0862 - acc: 0.9623 - val_loss: 0.0997 - val_acc: 0.9638\n",
            "Epoch 1815/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0839 - acc: 0.9645 - val_loss: 0.0974 - val_acc: 0.9643\n",
            "Epoch 1816/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0874 - acc: 0.9621 - val_loss: 0.0932 - val_acc: 0.9633\n",
            "Epoch 1817/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0869 - acc: 0.9637 - val_loss: 0.0929 - val_acc: 0.9652\n",
            "Epoch 1818/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0879 - acc: 0.9635 - val_loss: 0.0930 - val_acc: 0.9662\n",
            "Epoch 1819/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0881 - acc: 0.9637 - val_loss: 0.1047 - val_acc: 0.9613\n",
            "Epoch 1820/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0884 - acc: 0.9629 - val_loss: 0.0958 - val_acc: 0.9647\n",
            "Epoch 1821/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0866 - acc: 0.9637 - val_loss: 0.0963 - val_acc: 0.9643\n",
            "Epoch 1822/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0890 - acc: 0.9617 - val_loss: 0.1029 - val_acc: 0.9598\n",
            "Epoch 1823/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0876 - acc: 0.9642 - val_loss: 0.0926 - val_acc: 0.9647\n",
            "Epoch 1824/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0843 - acc: 0.9641 - val_loss: 0.1042 - val_acc: 0.9598\n",
            "Epoch 1825/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0885 - acc: 0.9626 - val_loss: 0.1058 - val_acc: 0.9584\n",
            "Epoch 1826/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0871 - acc: 0.9644 - val_loss: 0.0981 - val_acc: 0.9598\n",
            "Epoch 1827/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0897 - acc: 0.9608 - val_loss: 0.0961 - val_acc: 0.9633\n",
            "Epoch 1828/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0874 - acc: 0.9635 - val_loss: 0.0991 - val_acc: 0.9638\n",
            "Epoch 1829/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0847 - acc: 0.9651 - val_loss: 0.0956 - val_acc: 0.9633\n",
            "Epoch 1830/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0856 - acc: 0.9640 - val_loss: 0.0921 - val_acc: 0.9672\n",
            "Epoch 1831/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0842 - acc: 0.9651 - val_loss: 0.0963 - val_acc: 0.9657\n",
            "Epoch 1832/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0904 - acc: 0.9624 - val_loss: 0.1143 - val_acc: 0.9584\n",
            "Epoch 1833/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0845 - acc: 0.9629 - val_loss: 0.1051 - val_acc: 0.9608\n",
            "Epoch 1834/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0856 - acc: 0.9628 - val_loss: 0.1016 - val_acc: 0.9613\n",
            "Epoch 1835/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0867 - acc: 0.9633 - val_loss: 0.1126 - val_acc: 0.9564\n",
            "Epoch 1836/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0917 - acc: 0.9638 - val_loss: 0.0959 - val_acc: 0.9647\n",
            "Epoch 1837/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0872 - acc: 0.9637 - val_loss: 0.0960 - val_acc: 0.9643\n",
            "Epoch 1838/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0858 - acc: 0.9644 - val_loss: 0.0998 - val_acc: 0.9623\n",
            "Epoch 1839/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0879 - acc: 0.9627 - val_loss: 0.0969 - val_acc: 0.9623\n",
            "Epoch 1840/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0876 - acc: 0.9632 - val_loss: 0.0985 - val_acc: 0.9623\n",
            "Epoch 1841/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0861 - acc: 0.9638 - val_loss: 0.0995 - val_acc: 0.9613\n",
            "Epoch 1842/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0882 - acc: 0.9630 - val_loss: 0.1012 - val_acc: 0.9603\n",
            "Epoch 1843/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0848 - acc: 0.9632 - val_loss: 0.0944 - val_acc: 0.9667\n",
            "Epoch 1844/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0831 - acc: 0.9658 - val_loss: 0.0970 - val_acc: 0.9667\n",
            "Epoch 1845/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0839 - acc: 0.9641 - val_loss: 0.1044 - val_acc: 0.9638\n",
            "Epoch 1846/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0864 - acc: 0.9633 - val_loss: 0.0923 - val_acc: 0.9691\n",
            "Epoch 1847/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0872 - acc: 0.9621 - val_loss: 0.0954 - val_acc: 0.9657\n",
            "Epoch 1848/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0876 - acc: 0.9626 - val_loss: 0.0947 - val_acc: 0.9628\n",
            "Epoch 1849/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0876 - acc: 0.9629 - val_loss: 0.0969 - val_acc: 0.9623\n",
            "Epoch 1850/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0866 - acc: 0.9629 - val_loss: 0.0981 - val_acc: 0.9623\n",
            "Epoch 1851/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0862 - acc: 0.9639 - val_loss: 0.0910 - val_acc: 0.9672\n",
            "Epoch 1852/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0851 - acc: 0.9644 - val_loss: 0.0920 - val_acc: 0.9647\n",
            "Epoch 1853/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0854 - acc: 0.9628 - val_loss: 0.0954 - val_acc: 0.9633\n",
            "Epoch 1854/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9622 - val_loss: 0.0924 - val_acc: 0.9672\n",
            "Epoch 1855/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0828 - acc: 0.9654 - val_loss: 0.0998 - val_acc: 0.9618\n",
            "Epoch 1856/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0874 - acc: 0.9637 - val_loss: 0.0932 - val_acc: 0.9657\n",
            "Epoch 1857/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0847 - acc: 0.9655 - val_loss: 0.0931 - val_acc: 0.9682\n",
            "Epoch 1858/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9647 - val_loss: 0.0931 - val_acc: 0.9643\n",
            "Epoch 1859/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0904 - acc: 0.9622 - val_loss: 0.0995 - val_acc: 0.9618\n",
            "Epoch 1860/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0851 - acc: 0.9645 - val_loss: 0.0984 - val_acc: 0.9628\n",
            "Epoch 1861/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0872 - acc: 0.9630 - val_loss: 0.1003 - val_acc: 0.9608\n",
            "Epoch 1862/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0891 - acc: 0.9630 - val_loss: 0.0903 - val_acc: 0.9667\n",
            "Epoch 1863/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0863 - acc: 0.9639 - val_loss: 0.0967 - val_acc: 0.9652\n",
            "Epoch 1864/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0896 - acc: 0.9635 - val_loss: 0.0953 - val_acc: 0.9652\n",
            "Epoch 1865/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0852 - acc: 0.9644 - val_loss: 0.0983 - val_acc: 0.9633\n",
            "Epoch 1866/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0828 - acc: 0.9633 - val_loss: 0.0975 - val_acc: 0.9638\n",
            "Epoch 1867/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9643 - val_loss: 0.1099 - val_acc: 0.9598\n",
            "Epoch 1868/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0878 - acc: 0.9626 - val_loss: 0.1076 - val_acc: 0.9608\n",
            "Epoch 1869/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0887 - acc: 0.9620 - val_loss: 0.0975 - val_acc: 0.9643\n",
            "Epoch 1870/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0868 - acc: 0.9636 - val_loss: 0.0993 - val_acc: 0.9623\n",
            "Epoch 1871/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0856 - acc: 0.9644 - val_loss: 0.0936 - val_acc: 0.9667\n",
            "Epoch 1872/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0858 - acc: 0.9643 - val_loss: 0.0957 - val_acc: 0.9647\n",
            "Epoch 1873/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0876 - acc: 0.9635 - val_loss: 0.1026 - val_acc: 0.9633\n",
            "Epoch 1874/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9643 - val_loss: 0.0993 - val_acc: 0.9618\n",
            "Epoch 1875/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0869 - acc: 0.9613 - val_loss: 0.0971 - val_acc: 0.9633\n",
            "Epoch 1876/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0837 - acc: 0.9651 - val_loss: 0.0988 - val_acc: 0.9633\n",
            "Epoch 1877/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0868 - acc: 0.9627 - val_loss: 0.0981 - val_acc: 0.9608\n",
            "Epoch 1878/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0848 - acc: 0.9632 - val_loss: 0.0944 - val_acc: 0.9667\n",
            "Epoch 1879/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0850 - acc: 0.9644 - val_loss: 0.0962 - val_acc: 0.9628\n",
            "Epoch 1880/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0853 - acc: 0.9642 - val_loss: 0.0965 - val_acc: 0.9638\n",
            "Epoch 1881/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0845 - acc: 0.9639 - val_loss: 0.0952 - val_acc: 0.9652\n",
            "Epoch 1882/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0844 - acc: 0.9636 - val_loss: 0.0953 - val_acc: 0.9647\n",
            "Epoch 1883/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0848 - acc: 0.9640 - val_loss: 0.0985 - val_acc: 0.9618\n",
            "Epoch 1884/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0866 - acc: 0.9624 - val_loss: 0.0933 - val_acc: 0.9662\n",
            "Epoch 1885/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0873 - acc: 0.9633 - val_loss: 0.0931 - val_acc: 0.9662\n",
            "Epoch 1886/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0837 - acc: 0.9647 - val_loss: 0.0947 - val_acc: 0.9682\n",
            "Epoch 1887/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0861 - acc: 0.9642 - val_loss: 0.0973 - val_acc: 0.9647\n",
            "Epoch 1888/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0857 - acc: 0.9640 - val_loss: 0.1022 - val_acc: 0.9603\n",
            "Epoch 1889/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0850 - acc: 0.9637 - val_loss: 0.0970 - val_acc: 0.9662\n",
            "Epoch 1890/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0858 - acc: 0.9627 - val_loss: 0.0969 - val_acc: 0.9623\n",
            "Epoch 1891/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0883 - acc: 0.9638 - val_loss: 0.1020 - val_acc: 0.9608\n",
            "Epoch 1892/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0877 - acc: 0.9632 - val_loss: 0.0933 - val_acc: 0.9652\n",
            "Epoch 1893/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0834 - acc: 0.9651 - val_loss: 0.0947 - val_acc: 0.9647\n",
            "Epoch 1894/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0878 - acc: 0.9630 - val_loss: 0.0998 - val_acc: 0.9618\n",
            "Epoch 1895/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0853 - acc: 0.9643 - val_loss: 0.0955 - val_acc: 0.9672\n",
            "Epoch 1896/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0864 - acc: 0.9637 - val_loss: 0.0959 - val_acc: 0.9672\n",
            "Epoch 1897/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0873 - acc: 0.9628 - val_loss: 0.0938 - val_acc: 0.9657\n",
            "Epoch 1898/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9631 - val_loss: 0.0963 - val_acc: 0.9657\n",
            "Epoch 1899/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0849 - acc: 0.9642 - val_loss: 0.1103 - val_acc: 0.9589\n",
            "Epoch 1900/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0839 - acc: 0.9654 - val_loss: 0.1010 - val_acc: 0.9643\n",
            "Epoch 1901/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0854 - acc: 0.9636 - val_loss: 0.0935 - val_acc: 0.9667\n",
            "Epoch 1902/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0860 - acc: 0.9640 - val_loss: 0.0971 - val_acc: 0.9643\n",
            "Epoch 1903/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0852 - acc: 0.9639 - val_loss: 0.0923 - val_acc: 0.9677\n",
            "Epoch 1904/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0888 - acc: 0.9634 - val_loss: 0.0968 - val_acc: 0.9647\n",
            "Epoch 1905/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0844 - acc: 0.9642 - val_loss: 0.0984 - val_acc: 0.9638\n",
            "Epoch 1906/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9634 - val_loss: 0.0999 - val_acc: 0.9638\n",
            "Epoch 1907/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0835 - acc: 0.9642 - val_loss: 0.1022 - val_acc: 0.9633\n",
            "Epoch 1908/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9650 - val_loss: 0.1020 - val_acc: 0.9623\n",
            "Epoch 1909/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0824 - acc: 0.9651 - val_loss: 0.0969 - val_acc: 0.9657\n",
            "Epoch 1910/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0812 - acc: 0.9660 - val_loss: 0.0999 - val_acc: 0.9613\n",
            "Epoch 1911/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9632 - val_loss: 0.1043 - val_acc: 0.9569\n",
            "Epoch 1912/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0861 - acc: 0.9634 - val_loss: 0.1078 - val_acc: 0.9589\n",
            "Epoch 1913/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0840 - acc: 0.9637 - val_loss: 0.0959 - val_acc: 0.9647\n",
            "Epoch 1914/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0810 - acc: 0.9667 - val_loss: 0.0976 - val_acc: 0.9643\n",
            "Epoch 1915/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0831 - acc: 0.9636 - val_loss: 0.0961 - val_acc: 0.9657\n",
            "Epoch 1916/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0839 - acc: 0.9656 - val_loss: 0.0995 - val_acc: 0.9618\n",
            "Epoch 1917/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9638 - val_loss: 0.0974 - val_acc: 0.9623\n",
            "Epoch 1918/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0861 - acc: 0.9640 - val_loss: 0.0992 - val_acc: 0.9657\n",
            "Epoch 1919/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0841 - acc: 0.9638 - val_loss: 0.0959 - val_acc: 0.9657\n",
            "Epoch 1920/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0847 - acc: 0.9648 - val_loss: 0.0947 - val_acc: 0.9657\n",
            "Epoch 1921/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0862 - acc: 0.9641 - val_loss: 0.0974 - val_acc: 0.9662\n",
            "Epoch 1922/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0858 - acc: 0.9643 - val_loss: 0.0991 - val_acc: 0.9628\n",
            "Epoch 1923/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0821 - acc: 0.9654 - val_loss: 0.0951 - val_acc: 0.9623\n",
            "Epoch 1924/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0861 - acc: 0.9642 - val_loss: 0.0986 - val_acc: 0.9657\n",
            "Epoch 1925/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0842 - acc: 0.9652 - val_loss: 0.1000 - val_acc: 0.9652\n",
            "Epoch 1926/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0835 - acc: 0.9646 - val_loss: 0.0947 - val_acc: 0.9657\n",
            "Epoch 1927/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0878 - acc: 0.9618 - val_loss: 0.0955 - val_acc: 0.9672\n",
            "Epoch 1928/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0843 - acc: 0.9640 - val_loss: 0.0940 - val_acc: 0.9667\n",
            "Epoch 1929/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0833 - acc: 0.9643 - val_loss: 0.0947 - val_acc: 0.9633\n",
            "Epoch 1930/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0833 - acc: 0.9644 - val_loss: 0.0912 - val_acc: 0.9662\n",
            "Epoch 1931/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0814 - acc: 0.9659 - val_loss: 0.1001 - val_acc: 0.9613\n",
            "Epoch 1932/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0870 - acc: 0.9638 - val_loss: 0.0971 - val_acc: 0.9638\n",
            "Epoch 1933/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0830 - acc: 0.9648 - val_loss: 0.0983 - val_acc: 0.9667\n",
            "Epoch 1934/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0872 - acc: 0.9624 - val_loss: 0.0974 - val_acc: 0.9647\n",
            "Epoch 1935/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0820 - acc: 0.9661 - val_loss: 0.0937 - val_acc: 0.9657\n",
            "Epoch 1936/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0853 - acc: 0.9637 - val_loss: 0.0979 - val_acc: 0.9662\n",
            "Epoch 1937/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0860 - acc: 0.9630 - val_loss: 0.0967 - val_acc: 0.9652\n",
            "Epoch 1938/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0839 - acc: 0.9641 - val_loss: 0.1004 - val_acc: 0.9643\n",
            "Epoch 1939/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0826 - acc: 0.9652 - val_loss: 0.0970 - val_acc: 0.9647\n",
            "Epoch 1940/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0837 - acc: 0.9643 - val_loss: 0.1012 - val_acc: 0.9628\n",
            "Epoch 1941/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0855 - acc: 0.9642 - val_loss: 0.0961 - val_acc: 0.9652\n",
            "Epoch 1942/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0847 - acc: 0.9644 - val_loss: 0.0970 - val_acc: 0.9613\n",
            "Epoch 1943/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0852 - acc: 0.9641 - val_loss: 0.0950 - val_acc: 0.9682\n",
            "Epoch 1944/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0848 - acc: 0.9635 - val_loss: 0.0943 - val_acc: 0.9643\n",
            "Epoch 1945/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0841 - acc: 0.9652 - val_loss: 0.0970 - val_acc: 0.9647\n",
            "Epoch 1946/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0833 - acc: 0.9652 - val_loss: 0.0947 - val_acc: 0.9652\n",
            "Epoch 1947/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0842 - acc: 0.9641 - val_loss: 0.1037 - val_acc: 0.9603\n",
            "Epoch 1948/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9643 - val_loss: 0.1024 - val_acc: 0.9633\n",
            "Epoch 1949/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0854 - acc: 0.9635 - val_loss: 0.0939 - val_acc: 0.9643\n",
            "Epoch 1950/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0842 - acc: 0.9641 - val_loss: 0.0919 - val_acc: 0.9657\n",
            "Epoch 1951/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0820 - acc: 0.9657 - val_loss: 0.1029 - val_acc: 0.9608\n",
            "Epoch 1952/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0808 - acc: 0.9663 - val_loss: 0.0891 - val_acc: 0.9687\n",
            "Epoch 1953/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0816 - acc: 0.9646 - val_loss: 0.0961 - val_acc: 0.9667\n",
            "Epoch 1954/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0854 - acc: 0.9637 - val_loss: 0.0993 - val_acc: 0.9647\n",
            "Epoch 1955/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0843 - acc: 0.9651 - val_loss: 0.0934 - val_acc: 0.9677\n",
            "Epoch 1956/4096\n",
            "16342/16342 [==============================] - 0s 18us/step - loss: 0.0873 - acc: 0.9616 - val_loss: 0.1071 - val_acc: 0.9603\n",
            "Epoch 1957/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0832 - acc: 0.9635 - val_loss: 0.0894 - val_acc: 0.9677\n",
            "Epoch 1958/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0833 - acc: 0.9651 - val_loss: 0.0928 - val_acc: 0.9667\n",
            "Epoch 1959/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0828 - acc: 0.9639 - val_loss: 0.0902 - val_acc: 0.9677\n",
            "Epoch 1960/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0852 - acc: 0.9627 - val_loss: 0.0967 - val_acc: 0.9638\n",
            "Epoch 1961/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0826 - acc: 0.9650 - val_loss: 0.0941 - val_acc: 0.9662\n",
            "Epoch 1962/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9666 - val_loss: 0.0934 - val_acc: 0.9682\n",
            "Epoch 1963/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0834 - acc: 0.9645 - val_loss: 0.0957 - val_acc: 0.9647\n",
            "Epoch 1964/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0828 - acc: 0.9646 - val_loss: 0.1001 - val_acc: 0.9633\n",
            "Epoch 1965/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0837 - acc: 0.9647 - val_loss: 0.1028 - val_acc: 0.9618\n",
            "Epoch 1966/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0818 - acc: 0.9668 - val_loss: 0.0913 - val_acc: 0.9657\n",
            "Epoch 1967/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0865 - acc: 0.9643 - val_loss: 0.1012 - val_acc: 0.9618\n",
            "Epoch 1968/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0850 - acc: 0.9634 - val_loss: 0.0974 - val_acc: 0.9657\n",
            "Epoch 1969/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0849 - acc: 0.9650 - val_loss: 0.1059 - val_acc: 0.9598\n",
            "Epoch 1970/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0893 - acc: 0.9617 - val_loss: 0.0987 - val_acc: 0.9662\n",
            "Epoch 1971/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0852 - acc: 0.9624 - val_loss: 0.1162 - val_acc: 0.9559\n",
            "Epoch 1972/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0830 - acc: 0.9658 - val_loss: 0.0895 - val_acc: 0.9687\n",
            "Epoch 1973/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0859 - acc: 0.9630 - val_loss: 0.0960 - val_acc: 0.9662\n",
            "Epoch 1974/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0807 - acc: 0.9659 - val_loss: 0.1005 - val_acc: 0.9643\n",
            "Epoch 1975/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0836 - acc: 0.9665 - val_loss: 0.0960 - val_acc: 0.9643\n",
            "Epoch 1976/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0836 - acc: 0.9651 - val_loss: 0.0962 - val_acc: 0.9662\n",
            "Epoch 1977/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0815 - acc: 0.9653 - val_loss: 0.0945 - val_acc: 0.9652\n",
            "Epoch 1978/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0822 - acc: 0.9656 - val_loss: 0.0908 - val_acc: 0.9672\n",
            "Epoch 1979/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0828 - acc: 0.9646 - val_loss: 0.0981 - val_acc: 0.9633\n",
            "Epoch 1980/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0806 - acc: 0.9656 - val_loss: 0.0916 - val_acc: 0.9672\n",
            "Epoch 1981/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0825 - acc: 0.9663 - val_loss: 0.1073 - val_acc: 0.9574\n",
            "Epoch 1982/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0869 - acc: 0.9628 - val_loss: 0.0993 - val_acc: 0.9633\n",
            "Epoch 1983/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0814 - acc: 0.9655 - val_loss: 0.0953 - val_acc: 0.9662\n",
            "Epoch 1984/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0822 - acc: 0.9659 - val_loss: 0.0978 - val_acc: 0.9638\n",
            "Epoch 1985/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0820 - acc: 0.9652 - val_loss: 0.0916 - val_acc: 0.9657\n",
            "Epoch 1986/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0812 - acc: 0.9655 - val_loss: 0.0924 - val_acc: 0.9696\n",
            "Epoch 1987/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0816 - acc: 0.9676 - val_loss: 0.0929 - val_acc: 0.9662\n",
            "Epoch 1988/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0811 - acc: 0.9644 - val_loss: 0.0958 - val_acc: 0.9682\n",
            "Epoch 1989/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0826 - acc: 0.9641 - val_loss: 0.0932 - val_acc: 0.9633\n",
            "Epoch 1990/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0838 - acc: 0.9647 - val_loss: 0.1113 - val_acc: 0.9584\n",
            "Epoch 1991/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0844 - acc: 0.9636 - val_loss: 0.0924 - val_acc: 0.9638\n",
            "Epoch 1992/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0822 - acc: 0.9654 - val_loss: 0.0991 - val_acc: 0.9652\n",
            "Epoch 1993/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0785 - acc: 0.9681 - val_loss: 0.1183 - val_acc: 0.9598\n",
            "Epoch 1994/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0833 - acc: 0.9638 - val_loss: 0.1126 - val_acc: 0.9598\n",
            "Epoch 1995/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0807 - acc: 0.9652 - val_loss: 0.1002 - val_acc: 0.9638\n",
            "Epoch 1996/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0858 - acc: 0.9635 - val_loss: 0.0952 - val_acc: 0.9657\n",
            "Epoch 1997/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0809 - acc: 0.9652 - val_loss: 0.1052 - val_acc: 0.9628\n",
            "Epoch 1998/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0832 - acc: 0.9649 - val_loss: 0.1045 - val_acc: 0.9618\n",
            "Epoch 1999/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0796 - acc: 0.9663 - val_loss: 0.0925 - val_acc: 0.9677\n",
            "Epoch 2000/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0811 - acc: 0.9657 - val_loss: 0.0986 - val_acc: 0.9633\n",
            "Epoch 2001/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0859 - acc: 0.9651 - val_loss: 0.0927 - val_acc: 0.9672\n",
            "Epoch 2002/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0801 - acc: 0.9663 - val_loss: 0.0937 - val_acc: 0.9662\n",
            "Epoch 2003/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0790 - acc: 0.9659 - val_loss: 0.0987 - val_acc: 0.9623\n",
            "Epoch 2004/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0841 - acc: 0.9649 - val_loss: 0.0925 - val_acc: 0.9691\n",
            "Epoch 2005/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0874 - acc: 0.9628 - val_loss: 0.1011 - val_acc: 0.9638\n",
            "Epoch 2006/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0811 - acc: 0.9651 - val_loss: 0.0933 - val_acc: 0.9667\n",
            "Epoch 2007/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0839 - acc: 0.9641 - val_loss: 0.0971 - val_acc: 0.9638\n",
            "Epoch 2008/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0836 - acc: 0.9657 - val_loss: 0.1037 - val_acc: 0.9638\n",
            "Epoch 2009/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0834 - acc: 0.9659 - val_loss: 0.1120 - val_acc: 0.9594\n",
            "Epoch 2010/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0826 - acc: 0.9653 - val_loss: 0.0990 - val_acc: 0.9618\n",
            "Epoch 2011/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9659 - val_loss: 0.0963 - val_acc: 0.9667\n",
            "Epoch 2012/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0844 - acc: 0.9634 - val_loss: 0.1020 - val_acc: 0.9647\n",
            "Epoch 2013/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0828 - acc: 0.9663 - val_loss: 0.0997 - val_acc: 0.9633\n",
            "Epoch 2014/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0812 - acc: 0.9680 - val_loss: 0.0934 - val_acc: 0.9652\n",
            "Epoch 2015/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0855 - acc: 0.9629 - val_loss: 0.0951 - val_acc: 0.9652\n",
            "Epoch 2016/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0809 - acc: 0.9639 - val_loss: 0.0936 - val_acc: 0.9682\n",
            "Epoch 2017/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0819 - acc: 0.9639 - val_loss: 0.0975 - val_acc: 0.9652\n",
            "Epoch 2018/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0835 - acc: 0.9653 - val_loss: 0.0947 - val_acc: 0.9652\n",
            "Epoch 2019/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0788 - acc: 0.9674 - val_loss: 0.1012 - val_acc: 0.9613\n",
            "Epoch 2020/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0801 - acc: 0.9670 - val_loss: 0.0920 - val_acc: 0.9701\n",
            "Epoch 2021/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0796 - acc: 0.9655 - val_loss: 0.1027 - val_acc: 0.9643\n",
            "Epoch 2022/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0816 - acc: 0.9644 - val_loss: 0.1010 - val_acc: 0.9657\n",
            "Epoch 2023/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0832 - acc: 0.9658 - val_loss: 0.0906 - val_acc: 0.9667\n",
            "Epoch 2024/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0806 - acc: 0.9667 - val_loss: 0.0968 - val_acc: 0.9657\n",
            "Epoch 2025/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0813 - acc: 0.9654 - val_loss: 0.1002 - val_acc: 0.9643\n",
            "Epoch 2026/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0799 - acc: 0.9670 - val_loss: 0.0996 - val_acc: 0.9638\n",
            "Epoch 2027/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0825 - acc: 0.9649 - val_loss: 0.0963 - val_acc: 0.9652\n",
            "Epoch 2028/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0815 - acc: 0.9655 - val_loss: 0.1029 - val_acc: 0.9618\n",
            "Epoch 2029/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0820 - acc: 0.9652 - val_loss: 0.0966 - val_acc: 0.9657\n",
            "Epoch 2030/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0833 - acc: 0.9637 - val_loss: 0.0993 - val_acc: 0.9623\n",
            "Epoch 2031/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0845 - acc: 0.9654 - val_loss: 0.0922 - val_acc: 0.9652\n",
            "Epoch 2032/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9654 - val_loss: 0.0992 - val_acc: 0.9652\n",
            "Epoch 2033/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0800 - acc: 0.9659 - val_loss: 0.0925 - val_acc: 0.9696\n",
            "Epoch 2034/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0796 - acc: 0.9663 - val_loss: 0.0917 - val_acc: 0.9677\n",
            "Epoch 2035/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0809 - acc: 0.9653 - val_loss: 0.0904 - val_acc: 0.9682\n",
            "Epoch 2036/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0827 - acc: 0.9651 - val_loss: 0.0988 - val_acc: 0.9628\n",
            "Epoch 2037/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0800 - acc: 0.9663 - val_loss: 0.0985 - val_acc: 0.9643\n",
            "Epoch 2038/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0780 - acc: 0.9673 - val_loss: 0.0938 - val_acc: 0.9647\n",
            "Epoch 2039/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0822 - acc: 0.9655 - val_loss: 0.0965 - val_acc: 0.9672\n",
            "Epoch 2040/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0779 - acc: 0.9663 - val_loss: 0.0963 - val_acc: 0.9677\n",
            "Epoch 2041/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0807 - acc: 0.9655 - val_loss: 0.0963 - val_acc: 0.9677\n",
            "Epoch 2042/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9670 - val_loss: 0.0970 - val_acc: 0.9623\n",
            "Epoch 2043/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0819 - acc: 0.9660 - val_loss: 0.0906 - val_acc: 0.9647\n",
            "Epoch 2044/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0789 - acc: 0.9660 - val_loss: 0.0997 - val_acc: 0.9647\n",
            "Epoch 2045/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0824 - acc: 0.9665 - val_loss: 0.0915 - val_acc: 0.9667\n",
            "Epoch 2046/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0810 - acc: 0.9666 - val_loss: 0.0900 - val_acc: 0.9691\n",
            "Epoch 2047/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0838 - acc: 0.9650 - val_loss: 0.0963 - val_acc: 0.9662\n",
            "Epoch 2048/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0805 - acc: 0.9665 - val_loss: 0.0863 - val_acc: 0.9667\n",
            "Epoch 2049/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0793 - acc: 0.9664 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2050/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0821 - acc: 0.9651 - val_loss: 0.0959 - val_acc: 0.9652\n",
            "Epoch 2051/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0796 - acc: 0.9665 - val_loss: 0.0930 - val_acc: 0.9657\n",
            "Epoch 2052/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0801 - acc: 0.9667 - val_loss: 0.0914 - val_acc: 0.9662\n",
            "Epoch 2053/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0821 - acc: 0.9660 - val_loss: 0.0941 - val_acc: 0.9667\n",
            "Epoch 2054/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9648 - val_loss: 0.0905 - val_acc: 0.9672\n",
            "Epoch 2055/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0820 - acc: 0.9648 - val_loss: 0.0996 - val_acc: 0.9618\n",
            "Epoch 2056/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0867 - acc: 0.9640 - val_loss: 0.0938 - val_acc: 0.9643\n",
            "Epoch 2057/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0799 - acc: 0.9669 - val_loss: 0.0986 - val_acc: 0.9633\n",
            "Epoch 2058/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9670 - val_loss: 0.0928 - val_acc: 0.9623\n",
            "Epoch 2059/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0827 - acc: 0.9662 - val_loss: 0.0984 - val_acc: 0.9652\n",
            "Epoch 2060/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0809 - acc: 0.9644 - val_loss: 0.0873 - val_acc: 0.9691\n",
            "Epoch 2061/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0822 - acc: 0.9651 - val_loss: 0.0957 - val_acc: 0.9647\n",
            "Epoch 2062/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0783 - acc: 0.9678 - val_loss: 0.0937 - val_acc: 0.9652\n",
            "Epoch 2063/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0779 - acc: 0.9673 - val_loss: 0.0971 - val_acc: 0.9657\n",
            "Epoch 2064/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0797 - acc: 0.9668 - val_loss: 0.0914 - val_acc: 0.9662\n",
            "Epoch 2065/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0794 - acc: 0.9663 - val_loss: 0.0983 - val_acc: 0.9633\n",
            "Epoch 2066/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0795 - acc: 0.9663 - val_loss: 0.0969 - val_acc: 0.9657\n",
            "Epoch 2067/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0783 - acc: 0.9667 - val_loss: 0.0921 - val_acc: 0.9667\n",
            "Epoch 2068/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0832 - acc: 0.9646 - val_loss: 0.0922 - val_acc: 0.9687\n",
            "Epoch 2069/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0837 - acc: 0.9637 - val_loss: 0.0965 - val_acc: 0.9638\n",
            "Epoch 2070/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0806 - acc: 0.9651 - val_loss: 0.1036 - val_acc: 0.9638\n",
            "Epoch 2071/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9665 - val_loss: 0.0959 - val_acc: 0.9652\n",
            "Epoch 2072/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0803 - acc: 0.9653 - val_loss: 0.0990 - val_acc: 0.9628\n",
            "Epoch 2073/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0824 - acc: 0.9651 - val_loss: 0.0973 - val_acc: 0.9657\n",
            "Epoch 2074/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0847 - acc: 0.9640 - val_loss: 0.0940 - val_acc: 0.9652\n",
            "Epoch 2075/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0818 - acc: 0.9652 - val_loss: 0.0929 - val_acc: 0.9652\n",
            "Epoch 2076/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0828 - acc: 0.9649 - val_loss: 0.0916 - val_acc: 0.9667\n",
            "Epoch 2077/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0812 - acc: 0.9651 - val_loss: 0.0957 - val_acc: 0.9667\n",
            "Epoch 2078/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0803 - acc: 0.9657 - val_loss: 0.0895 - val_acc: 0.9677\n",
            "Epoch 2079/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0793 - acc: 0.9657 - val_loss: 0.1063 - val_acc: 0.9638\n",
            "Epoch 2080/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0788 - acc: 0.9657 - val_loss: 0.0948 - val_acc: 0.9682\n",
            "Epoch 2081/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0771 - acc: 0.9684 - val_loss: 0.0993 - val_acc: 0.9643\n",
            "Epoch 2082/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0809 - acc: 0.9661 - val_loss: 0.0930 - val_acc: 0.9657\n",
            "Epoch 2083/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0789 - acc: 0.9667 - val_loss: 0.0943 - val_acc: 0.9652\n",
            "Epoch 2084/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0845 - acc: 0.9644 - val_loss: 0.0935 - val_acc: 0.9682\n",
            "Epoch 2085/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0822 - acc: 0.9649 - val_loss: 0.0975 - val_acc: 0.9628\n",
            "Epoch 2086/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9661 - val_loss: 0.0958 - val_acc: 0.9647\n",
            "Epoch 2087/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0785 - acc: 0.9666 - val_loss: 0.1079 - val_acc: 0.9613\n",
            "Epoch 2088/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0816 - acc: 0.9653 - val_loss: 0.0928 - val_acc: 0.9687\n",
            "Epoch 2089/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0797 - acc: 0.9667 - val_loss: 0.0944 - val_acc: 0.9672\n",
            "Epoch 2090/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0769 - acc: 0.9671 - val_loss: 0.0956 - val_acc: 0.9667\n",
            "Epoch 2091/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0782 - acc: 0.9676 - val_loss: 0.0930 - val_acc: 0.9657\n",
            "Epoch 2092/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0785 - acc: 0.9676 - val_loss: 0.0962 - val_acc: 0.9672\n",
            "Epoch 2093/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0775 - acc: 0.9678 - val_loss: 0.1024 - val_acc: 0.9638\n",
            "Epoch 2094/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0775 - acc: 0.9670 - val_loss: 0.0927 - val_acc: 0.9667\n",
            "Epoch 2095/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0807 - acc: 0.9666 - val_loss: 0.0960 - val_acc: 0.9657\n",
            "Epoch 2096/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0755 - acc: 0.9696 - val_loss: 0.0970 - val_acc: 0.9652\n",
            "Epoch 2097/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0776 - acc: 0.9679 - val_loss: 0.0960 - val_acc: 0.9667\n",
            "Epoch 2098/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0811 - acc: 0.9654 - val_loss: 0.1004 - val_acc: 0.9633\n",
            "Epoch 2099/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0798 - acc: 0.9665 - val_loss: 0.0890 - val_acc: 0.9687\n",
            "Epoch 2100/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0790 - acc: 0.9675 - val_loss: 0.0972 - val_acc: 0.9623\n",
            "Epoch 2101/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0782 - acc: 0.9689 - val_loss: 0.0929 - val_acc: 0.9677\n",
            "Epoch 2102/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9663 - val_loss: 0.0904 - val_acc: 0.9706\n",
            "Epoch 2103/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0799 - acc: 0.9663 - val_loss: 0.0989 - val_acc: 0.9643\n",
            "Epoch 2104/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0814 - acc: 0.9674 - val_loss: 0.0985 - val_acc: 0.9662\n",
            "Epoch 2105/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0786 - acc: 0.9658 - val_loss: 0.0936 - val_acc: 0.9662\n",
            "Epoch 2106/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0814 - acc: 0.9638 - val_loss: 0.0926 - val_acc: 0.9652\n",
            "Epoch 2107/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0784 - acc: 0.9678 - val_loss: 0.0952 - val_acc: 0.9672\n",
            "Epoch 2108/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0801 - acc: 0.9652 - val_loss: 0.0952 - val_acc: 0.9652\n",
            "Epoch 2109/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0822 - acc: 0.9656 - val_loss: 0.0972 - val_acc: 0.9638\n",
            "Epoch 2110/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0840 - acc: 0.9636 - val_loss: 0.0944 - val_acc: 0.9701\n",
            "Epoch 2111/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0809 - acc: 0.9673 - val_loss: 0.0892 - val_acc: 0.9677\n",
            "Epoch 2112/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0772 - acc: 0.9681 - val_loss: 0.1027 - val_acc: 0.9628\n",
            "Epoch 2113/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0774 - acc: 0.9674 - val_loss: 0.0909 - val_acc: 0.9662\n",
            "Epoch 2114/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0779 - acc: 0.9662 - val_loss: 0.0897 - val_acc: 0.9662\n",
            "Epoch 2115/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0801 - acc: 0.9654 - val_loss: 0.0960 - val_acc: 0.9643\n",
            "Epoch 2116/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0776 - acc: 0.9670 - val_loss: 0.0881 - val_acc: 0.9691\n",
            "Epoch 2117/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0765 - acc: 0.9671 - val_loss: 0.0960 - val_acc: 0.9662\n",
            "Epoch 2118/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0785 - acc: 0.9657 - val_loss: 0.0931 - val_acc: 0.9633\n",
            "Epoch 2119/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0772 - acc: 0.9674 - val_loss: 0.1036 - val_acc: 0.9618\n",
            "Epoch 2120/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0836 - acc: 0.9657 - val_loss: 0.1035 - val_acc: 0.9598\n",
            "Epoch 2121/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0796 - acc: 0.9679 - val_loss: 0.0921 - val_acc: 0.9677\n",
            "Epoch 2122/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0804 - acc: 0.9655 - val_loss: 0.0926 - val_acc: 0.9662\n",
            "Epoch 2123/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0760 - acc: 0.9679 - val_loss: 0.0927 - val_acc: 0.9691\n",
            "Epoch 2124/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0777 - acc: 0.9675 - val_loss: 0.0950 - val_acc: 0.9667\n",
            "Epoch 2125/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0773 - acc: 0.9676 - val_loss: 0.0943 - val_acc: 0.9667\n",
            "Epoch 2126/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0817 - acc: 0.9650 - val_loss: 0.0891 - val_acc: 0.9691\n",
            "Epoch 2127/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0797 - acc: 0.9657 - val_loss: 0.0939 - val_acc: 0.9696\n",
            "Epoch 2128/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0779 - acc: 0.9667 - val_loss: 0.0921 - val_acc: 0.9672\n",
            "Epoch 2129/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0772 - acc: 0.9681 - val_loss: 0.0935 - val_acc: 0.9677\n",
            "Epoch 2130/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0774 - acc: 0.9680 - val_loss: 0.1014 - val_acc: 0.9657\n",
            "Epoch 2131/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0774 - acc: 0.9681 - val_loss: 0.0919 - val_acc: 0.9682\n",
            "Epoch 2132/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0796 - acc: 0.9668 - val_loss: 0.0931 - val_acc: 0.9638\n",
            "Epoch 2133/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0803 - acc: 0.9666 - val_loss: 0.0938 - val_acc: 0.9643\n",
            "Epoch 2134/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0765 - acc: 0.9679 - val_loss: 0.0952 - val_acc: 0.9667\n",
            "Epoch 2135/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0772 - acc: 0.9682 - val_loss: 0.0981 - val_acc: 0.9652\n",
            "Epoch 2136/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0796 - acc: 0.9664 - val_loss: 0.0993 - val_acc: 0.9643\n",
            "Epoch 2137/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0785 - acc: 0.9681 - val_loss: 0.0904 - val_acc: 0.9672\n",
            "Epoch 2138/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0802 - acc: 0.9667 - val_loss: 0.0944 - val_acc: 0.9652\n",
            "Epoch 2139/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0771 - acc: 0.9666 - val_loss: 0.0952 - val_acc: 0.9662\n",
            "Epoch 2140/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0765 - acc: 0.9690 - val_loss: 0.0964 - val_acc: 0.9638\n",
            "Epoch 2141/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0786 - acc: 0.9671 - val_loss: 0.0960 - val_acc: 0.9638\n",
            "Epoch 2142/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0820 - acc: 0.9655 - val_loss: 0.1023 - val_acc: 0.9623\n",
            "Epoch 2143/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0779 - acc: 0.9674 - val_loss: 0.0983 - val_acc: 0.9638\n",
            "Epoch 2144/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0754 - acc: 0.9685 - val_loss: 0.0881 - val_acc: 0.9706\n",
            "Epoch 2145/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0808 - acc: 0.9655 - val_loss: 0.1041 - val_acc: 0.9652\n",
            "Epoch 2146/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0795 - acc: 0.9681 - val_loss: 0.0951 - val_acc: 0.9662\n",
            "Epoch 2147/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9661 - val_loss: 0.1024 - val_acc: 0.9643\n",
            "Epoch 2148/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0773 - acc: 0.9669 - val_loss: 0.0946 - val_acc: 0.9633\n",
            "Epoch 2149/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9682 - val_loss: 0.1075 - val_acc: 0.9594\n",
            "Epoch 2150/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0777 - acc: 0.9682 - val_loss: 0.0961 - val_acc: 0.9647\n",
            "Epoch 2151/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9670 - val_loss: 0.0924 - val_acc: 0.9667\n",
            "Epoch 2152/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0794 - acc: 0.9657 - val_loss: 0.0955 - val_acc: 0.9657\n",
            "Epoch 2153/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0778 - acc: 0.9674 - val_loss: 0.0931 - val_acc: 0.9662\n",
            "Epoch 2154/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0763 - acc: 0.9673 - val_loss: 0.0937 - val_acc: 0.9662\n",
            "Epoch 2155/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0796 - acc: 0.9663 - val_loss: 0.0915 - val_acc: 0.9662\n",
            "Epoch 2156/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0787 - acc: 0.9672 - val_loss: 0.0956 - val_acc: 0.9662\n",
            "Epoch 2157/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0770 - acc: 0.9684 - val_loss: 0.0946 - val_acc: 0.9667\n",
            "Epoch 2158/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0763 - acc: 0.9676 - val_loss: 0.0949 - val_acc: 0.9672\n",
            "Epoch 2159/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9680 - val_loss: 0.0956 - val_acc: 0.9657\n",
            "Epoch 2160/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0777 - acc: 0.9674 - val_loss: 0.0957 - val_acc: 0.9638\n",
            "Epoch 2161/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0750 - acc: 0.9676 - val_loss: 0.0914 - val_acc: 0.9652\n",
            "Epoch 2162/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0756 - acc: 0.9690 - val_loss: 0.0911 - val_acc: 0.9667\n",
            "Epoch 2163/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0782 - acc: 0.9678 - val_loss: 0.0990 - val_acc: 0.9652\n",
            "Epoch 2164/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0762 - acc: 0.9671 - val_loss: 0.0912 - val_acc: 0.9667\n",
            "Epoch 2165/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0764 - acc: 0.9686 - val_loss: 0.0907 - val_acc: 0.9682\n",
            "Epoch 2166/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0787 - acc: 0.9695 - val_loss: 0.0966 - val_acc: 0.9677\n",
            "Epoch 2167/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0758 - acc: 0.9676 - val_loss: 0.0864 - val_acc: 0.9677\n",
            "Epoch 2168/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0758 - acc: 0.9690 - val_loss: 0.0927 - val_acc: 0.9677\n",
            "Epoch 2169/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0791 - acc: 0.9673 - val_loss: 0.0926 - val_acc: 0.9662\n",
            "Epoch 2170/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0745 - acc: 0.9676 - val_loss: 0.0939 - val_acc: 0.9682\n",
            "Epoch 2171/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0775 - acc: 0.9670 - val_loss: 0.0921 - val_acc: 0.9691\n",
            "Epoch 2172/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0762 - acc: 0.9676 - val_loss: 0.0882 - val_acc: 0.9706\n",
            "Epoch 2173/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0757 - acc: 0.9674 - val_loss: 0.0961 - val_acc: 0.9677\n",
            "Epoch 2174/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0768 - acc: 0.9683 - val_loss: 0.0929 - val_acc: 0.9687\n",
            "Epoch 2175/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0774 - acc: 0.9670 - val_loss: 0.0947 - val_acc: 0.9677\n",
            "Epoch 2176/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0770 - acc: 0.9665 - val_loss: 0.0893 - val_acc: 0.9657\n",
            "Epoch 2177/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0807 - acc: 0.9658 - val_loss: 0.0953 - val_acc: 0.9652\n",
            "Epoch 2178/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0772 - acc: 0.9676 - val_loss: 0.0895 - val_acc: 0.9682\n",
            "Epoch 2179/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0789 - acc: 0.9664 - val_loss: 0.0885 - val_acc: 0.9662\n",
            "Epoch 2180/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0775 - acc: 0.9678 - val_loss: 0.0911 - val_acc: 0.9667\n",
            "Epoch 2181/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0763 - acc: 0.9684 - val_loss: 0.1024 - val_acc: 0.9633\n",
            "Epoch 2182/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0739 - acc: 0.9689 - val_loss: 0.0943 - val_acc: 0.9682\n",
            "Epoch 2183/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0770 - acc: 0.9671 - val_loss: 0.0886 - val_acc: 0.9696\n",
            "Epoch 2184/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0800 - acc: 0.9660 - val_loss: 0.0924 - val_acc: 0.9677\n",
            "Epoch 2185/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0790 - acc: 0.9667 - val_loss: 0.1041 - val_acc: 0.9652\n",
            "Epoch 2186/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0786 - acc: 0.9675 - val_loss: 0.1090 - val_acc: 0.9618\n",
            "Epoch 2187/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0763 - acc: 0.9680 - val_loss: 0.0913 - val_acc: 0.9667\n",
            "Epoch 2188/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0769 - acc: 0.9670 - val_loss: 0.0902 - val_acc: 0.9682\n",
            "Epoch 2189/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9676 - val_loss: 0.0876 - val_acc: 0.9682\n",
            "Epoch 2190/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0753 - acc: 0.9688 - val_loss: 0.0892 - val_acc: 0.9662\n",
            "Epoch 2191/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0746 - acc: 0.9687 - val_loss: 0.0876 - val_acc: 0.9706\n",
            "Epoch 2192/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0785 - acc: 0.9674 - val_loss: 0.0922 - val_acc: 0.9643\n",
            "Epoch 2193/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0772 - acc: 0.9674 - val_loss: 0.0999 - val_acc: 0.9608\n",
            "Epoch 2194/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0791 - acc: 0.9665 - val_loss: 0.1002 - val_acc: 0.9608\n",
            "Epoch 2195/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0763 - acc: 0.9676 - val_loss: 0.0889 - val_acc: 0.9667\n",
            "Epoch 2196/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0747 - acc: 0.9679 - val_loss: 0.0894 - val_acc: 0.9677\n",
            "Epoch 2197/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0741 - acc: 0.9682 - val_loss: 0.0968 - val_acc: 0.9647\n",
            "Epoch 2198/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0784 - acc: 0.9680 - val_loss: 0.0992 - val_acc: 0.9628\n",
            "Epoch 2199/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0779 - acc: 0.9685 - val_loss: 0.0923 - val_acc: 0.9701\n",
            "Epoch 2200/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0791 - acc: 0.9666 - val_loss: 0.0917 - val_acc: 0.9687\n",
            "Epoch 2201/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0775 - acc: 0.9672 - val_loss: 0.0933 - val_acc: 0.9647\n",
            "Epoch 2202/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0753 - acc: 0.9677 - val_loss: 0.0931 - val_acc: 0.9682\n",
            "Epoch 2203/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0772 - acc: 0.9684 - val_loss: 0.0892 - val_acc: 0.9672\n",
            "Epoch 2204/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0788 - acc: 0.9675 - val_loss: 0.0957 - val_acc: 0.9652\n",
            "Epoch 2205/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0816 - acc: 0.9652 - val_loss: 0.1226 - val_acc: 0.9545\n",
            "Epoch 2206/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0783 - acc: 0.9670 - val_loss: 0.0994 - val_acc: 0.9672\n",
            "Epoch 2207/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0742 - acc: 0.9692 - val_loss: 0.0966 - val_acc: 0.9682\n",
            "Epoch 2208/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0767 - acc: 0.9697 - val_loss: 0.0956 - val_acc: 0.9643\n",
            "Epoch 2209/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0775 - acc: 0.9677 - val_loss: 0.0995 - val_acc: 0.9652\n",
            "Epoch 2210/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0776 - acc: 0.9689 - val_loss: 0.0957 - val_acc: 0.9628\n",
            "Epoch 2211/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0746 - acc: 0.9692 - val_loss: 0.0970 - val_acc: 0.9643\n",
            "Epoch 2212/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0770 - acc: 0.9676 - val_loss: 0.0890 - val_acc: 0.9667\n",
            "Epoch 2213/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0761 - acc: 0.9685 - val_loss: 0.0974 - val_acc: 0.9623\n",
            "Epoch 2214/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9674 - val_loss: 0.0994 - val_acc: 0.9662\n",
            "Epoch 2215/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0805 - acc: 0.9657 - val_loss: 0.0940 - val_acc: 0.9677\n",
            "Epoch 2216/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0756 - acc: 0.9683 - val_loss: 0.1052 - val_acc: 0.9598\n",
            "Epoch 2217/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0741 - acc: 0.9701 - val_loss: 0.0889 - val_acc: 0.9672\n",
            "Epoch 2218/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0737 - acc: 0.9697 - val_loss: 0.0888 - val_acc: 0.9696\n",
            "Epoch 2219/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0775 - acc: 0.9672 - val_loss: 0.0879 - val_acc: 0.9687\n",
            "Epoch 2220/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0760 - acc: 0.9681 - val_loss: 0.0965 - val_acc: 0.9618\n",
            "Epoch 2221/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0780 - acc: 0.9664 - val_loss: 0.0881 - val_acc: 0.9682\n",
            "Epoch 2222/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0765 - acc: 0.9679 - val_loss: 0.0945 - val_acc: 0.9657\n",
            "Epoch 2223/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0759 - acc: 0.9675 - val_loss: 0.0840 - val_acc: 0.9696\n",
            "Epoch 2224/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0770 - acc: 0.9682 - val_loss: 0.0916 - val_acc: 0.9667\n",
            "Epoch 2225/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0789 - acc: 0.9660 - val_loss: 0.0931 - val_acc: 0.9667\n",
            "Epoch 2226/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0766 - acc: 0.9679 - val_loss: 0.0976 - val_acc: 0.9633\n",
            "Epoch 2227/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0783 - acc: 0.9678 - val_loss: 0.0945 - val_acc: 0.9672\n",
            "Epoch 2228/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0764 - acc: 0.9671 - val_loss: 0.1015 - val_acc: 0.9638\n",
            "Epoch 2229/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0740 - acc: 0.9695 - val_loss: 0.0937 - val_acc: 0.9687\n",
            "Epoch 2230/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0739 - acc: 0.9685 - val_loss: 0.1013 - val_acc: 0.9662\n",
            "Epoch 2231/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0782 - acc: 0.9687 - val_loss: 0.0889 - val_acc: 0.9687\n",
            "Epoch 2232/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9681 - val_loss: 0.0916 - val_acc: 0.9638\n",
            "Epoch 2233/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0791 - acc: 0.9656 - val_loss: 0.0916 - val_acc: 0.9667\n",
            "Epoch 2234/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0740 - acc: 0.9695 - val_loss: 0.0935 - val_acc: 0.9672\n",
            "Epoch 2235/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0749 - acc: 0.9685 - val_loss: 0.0972 - val_acc: 0.9682\n",
            "Epoch 2236/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0767 - acc: 0.9677 - val_loss: 0.0901 - val_acc: 0.9662\n",
            "Epoch 2237/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0762 - acc: 0.9687 - val_loss: 0.0965 - val_acc: 0.9662\n",
            "Epoch 2238/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0747 - acc: 0.9680 - val_loss: 0.0943 - val_acc: 0.9647\n",
            "Epoch 2239/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0753 - acc: 0.9684 - val_loss: 0.0920 - val_acc: 0.9687\n",
            "Epoch 2240/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0752 - acc: 0.9668 - val_loss: 0.0966 - val_acc: 0.9662\n",
            "Epoch 2241/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0768 - acc: 0.9692 - val_loss: 0.0939 - val_acc: 0.9677\n",
            "Epoch 2242/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0744 - acc: 0.9694 - val_loss: 0.1006 - val_acc: 0.9623\n",
            "Epoch 2243/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0744 - acc: 0.9696 - val_loss: 0.0945 - val_acc: 0.9652\n",
            "Epoch 2244/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9663 - val_loss: 0.0904 - val_acc: 0.9706\n",
            "Epoch 2245/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0740 - acc: 0.9694 - val_loss: 0.0897 - val_acc: 0.9677\n",
            "Epoch 2246/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0771 - acc: 0.9677 - val_loss: 0.0907 - val_acc: 0.9672\n",
            "Epoch 2247/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0756 - acc: 0.9694 - val_loss: 0.0894 - val_acc: 0.9691\n",
            "Epoch 2248/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0737 - acc: 0.9700 - val_loss: 0.0916 - val_acc: 0.9662\n",
            "Epoch 2249/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0770 - acc: 0.9683 - val_loss: 0.0821 - val_acc: 0.9701\n",
            "Epoch 2250/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0769 - acc: 0.9689 - val_loss: 0.0933 - val_acc: 0.9662\n",
            "Epoch 2251/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0788 - acc: 0.9677 - val_loss: 0.0960 - val_acc: 0.9677\n",
            "Epoch 2252/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0727 - acc: 0.9698 - val_loss: 0.0927 - val_acc: 0.9711\n",
            "Epoch 2253/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0747 - acc: 0.9674 - val_loss: 0.0880 - val_acc: 0.9706\n",
            "Epoch 2254/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0763 - acc: 0.9687 - val_loss: 0.0958 - val_acc: 0.9667\n",
            "Epoch 2255/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9707 - val_loss: 0.0983 - val_acc: 0.9647\n",
            "Epoch 2256/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0782 - acc: 0.9682 - val_loss: 0.0877 - val_acc: 0.9706\n",
            "Epoch 2257/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0747 - acc: 0.9684 - val_loss: 0.0887 - val_acc: 0.9682\n",
            "Epoch 2258/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0777 - acc: 0.9655 - val_loss: 0.1001 - val_acc: 0.9652\n",
            "Epoch 2259/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0778 - acc: 0.9662 - val_loss: 0.1045 - val_acc: 0.9633\n",
            "Epoch 2260/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0743 - acc: 0.9681 - val_loss: 0.0966 - val_acc: 0.9657\n",
            "Epoch 2261/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0757 - acc: 0.9688 - val_loss: 0.0922 - val_acc: 0.9672\n",
            "Epoch 2262/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0758 - acc: 0.9688 - val_loss: 0.0922 - val_acc: 0.9657\n",
            "Epoch 2263/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0753 - acc: 0.9684 - val_loss: 0.0864 - val_acc: 0.9667\n",
            "Epoch 2264/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0725 - acc: 0.9695 - val_loss: 0.0893 - val_acc: 0.9652\n",
            "Epoch 2265/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0788 - acc: 0.9683 - val_loss: 0.0980 - val_acc: 0.9672\n",
            "Epoch 2266/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0749 - acc: 0.9690 - val_loss: 0.0885 - val_acc: 0.9696\n",
            "Epoch 2267/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9681 - val_loss: 0.0962 - val_acc: 0.9633\n",
            "Epoch 2268/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0790 - acc: 0.9665 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2269/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9692 - val_loss: 0.0952 - val_acc: 0.9677\n",
            "Epoch 2270/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9692 - val_loss: 0.0938 - val_acc: 0.9643\n",
            "Epoch 2271/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0774 - acc: 0.9670 - val_loss: 0.0919 - val_acc: 0.9638\n",
            "Epoch 2272/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0747 - acc: 0.9687 - val_loss: 0.0969 - val_acc: 0.9638\n",
            "Epoch 2273/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0713 - acc: 0.9698 - val_loss: 0.0888 - val_acc: 0.9706\n",
            "Epoch 2274/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0755 - acc: 0.9682 - val_loss: 0.0870 - val_acc: 0.9701\n",
            "Epoch 2275/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0736 - acc: 0.9692 - val_loss: 0.0957 - val_acc: 0.9652\n",
            "Epoch 2276/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0762 - acc: 0.9679 - val_loss: 0.0903 - val_acc: 0.9687\n",
            "Epoch 2277/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0768 - acc: 0.9665 - val_loss: 0.0927 - val_acc: 0.9672\n",
            "Epoch 2278/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0748 - acc: 0.9684 - val_loss: 0.0871 - val_acc: 0.9682\n",
            "Epoch 2279/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0724 - acc: 0.9690 - val_loss: 0.0880 - val_acc: 0.9691\n",
            "Epoch 2280/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0742 - acc: 0.9691 - val_loss: 0.0912 - val_acc: 0.9682\n",
            "Epoch 2281/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0713 - acc: 0.9693 - val_loss: 0.0926 - val_acc: 0.9672\n",
            "Epoch 2282/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9685 - val_loss: 0.0948 - val_acc: 0.9643\n",
            "Epoch 2283/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0734 - acc: 0.9697 - val_loss: 0.0903 - val_acc: 0.9677\n",
            "Epoch 2284/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0741 - acc: 0.9684 - val_loss: 0.0940 - val_acc: 0.9701\n",
            "Epoch 2285/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0733 - acc: 0.9689 - val_loss: 0.0976 - val_acc: 0.9623\n",
            "Epoch 2286/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0739 - acc: 0.9700 - val_loss: 0.0905 - val_acc: 0.9677\n",
            "Epoch 2287/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0736 - acc: 0.9692 - val_loss: 0.0895 - val_acc: 0.9677\n",
            "Epoch 2288/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0757 - acc: 0.9680 - val_loss: 0.0915 - val_acc: 0.9667\n",
            "Epoch 2289/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0761 - acc: 0.9690 - val_loss: 0.1014 - val_acc: 0.9652\n",
            "Epoch 2290/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0736 - acc: 0.9682 - val_loss: 0.1073 - val_acc: 0.9638\n",
            "Epoch 2291/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0748 - acc: 0.9676 - val_loss: 0.0873 - val_acc: 0.9711\n",
            "Epoch 2292/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0750 - acc: 0.9690 - val_loss: 0.0917 - val_acc: 0.9672\n",
            "Epoch 2293/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0713 - acc: 0.9703 - val_loss: 0.0849 - val_acc: 0.9701\n",
            "Epoch 2294/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0729 - acc: 0.9692 - val_loss: 0.0859 - val_acc: 0.9696\n",
            "Epoch 2295/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0759 - acc: 0.9681 - val_loss: 0.0937 - val_acc: 0.9677\n",
            "Epoch 2296/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0739 - acc: 0.9687 - val_loss: 0.0924 - val_acc: 0.9667\n",
            "Epoch 2297/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0723 - acc: 0.9711 - val_loss: 0.0951 - val_acc: 0.9643\n",
            "Epoch 2298/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0785 - acc: 0.9685 - val_loss: 0.0899 - val_acc: 0.9662\n",
            "Epoch 2299/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0733 - acc: 0.9695 - val_loss: 0.0966 - val_acc: 0.9623\n",
            "Epoch 2300/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9712 - val_loss: 0.0946 - val_acc: 0.9657\n",
            "Epoch 2301/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0774 - acc: 0.9694 - val_loss: 0.0850 - val_acc: 0.9721\n",
            "Epoch 2302/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0754 - acc: 0.9686 - val_loss: 0.0934 - val_acc: 0.9691\n",
            "Epoch 2303/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0766 - acc: 0.9689 - val_loss: 0.0892 - val_acc: 0.9691\n",
            "Epoch 2304/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9679 - val_loss: 0.0925 - val_acc: 0.9682\n",
            "Epoch 2305/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0755 - acc: 0.9670 - val_loss: 0.0950 - val_acc: 0.9672\n",
            "Epoch 2306/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0729 - acc: 0.9694 - val_loss: 0.0919 - val_acc: 0.9682\n",
            "Epoch 2307/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0743 - acc: 0.9690 - val_loss: 0.0857 - val_acc: 0.9701\n",
            "Epoch 2308/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0756 - acc: 0.9697 - val_loss: 0.0969 - val_acc: 0.9647\n",
            "Epoch 2309/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0764 - acc: 0.9687 - val_loss: 0.0902 - val_acc: 0.9701\n",
            "Epoch 2310/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0743 - acc: 0.9699 - val_loss: 0.0948 - val_acc: 0.9623\n",
            "Epoch 2311/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0738 - acc: 0.9689 - val_loss: 0.0934 - val_acc: 0.9657\n",
            "Epoch 2312/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0750 - acc: 0.9688 - val_loss: 0.0903 - val_acc: 0.9672\n",
            "Epoch 2313/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0735 - acc: 0.9703 - val_loss: 0.0957 - val_acc: 0.9672\n",
            "Epoch 2314/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0767 - acc: 0.9686 - val_loss: 0.0887 - val_acc: 0.9667\n",
            "Epoch 2315/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0711 - acc: 0.9687 - val_loss: 0.0865 - val_acc: 0.9667\n",
            "Epoch 2316/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0746 - acc: 0.9684 - val_loss: 0.0900 - val_acc: 0.9682\n",
            "Epoch 2317/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0759 - acc: 0.9675 - val_loss: 0.0941 - val_acc: 0.9667\n",
            "Epoch 2318/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0761 - acc: 0.9685 - val_loss: 0.0905 - val_acc: 0.9696\n",
            "Epoch 2319/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0748 - acc: 0.9687 - val_loss: 0.1007 - val_acc: 0.9643\n",
            "Epoch 2320/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9702 - val_loss: 0.0974 - val_acc: 0.9682\n",
            "Epoch 2321/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0734 - acc: 0.9695 - val_loss: 0.0901 - val_acc: 0.9696\n",
            "Epoch 2322/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0745 - acc: 0.9684 - val_loss: 0.0921 - val_acc: 0.9657\n",
            "Epoch 2323/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0717 - acc: 0.9697 - val_loss: 0.0936 - val_acc: 0.9682\n",
            "Epoch 2324/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9684 - val_loss: 0.0920 - val_acc: 0.9691\n",
            "Epoch 2325/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0751 - acc: 0.9677 - val_loss: 0.1075 - val_acc: 0.9613\n",
            "Epoch 2326/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0757 - acc: 0.9680 - val_loss: 0.0972 - val_acc: 0.9647\n",
            "Epoch 2327/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0729 - acc: 0.9696 - val_loss: 0.0914 - val_acc: 0.9687\n",
            "Epoch 2328/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0725 - acc: 0.9695 - val_loss: 0.0927 - val_acc: 0.9667\n",
            "Epoch 2329/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0740 - acc: 0.9684 - val_loss: 0.0881 - val_acc: 0.9677\n",
            "Epoch 2330/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0733 - acc: 0.9692 - val_loss: 0.1065 - val_acc: 0.9633\n",
            "Epoch 2331/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9709 - val_loss: 0.0885 - val_acc: 0.9657\n",
            "Epoch 2332/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0733 - acc: 0.9724 - val_loss: 0.0882 - val_acc: 0.9706\n",
            "Epoch 2333/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0714 - acc: 0.9697 - val_loss: 0.0923 - val_acc: 0.9672\n",
            "Epoch 2334/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0746 - acc: 0.9681 - val_loss: 0.0924 - val_acc: 0.9667\n",
            "Epoch 2335/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9702 - val_loss: 0.0855 - val_acc: 0.9711\n",
            "Epoch 2336/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0714 - acc: 0.9713 - val_loss: 0.0912 - val_acc: 0.9691\n",
            "Epoch 2337/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0763 - acc: 0.9676 - val_loss: 0.0939 - val_acc: 0.9657\n",
            "Epoch 2338/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0743 - acc: 0.9686 - val_loss: 0.0921 - val_acc: 0.9657\n",
            "Epoch 2339/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0768 - acc: 0.9684 - val_loss: 0.0873 - val_acc: 0.9682\n",
            "Epoch 2340/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0722 - acc: 0.9685 - val_loss: 0.0962 - val_acc: 0.9667\n",
            "Epoch 2341/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0735 - acc: 0.9694 - val_loss: 0.0933 - val_acc: 0.9662\n",
            "Epoch 2342/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9694 - val_loss: 0.0890 - val_acc: 0.9687\n",
            "Epoch 2343/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0746 - acc: 0.9689 - val_loss: 0.0943 - val_acc: 0.9657\n",
            "Epoch 2344/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0731 - acc: 0.9687 - val_loss: 0.0874 - val_acc: 0.9691\n",
            "Epoch 2345/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0743 - acc: 0.9701 - val_loss: 0.0935 - val_acc: 0.9647\n",
            "Epoch 2346/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0733 - acc: 0.9698 - val_loss: 0.0943 - val_acc: 0.9682\n",
            "Epoch 2347/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0697 - acc: 0.9705 - val_loss: 0.0876 - val_acc: 0.9677\n",
            "Epoch 2348/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0701 - acc: 0.9705 - val_loss: 0.0873 - val_acc: 0.9677\n",
            "Epoch 2349/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0731 - acc: 0.9700 - val_loss: 0.0871 - val_acc: 0.9701\n",
            "Epoch 2350/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0743 - acc: 0.9693 - val_loss: 0.0884 - val_acc: 0.9701\n",
            "Epoch 2351/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0744 - acc: 0.9674 - val_loss: 0.0856 - val_acc: 0.9696\n",
            "Epoch 2352/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0764 - acc: 0.9679 - val_loss: 0.0954 - val_acc: 0.9672\n",
            "Epoch 2353/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0742 - acc: 0.9681 - val_loss: 0.0927 - val_acc: 0.9677\n",
            "Epoch 2354/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0754 - acc: 0.9686 - val_loss: 0.0955 - val_acc: 0.9662\n",
            "Epoch 2355/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0699 - acc: 0.9705 - val_loss: 0.1005 - val_acc: 0.9643\n",
            "Epoch 2356/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0724 - acc: 0.9687 - val_loss: 0.0901 - val_acc: 0.9677\n",
            "Epoch 2357/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0727 - acc: 0.9706 - val_loss: 0.1022 - val_acc: 0.9647\n",
            "Epoch 2358/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9702 - val_loss: 0.0929 - val_acc: 0.9662\n",
            "Epoch 2359/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9673 - val_loss: 0.0982 - val_acc: 0.9618\n",
            "Epoch 2360/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0722 - acc: 0.9692 - val_loss: 0.0985 - val_acc: 0.9638\n",
            "Epoch 2361/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0734 - acc: 0.9697 - val_loss: 0.0914 - val_acc: 0.9652\n",
            "Epoch 2362/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0761 - acc: 0.9684 - val_loss: 0.0900 - val_acc: 0.9691\n",
            "Epoch 2363/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0731 - acc: 0.9714 - val_loss: 0.0906 - val_acc: 0.9677\n",
            "Epoch 2364/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0714 - acc: 0.9697 - val_loss: 0.0885 - val_acc: 0.9677\n",
            "Epoch 2365/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0763 - acc: 0.9701 - val_loss: 0.0888 - val_acc: 0.9677\n",
            "Epoch 2366/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0751 - acc: 0.9676 - val_loss: 0.0915 - val_acc: 0.9682\n",
            "Epoch 2367/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0709 - acc: 0.9696 - val_loss: 0.0881 - val_acc: 0.9682\n",
            "Epoch 2368/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0745 - acc: 0.9685 - val_loss: 0.0879 - val_acc: 0.9662\n",
            "Epoch 2369/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9700 - val_loss: 0.0911 - val_acc: 0.9677\n",
            "Epoch 2370/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0731 - acc: 0.9702 - val_loss: 0.0925 - val_acc: 0.9691\n",
            "Epoch 2371/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0714 - acc: 0.9700 - val_loss: 0.0902 - val_acc: 0.9657\n",
            "Epoch 2372/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9696 - val_loss: 0.0909 - val_acc: 0.9691\n",
            "Epoch 2373/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0728 - acc: 0.9708 - val_loss: 0.0912 - val_acc: 0.9672\n",
            "Epoch 2374/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0729 - acc: 0.9694 - val_loss: 0.0842 - val_acc: 0.9716\n",
            "Epoch 2375/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0722 - acc: 0.9714 - val_loss: 0.0883 - val_acc: 0.9677\n",
            "Epoch 2376/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0730 - acc: 0.9700 - val_loss: 0.0992 - val_acc: 0.9657\n",
            "Epoch 2377/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0747 - acc: 0.9695 - val_loss: 0.0961 - val_acc: 0.9662\n",
            "Epoch 2378/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0750 - acc: 0.9689 - val_loss: 0.0963 - val_acc: 0.9647\n",
            "Epoch 2379/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0719 - acc: 0.9703 - val_loss: 0.0874 - val_acc: 0.9701\n",
            "Epoch 2380/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0728 - acc: 0.9685 - val_loss: 0.0962 - val_acc: 0.9647\n",
            "Epoch 2381/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0719 - acc: 0.9693 - val_loss: 0.0913 - val_acc: 0.9633\n",
            "Epoch 2382/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0747 - acc: 0.9685 - val_loss: 0.0882 - val_acc: 0.9677\n",
            "Epoch 2383/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0727 - acc: 0.9701 - val_loss: 0.0953 - val_acc: 0.9638\n",
            "Epoch 2384/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0722 - acc: 0.9712 - val_loss: 0.1004 - val_acc: 0.9633\n",
            "Epoch 2385/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0737 - acc: 0.9688 - val_loss: 0.0918 - val_acc: 0.9672\n",
            "Epoch 2386/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0725 - acc: 0.9704 - val_loss: 0.0903 - val_acc: 0.9672\n",
            "Epoch 2387/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0736 - acc: 0.9695 - val_loss: 0.1011 - val_acc: 0.9628\n",
            "Epoch 2388/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0736 - acc: 0.9701 - val_loss: 0.0910 - val_acc: 0.9667\n",
            "Epoch 2389/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0706 - acc: 0.9712 - val_loss: 0.0908 - val_acc: 0.9672\n",
            "Epoch 2390/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0722 - acc: 0.9703 - val_loss: 0.0993 - val_acc: 0.9657\n",
            "Epoch 2391/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0719 - acc: 0.9704 - val_loss: 0.0918 - val_acc: 0.9691\n",
            "Epoch 2392/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0726 - acc: 0.9708 - val_loss: 0.1052 - val_acc: 0.9618\n",
            "Epoch 2393/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0714 - acc: 0.9712 - val_loss: 0.0878 - val_acc: 0.9701\n",
            "Epoch 2394/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0688 - acc: 0.9713 - val_loss: 0.1024 - val_acc: 0.9638\n",
            "Epoch 2395/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9696 - val_loss: 0.0971 - val_acc: 0.9638\n",
            "Epoch 2396/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0719 - acc: 0.9705 - val_loss: 0.0943 - val_acc: 0.9677\n",
            "Epoch 2397/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0742 - acc: 0.9685 - val_loss: 0.0898 - val_acc: 0.9682\n",
            "Epoch 2398/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0714 - acc: 0.9690 - val_loss: 0.0896 - val_acc: 0.9696\n",
            "Epoch 2399/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0714 - acc: 0.9697 - val_loss: 0.0951 - val_acc: 0.9652\n",
            "Epoch 2400/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0697 - acc: 0.9709 - val_loss: 0.0905 - val_acc: 0.9691\n",
            "Epoch 2401/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0720 - acc: 0.9679 - val_loss: 0.0826 - val_acc: 0.9691\n",
            "Epoch 2402/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0664 - acc: 0.9723 - val_loss: 0.0909 - val_acc: 0.9691\n",
            "Epoch 2403/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0724 - acc: 0.9706 - val_loss: 0.1025 - val_acc: 0.9618\n",
            "Epoch 2404/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0726 - acc: 0.9698 - val_loss: 0.0998 - val_acc: 0.9623\n",
            "Epoch 2405/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0716 - acc: 0.9708 - val_loss: 0.0909 - val_acc: 0.9677\n",
            "Epoch 2406/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0733 - acc: 0.9714 - val_loss: 0.0918 - val_acc: 0.9677\n",
            "Epoch 2407/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0727 - acc: 0.9707 - val_loss: 0.0868 - val_acc: 0.9677\n",
            "Epoch 2408/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0705 - acc: 0.9709 - val_loss: 0.0911 - val_acc: 0.9672\n",
            "Epoch 2409/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9705 - val_loss: 0.0826 - val_acc: 0.9726\n",
            "Epoch 2410/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0715 - acc: 0.9696 - val_loss: 0.0875 - val_acc: 0.9696\n",
            "Epoch 2411/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0720 - acc: 0.9693 - val_loss: 0.0944 - val_acc: 0.9647\n",
            "Epoch 2412/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0747 - acc: 0.9681 - val_loss: 0.0919 - val_acc: 0.9672\n",
            "Epoch 2413/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0727 - acc: 0.9694 - val_loss: 0.0862 - val_acc: 0.9691\n",
            "Epoch 2414/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9715 - val_loss: 0.0845 - val_acc: 0.9716\n",
            "Epoch 2415/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0747 - acc: 0.9696 - val_loss: 0.0890 - val_acc: 0.9667\n",
            "Epoch 2416/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0722 - acc: 0.9709 - val_loss: 0.0886 - val_acc: 0.9667\n",
            "Epoch 2417/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0760 - acc: 0.9684 - val_loss: 0.1007 - val_acc: 0.9647\n",
            "Epoch 2418/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0734 - acc: 0.9705 - val_loss: 0.0889 - val_acc: 0.9662\n",
            "Epoch 2419/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9701 - val_loss: 0.0963 - val_acc: 0.9652\n",
            "Epoch 2420/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0719 - acc: 0.9700 - val_loss: 0.0927 - val_acc: 0.9701\n",
            "Epoch 2421/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0720 - acc: 0.9695 - val_loss: 0.0883 - val_acc: 0.9672\n",
            "Epoch 2422/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9711 - val_loss: 0.0884 - val_acc: 0.9682\n",
            "Epoch 2423/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0717 - acc: 0.9717 - val_loss: 0.0975 - val_acc: 0.9657\n",
            "Epoch 2424/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0701 - acc: 0.9716 - val_loss: 0.0887 - val_acc: 0.9696\n",
            "Epoch 2425/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0696 - acc: 0.9717 - val_loss: 0.0871 - val_acc: 0.9691\n",
            "Epoch 2426/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0706 - acc: 0.9704 - val_loss: 0.0842 - val_acc: 0.9691\n",
            "Epoch 2427/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0733 - acc: 0.9695 - val_loss: 0.0907 - val_acc: 0.9691\n",
            "Epoch 2428/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9703 - val_loss: 0.0970 - val_acc: 0.9662\n",
            "Epoch 2429/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0721 - acc: 0.9699 - val_loss: 0.0892 - val_acc: 0.9696\n",
            "Epoch 2430/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0714 - acc: 0.9703 - val_loss: 0.0981 - val_acc: 0.9662\n",
            "Epoch 2431/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9691 - val_loss: 0.0934 - val_acc: 0.9687\n",
            "Epoch 2432/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9699 - val_loss: 0.0965 - val_acc: 0.9652\n",
            "Epoch 2433/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9704 - val_loss: 0.0999 - val_acc: 0.9647\n",
            "Epoch 2434/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0728 - acc: 0.9700 - val_loss: 0.0886 - val_acc: 0.9721\n",
            "Epoch 2435/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0720 - acc: 0.9708 - val_loss: 0.0951 - val_acc: 0.9652\n",
            "Epoch 2436/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0720 - acc: 0.9695 - val_loss: 0.0829 - val_acc: 0.9706\n",
            "Epoch 2437/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0701 - acc: 0.9706 - val_loss: 0.0984 - val_acc: 0.9643\n",
            "Epoch 2438/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0696 - acc: 0.9709 - val_loss: 0.0904 - val_acc: 0.9691\n",
            "Epoch 2439/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0703 - acc: 0.9707 - val_loss: 0.0913 - val_acc: 0.9647\n",
            "Epoch 2440/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0724 - acc: 0.9698 - val_loss: 0.0995 - val_acc: 0.9643\n",
            "Epoch 2441/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9692 - val_loss: 0.0940 - val_acc: 0.9638\n",
            "Epoch 2442/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0733 - acc: 0.9684 - val_loss: 0.0940 - val_acc: 0.9706\n",
            "Epoch 2443/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0697 - acc: 0.9714 - val_loss: 0.0852 - val_acc: 0.9701\n",
            "Epoch 2444/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9708 - val_loss: 0.0946 - val_acc: 0.9677\n",
            "Epoch 2445/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9714 - val_loss: 0.0918 - val_acc: 0.9677\n",
            "Epoch 2446/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0742 - acc: 0.9679 - val_loss: 0.0914 - val_acc: 0.9677\n",
            "Epoch 2447/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0704 - acc: 0.9697 - val_loss: 0.0887 - val_acc: 0.9677\n",
            "Epoch 2448/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0714 - acc: 0.9698 - val_loss: 0.0862 - val_acc: 0.9706\n",
            "Epoch 2449/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0683 - acc: 0.9721 - val_loss: 0.1017 - val_acc: 0.9638\n",
            "Epoch 2450/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9693 - val_loss: 0.0875 - val_acc: 0.9691\n",
            "Epoch 2451/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0727 - acc: 0.9696 - val_loss: 0.0842 - val_acc: 0.9706\n",
            "Epoch 2452/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0670 - acc: 0.9727 - val_loss: 0.0960 - val_acc: 0.9652\n",
            "Epoch 2453/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0693 - acc: 0.9714 - val_loss: 0.0888 - val_acc: 0.9682\n",
            "Epoch 2454/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0734 - acc: 0.9689 - val_loss: 0.0881 - val_acc: 0.9667\n",
            "Epoch 2455/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9704 - val_loss: 0.0904 - val_acc: 0.9682\n",
            "Epoch 2456/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0707 - acc: 0.9708 - val_loss: 0.1029 - val_acc: 0.9633\n",
            "Epoch 2457/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0712 - acc: 0.9701 - val_loss: 0.0938 - val_acc: 0.9657\n",
            "Epoch 2458/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0708 - acc: 0.9695 - val_loss: 0.0954 - val_acc: 0.9682\n",
            "Epoch 2459/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0771 - acc: 0.9678 - val_loss: 0.0918 - val_acc: 0.9691\n",
            "Epoch 2460/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0744 - acc: 0.9694 - val_loss: 0.0994 - val_acc: 0.9667\n",
            "Epoch 2461/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0703 - acc: 0.9706 - val_loss: 0.0930 - val_acc: 0.9662\n",
            "Epoch 2462/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0695 - acc: 0.9706 - val_loss: 0.0926 - val_acc: 0.9677\n",
            "Epoch 2463/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0721 - acc: 0.9702 - val_loss: 0.0872 - val_acc: 0.9667\n",
            "Epoch 2464/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9731 - val_loss: 0.0924 - val_acc: 0.9691\n",
            "Epoch 2465/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9715 - val_loss: 0.0877 - val_acc: 0.9696\n",
            "Epoch 2466/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0704 - acc: 0.9701 - val_loss: 0.0905 - val_acc: 0.9667\n",
            "Epoch 2467/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0681 - acc: 0.9720 - val_loss: 0.0896 - val_acc: 0.9657\n",
            "Epoch 2468/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0724 - acc: 0.9689 - val_loss: 0.0888 - val_acc: 0.9701\n",
            "Epoch 2469/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0707 - acc: 0.9703 - val_loss: 0.0951 - val_acc: 0.9662\n",
            "Epoch 2470/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0715 - acc: 0.9711 - val_loss: 0.0868 - val_acc: 0.9696\n",
            "Epoch 2471/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0665 - acc: 0.9731 - val_loss: 0.1007 - val_acc: 0.9613\n",
            "Epoch 2472/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0723 - acc: 0.9700 - val_loss: 0.0905 - val_acc: 0.9687\n",
            "Epoch 2473/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9702 - val_loss: 0.1020 - val_acc: 0.9647\n",
            "Epoch 2474/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0711 - acc: 0.9701 - val_loss: 0.0888 - val_acc: 0.9662\n",
            "Epoch 2475/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0725 - acc: 0.9695 - val_loss: 0.0977 - val_acc: 0.9662\n",
            "Epoch 2476/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0674 - acc: 0.9716 - val_loss: 0.0950 - val_acc: 0.9647\n",
            "Epoch 2477/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0684 - acc: 0.9715 - val_loss: 0.0869 - val_acc: 0.9696\n",
            "Epoch 2478/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0717 - acc: 0.9704 - val_loss: 0.0874 - val_acc: 0.9696\n",
            "Epoch 2479/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0697 - acc: 0.9715 - val_loss: 0.0944 - val_acc: 0.9638\n",
            "Epoch 2480/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0702 - acc: 0.9712 - val_loss: 0.0960 - val_acc: 0.9682\n",
            "Epoch 2481/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0711 - acc: 0.9710 - val_loss: 0.0893 - val_acc: 0.9662\n",
            "Epoch 2482/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0696 - acc: 0.9719 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2483/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0689 - acc: 0.9715 - val_loss: 0.0869 - val_acc: 0.9677\n",
            "Epoch 2484/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0707 - acc: 0.9714 - val_loss: 0.0940 - val_acc: 0.9652\n",
            "Epoch 2485/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0727 - acc: 0.9694 - val_loss: 0.0879 - val_acc: 0.9691\n",
            "Epoch 2486/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0738 - acc: 0.9703 - val_loss: 0.0887 - val_acc: 0.9691\n",
            "Epoch 2487/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0664 - acc: 0.9719 - val_loss: 0.0897 - val_acc: 0.9672\n",
            "Epoch 2488/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9717 - val_loss: 0.0989 - val_acc: 0.9667\n",
            "Epoch 2489/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0710 - acc: 0.9705 - val_loss: 0.0886 - val_acc: 0.9706\n",
            "Epoch 2490/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0711 - acc: 0.9703 - val_loss: 0.0905 - val_acc: 0.9682\n",
            "Epoch 2491/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0685 - acc: 0.9714 - val_loss: 0.0888 - val_acc: 0.9691\n",
            "Epoch 2492/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0702 - acc: 0.9717 - val_loss: 0.0913 - val_acc: 0.9672\n",
            "Epoch 2493/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0724 - acc: 0.9701 - val_loss: 0.0897 - val_acc: 0.9696\n",
            "Epoch 2494/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0721 - acc: 0.9716 - val_loss: 0.0949 - val_acc: 0.9687\n",
            "Epoch 2495/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0689 - acc: 0.9724 - val_loss: 0.0927 - val_acc: 0.9657\n",
            "Epoch 2496/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0706 - acc: 0.9711 - val_loss: 0.0997 - val_acc: 0.9677\n",
            "Epoch 2497/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0723 - acc: 0.9711 - val_loss: 0.0893 - val_acc: 0.9691\n",
            "Epoch 2498/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0695 - acc: 0.9704 - val_loss: 0.0864 - val_acc: 0.9701\n",
            "Epoch 2499/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0663 - acc: 0.9724 - val_loss: 0.0903 - val_acc: 0.9682\n",
            "Epoch 2500/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0682 - acc: 0.9711 - val_loss: 0.0916 - val_acc: 0.9682\n",
            "Epoch 2501/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0695 - acc: 0.9719 - val_loss: 0.0978 - val_acc: 0.9652\n",
            "Epoch 2502/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0662 - acc: 0.9728 - val_loss: 0.0921 - val_acc: 0.9657\n",
            "Epoch 2503/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0707 - acc: 0.9711 - val_loss: 0.0960 - val_acc: 0.9633\n",
            "Epoch 2504/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0703 - acc: 0.9719 - val_loss: 0.0869 - val_acc: 0.9721\n",
            "Epoch 2505/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0661 - acc: 0.9720 - val_loss: 0.0935 - val_acc: 0.9687\n",
            "Epoch 2506/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9723 - val_loss: 0.0853 - val_acc: 0.9687\n",
            "Epoch 2507/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9713 - val_loss: 0.0916 - val_acc: 0.9677\n",
            "Epoch 2508/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0680 - acc: 0.9712 - val_loss: 0.0906 - val_acc: 0.9696\n",
            "Epoch 2509/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0677 - acc: 0.9715 - val_loss: 0.0907 - val_acc: 0.9682\n",
            "Epoch 2510/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0691 - acc: 0.9719 - val_loss: 0.0917 - val_acc: 0.9667\n",
            "Epoch 2511/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0700 - acc: 0.9708 - val_loss: 0.0877 - val_acc: 0.9667\n",
            "Epoch 2512/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0682 - acc: 0.9711 - val_loss: 0.0853 - val_acc: 0.9691\n",
            "Epoch 2513/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0678 - acc: 0.9704 - val_loss: 0.0961 - val_acc: 0.9667\n",
            "Epoch 2514/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0731 - acc: 0.9695 - val_loss: 0.0853 - val_acc: 0.9682\n",
            "Epoch 2515/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0700 - acc: 0.9716 - val_loss: 0.0830 - val_acc: 0.9726\n",
            "Epoch 2516/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0728 - acc: 0.9692 - val_loss: 0.0892 - val_acc: 0.9691\n",
            "Epoch 2517/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0695 - acc: 0.9714 - val_loss: 0.0941 - val_acc: 0.9657\n",
            "Epoch 2518/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0677 - acc: 0.9716 - val_loss: 0.0865 - val_acc: 0.9716\n",
            "Epoch 2519/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9716 - val_loss: 0.0940 - val_acc: 0.9696\n",
            "Epoch 2520/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0696 - acc: 0.9697 - val_loss: 0.1010 - val_acc: 0.9672\n",
            "Epoch 2521/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0673 - acc: 0.9723 - val_loss: 0.0916 - val_acc: 0.9682\n",
            "Epoch 2522/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0676 - acc: 0.9722 - val_loss: 0.0933 - val_acc: 0.9672\n",
            "Epoch 2523/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0674 - acc: 0.9725 - val_loss: 0.0942 - val_acc: 0.9662\n",
            "Epoch 2524/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0703 - acc: 0.9717 - val_loss: 0.0949 - val_acc: 0.9672\n",
            "Epoch 2525/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0705 - acc: 0.9703 - val_loss: 0.0974 - val_acc: 0.9657\n",
            "Epoch 2526/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0712 - acc: 0.9709 - val_loss: 0.0911 - val_acc: 0.9687\n",
            "Epoch 2527/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0697 - acc: 0.9714 - val_loss: 0.0937 - val_acc: 0.9672\n",
            "Epoch 2528/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9706 - val_loss: 0.0930 - val_acc: 0.9677\n",
            "Epoch 2529/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0689 - acc: 0.9697 - val_loss: 0.0903 - val_acc: 0.9662\n",
            "Epoch 2530/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9724 - val_loss: 0.0973 - val_acc: 0.9662\n",
            "Epoch 2531/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0661 - acc: 0.9737 - val_loss: 0.0956 - val_acc: 0.9677\n",
            "Epoch 2532/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0703 - acc: 0.9695 - val_loss: 0.0888 - val_acc: 0.9687\n",
            "Epoch 2533/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0683 - acc: 0.9711 - val_loss: 0.0849 - val_acc: 0.9691\n",
            "Epoch 2534/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0733 - acc: 0.9690 - val_loss: 0.0931 - val_acc: 0.9687\n",
            "Epoch 2535/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0699 - acc: 0.9722 - val_loss: 0.0903 - val_acc: 0.9696\n",
            "Epoch 2536/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0739 - acc: 0.9687 - val_loss: 0.0912 - val_acc: 0.9647\n",
            "Epoch 2537/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0719 - acc: 0.9707 - val_loss: 0.0876 - val_acc: 0.9696\n",
            "Epoch 2538/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0699 - acc: 0.9696 - val_loss: 0.0928 - val_acc: 0.9672\n",
            "Epoch 2539/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0668 - acc: 0.9727 - val_loss: 0.0997 - val_acc: 0.9672\n",
            "Epoch 2540/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0705 - acc: 0.9705 - val_loss: 0.0912 - val_acc: 0.9662\n",
            "Epoch 2541/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0714 - acc: 0.9706 - val_loss: 0.0890 - val_acc: 0.9677\n",
            "Epoch 2542/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9701 - val_loss: 0.0871 - val_acc: 0.9687\n",
            "Epoch 2543/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0725 - acc: 0.9701 - val_loss: 0.0922 - val_acc: 0.9682\n",
            "Epoch 2544/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0674 - acc: 0.9704 - val_loss: 0.0938 - val_acc: 0.9682\n",
            "Epoch 2545/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0756 - acc: 0.9664 - val_loss: 0.0960 - val_acc: 0.9662\n",
            "Epoch 2546/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0692 - acc: 0.9708 - val_loss: 0.0959 - val_acc: 0.9652\n",
            "Epoch 2547/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0681 - acc: 0.9728 - val_loss: 0.1075 - val_acc: 0.9638\n",
            "Epoch 2548/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0639 - acc: 0.9728 - val_loss: 0.0905 - val_acc: 0.9682\n",
            "Epoch 2549/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0697 - acc: 0.9703 - val_loss: 0.0901 - val_acc: 0.9672\n",
            "Epoch 2550/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0687 - acc: 0.9717 - val_loss: 0.0964 - val_acc: 0.9691\n",
            "Epoch 2551/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0713 - acc: 0.9720 - val_loss: 0.0845 - val_acc: 0.9716\n",
            "Epoch 2552/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0695 - acc: 0.9712 - val_loss: 0.0818 - val_acc: 0.9736\n",
            "Epoch 2553/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9709 - val_loss: 0.0891 - val_acc: 0.9701\n",
            "Epoch 2554/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0645 - acc: 0.9717 - val_loss: 0.0899 - val_acc: 0.9662\n",
            "Epoch 2555/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0699 - acc: 0.9698 - val_loss: 0.0860 - val_acc: 0.9711\n",
            "Epoch 2556/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0683 - acc: 0.9720 - val_loss: 0.0867 - val_acc: 0.9691\n",
            "Epoch 2557/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0675 - acc: 0.9715 - val_loss: 0.0880 - val_acc: 0.9696\n",
            "Epoch 2558/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0674 - acc: 0.9726 - val_loss: 0.0869 - val_acc: 0.9716\n",
            "Epoch 2559/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0672 - acc: 0.9720 - val_loss: 0.0864 - val_acc: 0.9687\n",
            "Epoch 2560/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0654 - acc: 0.9742 - val_loss: 0.0871 - val_acc: 0.9691\n",
            "Epoch 2561/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0669 - acc: 0.9722 - val_loss: 0.0883 - val_acc: 0.9687\n",
            "Epoch 2562/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0698 - acc: 0.9711 - val_loss: 0.0863 - val_acc: 0.9726\n",
            "Epoch 2563/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0692 - acc: 0.9720 - val_loss: 0.0851 - val_acc: 0.9691\n",
            "Epoch 2564/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0648 - acc: 0.9749 - val_loss: 0.0846 - val_acc: 0.9706\n",
            "Epoch 2565/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0712 - acc: 0.9704 - val_loss: 0.0872 - val_acc: 0.9696\n",
            "Epoch 2566/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0679 - acc: 0.9716 - val_loss: 0.1009 - val_acc: 0.9608\n",
            "Epoch 2567/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9739 - val_loss: 0.0900 - val_acc: 0.9687\n",
            "Epoch 2568/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0719 - acc: 0.9698 - val_loss: 0.0982 - val_acc: 0.9687\n",
            "Epoch 2569/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0677 - acc: 0.9709 - val_loss: 0.0990 - val_acc: 0.9657\n",
            "Epoch 2570/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0694 - acc: 0.9710 - val_loss: 0.0843 - val_acc: 0.9696\n",
            "Epoch 2571/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0711 - acc: 0.9701 - val_loss: 0.1039 - val_acc: 0.9594\n",
            "Epoch 2572/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0687 - acc: 0.9704 - val_loss: 0.0865 - val_acc: 0.9696\n",
            "Epoch 2573/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0685 - acc: 0.9701 - val_loss: 0.0919 - val_acc: 0.9687\n",
            "Epoch 2574/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0729 - acc: 0.9703 - val_loss: 0.0909 - val_acc: 0.9691\n",
            "Epoch 2575/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0716 - acc: 0.9708 - val_loss: 0.0911 - val_acc: 0.9691\n",
            "Epoch 2576/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0670 - acc: 0.9727 - val_loss: 0.0897 - val_acc: 0.9682\n",
            "Epoch 2577/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0707 - acc: 0.9703 - val_loss: 0.0904 - val_acc: 0.9682\n",
            "Epoch 2578/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0695 - acc: 0.9714 - val_loss: 0.0896 - val_acc: 0.9682\n",
            "Epoch 2579/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0669 - acc: 0.9728 - val_loss: 0.0867 - val_acc: 0.9701\n",
            "Epoch 2580/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9714 - val_loss: 0.0987 - val_acc: 0.9643\n",
            "Epoch 2581/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0701 - acc: 0.9719 - val_loss: 0.0922 - val_acc: 0.9662\n",
            "Epoch 2582/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0663 - acc: 0.9723 - val_loss: 0.0857 - val_acc: 0.9691\n",
            "Epoch 2583/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0653 - acc: 0.9722 - val_loss: 0.0854 - val_acc: 0.9711\n",
            "Epoch 2584/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0708 - acc: 0.9720 - val_loss: 0.0907 - val_acc: 0.9696\n",
            "Epoch 2585/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0698 - acc: 0.9717 - val_loss: 0.0867 - val_acc: 0.9716\n",
            "Epoch 2586/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9736 - val_loss: 0.0825 - val_acc: 0.9726\n",
            "Epoch 2587/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9720 - val_loss: 0.0928 - val_acc: 0.9696\n",
            "Epoch 2588/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0671 - acc: 0.9717 - val_loss: 0.0893 - val_acc: 0.9701\n",
            "Epoch 2589/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9730 - val_loss: 0.0928 - val_acc: 0.9657\n",
            "Epoch 2590/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0685 - acc: 0.9708 - val_loss: 0.0977 - val_acc: 0.9623\n",
            "Epoch 2591/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0675 - acc: 0.9703 - val_loss: 0.0952 - val_acc: 0.9667\n",
            "Epoch 2592/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9747 - val_loss: 0.0878 - val_acc: 0.9696\n",
            "Epoch 2593/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0678 - acc: 0.9726 - val_loss: 0.0939 - val_acc: 0.9667\n",
            "Epoch 2594/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9745 - val_loss: 0.0955 - val_acc: 0.9662\n",
            "Epoch 2595/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0629 - acc: 0.9754 - val_loss: 0.0919 - val_acc: 0.9677\n",
            "Epoch 2596/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9726 - val_loss: 0.0813 - val_acc: 0.9716\n",
            "Epoch 2597/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0702 - acc: 0.9722 - val_loss: 0.0932 - val_acc: 0.9711\n",
            "Epoch 2598/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0690 - acc: 0.9715 - val_loss: 0.0925 - val_acc: 0.9672\n",
            "Epoch 2599/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0653 - acc: 0.9730 - val_loss: 0.0957 - val_acc: 0.9657\n",
            "Epoch 2600/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0699 - acc: 0.9705 - val_loss: 0.1074 - val_acc: 0.9613\n",
            "Epoch 2601/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0677 - acc: 0.9717 - val_loss: 0.0901 - val_acc: 0.9706\n",
            "Epoch 2602/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0685 - acc: 0.9720 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2603/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0694 - acc: 0.9725 - val_loss: 0.0853 - val_acc: 0.9672\n",
            "Epoch 2604/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0673 - acc: 0.9712 - val_loss: 0.0956 - val_acc: 0.9667\n",
            "Epoch 2605/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9724 - val_loss: 0.0845 - val_acc: 0.9716\n",
            "Epoch 2606/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0705 - acc: 0.9702 - val_loss: 0.0878 - val_acc: 0.9687\n",
            "Epoch 2607/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0712 - acc: 0.9717 - val_loss: 0.0893 - val_acc: 0.9672\n",
            "Epoch 2608/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0652 - acc: 0.9731 - val_loss: 0.0847 - val_acc: 0.9672\n",
            "Epoch 2609/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9736 - val_loss: 0.0897 - val_acc: 0.9672\n",
            "Epoch 2610/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0689 - acc: 0.9714 - val_loss: 0.0862 - val_acc: 0.9711\n",
            "Epoch 2611/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0691 - acc: 0.9723 - val_loss: 0.0877 - val_acc: 0.9687\n",
            "Epoch 2612/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0691 - acc: 0.9722 - val_loss: 0.0904 - val_acc: 0.9677\n",
            "Epoch 2613/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9731 - val_loss: 0.0942 - val_acc: 0.9682\n",
            "Epoch 2614/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9708 - val_loss: 0.0961 - val_acc: 0.9672\n",
            "Epoch 2615/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0690 - acc: 0.9722 - val_loss: 0.0899 - val_acc: 0.9731\n",
            "Epoch 2616/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0693 - acc: 0.9709 - val_loss: 0.0840 - val_acc: 0.9726\n",
            "Epoch 2617/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0656 - acc: 0.9724 - val_loss: 0.0873 - val_acc: 0.9691\n",
            "Epoch 2618/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0663 - acc: 0.9734 - val_loss: 0.0887 - val_acc: 0.9721\n",
            "Epoch 2619/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0657 - acc: 0.9736 - val_loss: 0.0882 - val_acc: 0.9721\n",
            "Epoch 2620/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0677 - acc: 0.9716 - val_loss: 0.0898 - val_acc: 0.9696\n",
            "Epoch 2621/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0672 - acc: 0.9726 - val_loss: 0.0925 - val_acc: 0.9691\n",
            "Epoch 2622/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0667 - acc: 0.9727 - val_loss: 0.1055 - val_acc: 0.9608\n",
            "Epoch 2623/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0672 - acc: 0.9722 - val_loss: 0.0894 - val_acc: 0.9706\n",
            "Epoch 2624/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0667 - acc: 0.9732 - val_loss: 0.0905 - val_acc: 0.9677\n",
            "Epoch 2625/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0679 - acc: 0.9725 - val_loss: 0.0891 - val_acc: 0.9696\n",
            "Epoch 2626/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0674 - acc: 0.9722 - val_loss: 0.0910 - val_acc: 0.9691\n",
            "Epoch 2627/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0658 - acc: 0.9730 - val_loss: 0.0922 - val_acc: 0.9672\n",
            "Epoch 2628/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0669 - acc: 0.9719 - val_loss: 0.0914 - val_acc: 0.9701\n",
            "Epoch 2629/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0653 - acc: 0.9722 - val_loss: 0.0887 - val_acc: 0.9706\n",
            "Epoch 2630/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0684 - acc: 0.9709 - val_loss: 0.0916 - val_acc: 0.9662\n",
            "Epoch 2631/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0661 - acc: 0.9733 - val_loss: 0.0905 - val_acc: 0.9691\n",
            "Epoch 2632/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0632 - acc: 0.9734 - val_loss: 0.0859 - val_acc: 0.9687\n",
            "Epoch 2633/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0665 - acc: 0.9727 - val_loss: 0.0883 - val_acc: 0.9652\n",
            "Epoch 2634/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0657 - acc: 0.9743 - val_loss: 0.0901 - val_acc: 0.9687\n",
            "Epoch 2635/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0655 - acc: 0.9732 - val_loss: 0.0881 - val_acc: 0.9682\n",
            "Epoch 2636/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0657 - acc: 0.9730 - val_loss: 0.0867 - val_acc: 0.9726\n",
            "Epoch 2637/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0646 - acc: 0.9735 - val_loss: 0.0878 - val_acc: 0.9701\n",
            "Epoch 2638/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0672 - acc: 0.9723 - val_loss: 0.0867 - val_acc: 0.9701\n",
            "Epoch 2639/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9729 - val_loss: 0.0897 - val_acc: 0.9691\n",
            "Epoch 2640/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0692 - acc: 0.9722 - val_loss: 0.1022 - val_acc: 0.9682\n",
            "Epoch 2641/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0648 - acc: 0.9733 - val_loss: 0.0872 - val_acc: 0.9682\n",
            "Epoch 2642/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0660 - acc: 0.9744 - val_loss: 0.0869 - val_acc: 0.9706\n",
            "Epoch 2643/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0686 - acc: 0.9730 - val_loss: 0.0895 - val_acc: 0.9682\n",
            "Epoch 2644/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0672 - acc: 0.9715 - val_loss: 0.0893 - val_acc: 0.9677\n",
            "Epoch 2645/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0667 - acc: 0.9729 - val_loss: 0.0872 - val_acc: 0.9677\n",
            "Epoch 2646/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0661 - acc: 0.9724 - val_loss: 0.0852 - val_acc: 0.9696\n",
            "Epoch 2647/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0652 - acc: 0.9734 - val_loss: 0.0876 - val_acc: 0.9691\n",
            "Epoch 2648/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0641 - acc: 0.9730 - val_loss: 0.0883 - val_acc: 0.9706\n",
            "Epoch 2649/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0715 - acc: 0.9712 - val_loss: 0.0963 - val_acc: 0.9687\n",
            "Epoch 2650/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0684 - acc: 0.9715 - val_loss: 0.0904 - val_acc: 0.9706\n",
            "Epoch 2651/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0679 - acc: 0.9713 - val_loss: 0.1010 - val_acc: 0.9638\n",
            "Epoch 2652/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0664 - acc: 0.9723 - val_loss: 0.0855 - val_acc: 0.9691\n",
            "Epoch 2653/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0643 - acc: 0.9737 - val_loss: 0.0852 - val_acc: 0.9691\n",
            "Epoch 2654/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0669 - acc: 0.9715 - val_loss: 0.0948 - val_acc: 0.9657\n",
            "Epoch 2655/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0660 - acc: 0.9734 - val_loss: 0.0885 - val_acc: 0.9706\n",
            "Epoch 2656/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0641 - acc: 0.9728 - val_loss: 0.0898 - val_acc: 0.9701\n",
            "Epoch 2657/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0659 - acc: 0.9734 - val_loss: 0.0957 - val_acc: 0.9647\n",
            "Epoch 2658/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0670 - acc: 0.9725 - val_loss: 0.0874 - val_acc: 0.9691\n",
            "Epoch 2659/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0672 - acc: 0.9726 - val_loss: 0.0873 - val_acc: 0.9711\n",
            "Epoch 2660/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0684 - acc: 0.9713 - val_loss: 0.0905 - val_acc: 0.9647\n",
            "Epoch 2661/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0668 - acc: 0.9730 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2662/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0678 - acc: 0.9729 - val_loss: 0.0935 - val_acc: 0.9662\n",
            "Epoch 2663/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0664 - acc: 0.9719 - val_loss: 0.0952 - val_acc: 0.9643\n",
            "Epoch 2664/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0636 - acc: 0.9750 - val_loss: 0.0936 - val_acc: 0.9696\n",
            "Epoch 2665/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0698 - acc: 0.9712 - val_loss: 0.0871 - val_acc: 0.9701\n",
            "Epoch 2666/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0656 - acc: 0.9722 - val_loss: 0.0835 - val_acc: 0.9701\n",
            "Epoch 2667/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0652 - acc: 0.9726 - val_loss: 0.0866 - val_acc: 0.9696\n",
            "Epoch 2668/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0640 - acc: 0.9731 - val_loss: 0.0944 - val_acc: 0.9647\n",
            "Epoch 2669/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0680 - acc: 0.9726 - val_loss: 0.0843 - val_acc: 0.9701\n",
            "Epoch 2670/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0663 - acc: 0.9726 - val_loss: 0.1039 - val_acc: 0.9623\n",
            "Epoch 2671/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0651 - acc: 0.9731 - val_loss: 0.0905 - val_acc: 0.9687\n",
            "Epoch 2672/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0656 - acc: 0.9719 - val_loss: 0.1030 - val_acc: 0.9633\n",
            "Epoch 2673/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0664 - acc: 0.9728 - val_loss: 0.0897 - val_acc: 0.9677\n",
            "Epoch 2674/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0680 - acc: 0.9730 - val_loss: 0.0905 - val_acc: 0.9672\n",
            "Epoch 2675/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9734 - val_loss: 0.0918 - val_acc: 0.9716\n",
            "Epoch 2676/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0693 - acc: 0.9715 - val_loss: 0.0885 - val_acc: 0.9696\n",
            "Epoch 2677/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0670 - acc: 0.9730 - val_loss: 0.0893 - val_acc: 0.9687\n",
            "Epoch 2678/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0670 - acc: 0.9730 - val_loss: 0.1019 - val_acc: 0.9647\n",
            "Epoch 2679/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0641 - acc: 0.9739 - val_loss: 0.0884 - val_acc: 0.9687\n",
            "Epoch 2680/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0662 - acc: 0.9731 - val_loss: 0.0917 - val_acc: 0.9696\n",
            "Epoch 2681/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0649 - acc: 0.9738 - val_loss: 0.0827 - val_acc: 0.9696\n",
            "Epoch 2682/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0654 - acc: 0.9733 - val_loss: 0.0898 - val_acc: 0.9677\n",
            "Epoch 2683/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0667 - acc: 0.9720 - val_loss: 0.0885 - val_acc: 0.9687\n",
            "Epoch 2684/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9734 - val_loss: 0.0999 - val_acc: 0.9638\n",
            "Epoch 2685/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0636 - acc: 0.9748 - val_loss: 0.0943 - val_acc: 0.9657\n",
            "Epoch 2686/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0692 - acc: 0.9711 - val_loss: 0.0928 - val_acc: 0.9682\n",
            "Epoch 2687/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9738 - val_loss: 0.0882 - val_acc: 0.9662\n",
            "Epoch 2688/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0667 - acc: 0.9725 - val_loss: 0.0992 - val_acc: 0.9633\n",
            "Epoch 2689/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0671 - acc: 0.9728 - val_loss: 0.0858 - val_acc: 0.9701\n",
            "Epoch 2690/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0674 - acc: 0.9721 - val_loss: 0.0882 - val_acc: 0.9687\n",
            "Epoch 2691/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0678 - acc: 0.9723 - val_loss: 0.0896 - val_acc: 0.9682\n",
            "Epoch 2692/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0658 - acc: 0.9730 - val_loss: 0.0945 - val_acc: 0.9677\n",
            "Epoch 2693/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0651 - acc: 0.9707 - val_loss: 0.0881 - val_acc: 0.9696\n",
            "Epoch 2694/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0649 - acc: 0.9732 - val_loss: 0.0884 - val_acc: 0.9687\n",
            "Epoch 2695/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0646 - acc: 0.9742 - val_loss: 0.0875 - val_acc: 0.9691\n",
            "Epoch 2696/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0681 - acc: 0.9727 - val_loss: 0.0907 - val_acc: 0.9667\n",
            "Epoch 2697/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0685 - acc: 0.9723 - val_loss: 0.0856 - val_acc: 0.9691\n",
            "Epoch 2698/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0655 - acc: 0.9733 - val_loss: 0.0911 - val_acc: 0.9711\n",
            "Epoch 2699/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0620 - acc: 0.9745 - val_loss: 0.0899 - val_acc: 0.9687\n",
            "Epoch 2700/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0654 - acc: 0.9725 - val_loss: 0.0979 - val_acc: 0.9662\n",
            "Epoch 2701/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0678 - acc: 0.9724 - val_loss: 0.0909 - val_acc: 0.9696\n",
            "Epoch 2702/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0673 - acc: 0.9721 - val_loss: 0.0878 - val_acc: 0.9716\n",
            "Epoch 2703/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0664 - acc: 0.9731 - val_loss: 0.0893 - val_acc: 0.9711\n",
            "Epoch 2704/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0661 - acc: 0.9734 - val_loss: 0.0909 - val_acc: 0.9716\n",
            "Epoch 2705/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9723 - val_loss: 0.0889 - val_acc: 0.9687\n",
            "Epoch 2706/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0648 - acc: 0.9743 - val_loss: 0.0911 - val_acc: 0.9687\n",
            "Epoch 2707/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0674 - acc: 0.9717 - val_loss: 0.1182 - val_acc: 0.9579\n",
            "Epoch 2708/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0671 - acc: 0.9739 - val_loss: 0.0859 - val_acc: 0.9711\n",
            "Epoch 2709/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0670 - acc: 0.9719 - val_loss: 0.0916 - val_acc: 0.9672\n",
            "Epoch 2710/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0659 - acc: 0.9737 - val_loss: 0.0853 - val_acc: 0.9711\n",
            "Epoch 2711/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0640 - acc: 0.9737 - val_loss: 0.0993 - val_acc: 0.9623\n",
            "Epoch 2712/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0691 - acc: 0.9701 - val_loss: 0.0899 - val_acc: 0.9667\n",
            "Epoch 2713/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0644 - acc: 0.9744 - val_loss: 0.0930 - val_acc: 0.9682\n",
            "Epoch 2714/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0657 - acc: 0.9732 - val_loss: 0.0923 - val_acc: 0.9672\n",
            "Epoch 2715/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0661 - acc: 0.9730 - val_loss: 0.1037 - val_acc: 0.9647\n",
            "Epoch 2716/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0643 - acc: 0.9735 - val_loss: 0.0915 - val_acc: 0.9682\n",
            "Epoch 2717/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0660 - acc: 0.9735 - val_loss: 0.0840 - val_acc: 0.9706\n",
            "Epoch 2718/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0663 - acc: 0.9724 - val_loss: 0.0912 - val_acc: 0.9687\n",
            "Epoch 2719/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0662 - acc: 0.9716 - val_loss: 0.0849 - val_acc: 0.9687\n",
            "Epoch 2720/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0615 - acc: 0.9756 - val_loss: 0.0903 - val_acc: 0.9652\n",
            "Epoch 2721/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9731 - val_loss: 0.0860 - val_acc: 0.9736\n",
            "Epoch 2722/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0646 - acc: 0.9738 - val_loss: 0.0834 - val_acc: 0.9696\n",
            "Epoch 2723/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0660 - acc: 0.9723 - val_loss: 0.0963 - val_acc: 0.9672\n",
            "Epoch 2724/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0673 - acc: 0.9726 - val_loss: 0.0940 - val_acc: 0.9657\n",
            "Epoch 2725/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0649 - acc: 0.9741 - val_loss: 0.0876 - val_acc: 0.9726\n",
            "Epoch 2726/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0670 - acc: 0.9728 - val_loss: 0.1048 - val_acc: 0.9657\n",
            "Epoch 2727/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0648 - acc: 0.9742 - val_loss: 0.0978 - val_acc: 0.9643\n",
            "Epoch 2728/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0666 - acc: 0.9736 - val_loss: 0.0839 - val_acc: 0.9691\n",
            "Epoch 2729/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9727 - val_loss: 0.0873 - val_acc: 0.9706\n",
            "Epoch 2730/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0642 - acc: 0.9740 - val_loss: 0.0891 - val_acc: 0.9696\n",
            "Epoch 2731/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9737 - val_loss: 0.0913 - val_acc: 0.9687\n",
            "Epoch 2732/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0670 - acc: 0.9736 - val_loss: 0.0890 - val_acc: 0.9667\n",
            "Epoch 2733/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0637 - acc: 0.9736 - val_loss: 0.0978 - val_acc: 0.9662\n",
            "Epoch 2734/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0653 - acc: 0.9725 - val_loss: 0.0830 - val_acc: 0.9750\n",
            "Epoch 2735/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0647 - acc: 0.9734 - val_loss: 0.0939 - val_acc: 0.9652\n",
            "Epoch 2736/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0632 - acc: 0.9733 - val_loss: 0.0905 - val_acc: 0.9662\n",
            "Epoch 2737/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0643 - acc: 0.9739 - val_loss: 0.0878 - val_acc: 0.9696\n",
            "Epoch 2738/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0631 - acc: 0.9742 - val_loss: 0.0870 - val_acc: 0.9696\n",
            "Epoch 2739/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0676 - acc: 0.9726 - val_loss: 0.1003 - val_acc: 0.9662\n",
            "Epoch 2740/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0652 - acc: 0.9730 - val_loss: 0.0921 - val_acc: 0.9667\n",
            "Epoch 2741/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0628 - acc: 0.9749 - val_loss: 0.0887 - val_acc: 0.9706\n",
            "Epoch 2742/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0629 - acc: 0.9751 - val_loss: 0.0951 - val_acc: 0.9682\n",
            "Epoch 2743/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0684 - acc: 0.9722 - val_loss: 0.0840 - val_acc: 0.9716\n",
            "Epoch 2744/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9733 - val_loss: 0.0902 - val_acc: 0.9662\n",
            "Epoch 2745/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0663 - acc: 0.9725 - val_loss: 0.0920 - val_acc: 0.9682\n",
            "Epoch 2746/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0617 - acc: 0.9746 - val_loss: 0.0952 - val_acc: 0.9657\n",
            "Epoch 2747/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0646 - acc: 0.9733 - val_loss: 0.0898 - val_acc: 0.9701\n",
            "Epoch 2748/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9753 - val_loss: 0.0925 - val_acc: 0.9652\n",
            "Epoch 2749/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0656 - acc: 0.9737 - val_loss: 0.0923 - val_acc: 0.9691\n",
            "Epoch 2750/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0663 - acc: 0.9730 - val_loss: 0.0917 - val_acc: 0.9696\n",
            "Epoch 2751/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0634 - acc: 0.9738 - val_loss: 0.0873 - val_acc: 0.9687\n",
            "Epoch 2752/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0641 - acc: 0.9736 - val_loss: 0.0866 - val_acc: 0.9696\n",
            "Epoch 2753/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0617 - acc: 0.9751 - val_loss: 0.0940 - val_acc: 0.9682\n",
            "Epoch 2754/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0626 - acc: 0.9753 - val_loss: 0.0904 - val_acc: 0.9701\n",
            "Epoch 2755/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0645 - acc: 0.9738 - val_loss: 0.0834 - val_acc: 0.9726\n",
            "Epoch 2756/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0636 - acc: 0.9741 - val_loss: 0.0908 - val_acc: 0.9726\n",
            "Epoch 2757/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9751 - val_loss: 0.0943 - val_acc: 0.9667\n",
            "Epoch 2758/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0646 - acc: 0.9746 - val_loss: 0.0904 - val_acc: 0.9667\n",
            "Epoch 2759/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9736 - val_loss: 0.0898 - val_acc: 0.9682\n",
            "Epoch 2760/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0662 - acc: 0.9732 - val_loss: 0.0871 - val_acc: 0.9711\n",
            "Epoch 2761/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0638 - acc: 0.9742 - val_loss: 0.0975 - val_acc: 0.9667\n",
            "Epoch 2762/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0674 - acc: 0.9726 - val_loss: 0.0902 - val_acc: 0.9691\n",
            "Epoch 2763/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0623 - acc: 0.9739 - val_loss: 0.0882 - val_acc: 0.9667\n",
            "Epoch 2764/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0669 - acc: 0.9734 - val_loss: 0.0847 - val_acc: 0.9701\n",
            "Epoch 2765/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9745 - val_loss: 0.0932 - val_acc: 0.9672\n",
            "Epoch 2766/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9744 - val_loss: 0.0967 - val_acc: 0.9657\n",
            "Epoch 2767/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0675 - acc: 0.9725 - val_loss: 0.0946 - val_acc: 0.9667\n",
            "Epoch 2768/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0671 - acc: 0.9728 - val_loss: 0.0890 - val_acc: 0.9711\n",
            "Epoch 2769/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9749 - val_loss: 0.0875 - val_acc: 0.9691\n",
            "Epoch 2770/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0675 - acc: 0.9722 - val_loss: 0.0940 - val_acc: 0.9652\n",
            "Epoch 2771/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0643 - acc: 0.9730 - val_loss: 0.0873 - val_acc: 0.9667\n",
            "Epoch 2772/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9751 - val_loss: 0.0869 - val_acc: 0.9672\n",
            "Epoch 2773/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0626 - acc: 0.9748 - val_loss: 0.0872 - val_acc: 0.9711\n",
            "Epoch 2774/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0622 - acc: 0.9753 - val_loss: 0.0887 - val_acc: 0.9677\n",
            "Epoch 2775/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0660 - acc: 0.9724 - val_loss: 0.0850 - val_acc: 0.9726\n",
            "Epoch 2776/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0641 - acc: 0.9737 - val_loss: 0.0862 - val_acc: 0.9716\n",
            "Epoch 2777/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0609 - acc: 0.9747 - val_loss: 0.0820 - val_acc: 0.9740\n",
            "Epoch 2778/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0641 - acc: 0.9734 - val_loss: 0.0843 - val_acc: 0.9716\n",
            "Epoch 2779/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0639 - acc: 0.9742 - val_loss: 0.0926 - val_acc: 0.9672\n",
            "Epoch 2780/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0659 - acc: 0.9730 - val_loss: 0.0864 - val_acc: 0.9677\n",
            "Epoch 2781/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0655 - acc: 0.9744 - val_loss: 0.0897 - val_acc: 0.9706\n",
            "Epoch 2782/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0665 - acc: 0.9720 - val_loss: 0.0946 - val_acc: 0.9672\n",
            "Epoch 2783/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0655 - acc: 0.9733 - val_loss: 0.0922 - val_acc: 0.9691\n",
            "Epoch 2784/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0645 - acc: 0.9737 - val_loss: 0.0880 - val_acc: 0.9687\n",
            "Epoch 2785/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0639 - acc: 0.9747 - val_loss: 0.0918 - val_acc: 0.9691\n",
            "Epoch 2786/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0698 - acc: 0.9728 - val_loss: 0.0883 - val_acc: 0.9691\n",
            "Epoch 2787/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0674 - acc: 0.9724 - val_loss: 0.0956 - val_acc: 0.9608\n",
            "Epoch 2788/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0662 - acc: 0.9732 - val_loss: 0.0923 - val_acc: 0.9687\n",
            "Epoch 2789/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0626 - acc: 0.9741 - val_loss: 0.0898 - val_acc: 0.9667\n",
            "Epoch 2790/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0633 - acc: 0.9742 - val_loss: 0.0942 - val_acc: 0.9691\n",
            "Epoch 2791/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0633 - acc: 0.9745 - val_loss: 0.0833 - val_acc: 0.9716\n",
            "Epoch 2792/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0675 - acc: 0.9711 - val_loss: 0.0930 - val_acc: 0.9662\n",
            "Epoch 2793/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0619 - acc: 0.9747 - val_loss: 0.0884 - val_acc: 0.9687\n",
            "Epoch 2794/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0599 - acc: 0.9763 - val_loss: 0.0840 - val_acc: 0.9711\n",
            "Epoch 2795/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0664 - acc: 0.9730 - val_loss: 0.0927 - val_acc: 0.9667\n",
            "Epoch 2796/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0682 - acc: 0.9726 - val_loss: 0.0908 - val_acc: 0.9677\n",
            "Epoch 2797/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0681 - acc: 0.9719 - val_loss: 0.1024 - val_acc: 0.9657\n",
            "Epoch 2798/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0631 - acc: 0.9739 - val_loss: 0.0867 - val_acc: 0.9716\n",
            "Epoch 2799/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0645 - acc: 0.9732 - val_loss: 0.0948 - val_acc: 0.9657\n",
            "Epoch 2800/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0620 - acc: 0.9758 - val_loss: 0.0954 - val_acc: 0.9672\n",
            "Epoch 2801/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9728 - val_loss: 0.0869 - val_acc: 0.9706\n",
            "Epoch 2802/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0623 - acc: 0.9742 - val_loss: 0.0901 - val_acc: 0.9696\n",
            "Epoch 2803/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0676 - acc: 0.9714 - val_loss: 0.0943 - val_acc: 0.9672\n",
            "Epoch 2804/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0655 - acc: 0.9729 - val_loss: 0.0967 - val_acc: 0.9677\n",
            "Epoch 2805/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0655 - acc: 0.9728 - val_loss: 0.0891 - val_acc: 0.9721\n",
            "Epoch 2806/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0634 - acc: 0.9752 - val_loss: 0.0925 - val_acc: 0.9662\n",
            "Epoch 2807/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0627 - acc: 0.9741 - val_loss: 0.0852 - val_acc: 0.9731\n",
            "Epoch 2808/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0629 - acc: 0.9740 - val_loss: 0.0829 - val_acc: 0.9691\n",
            "Epoch 2809/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0647 - acc: 0.9733 - val_loss: 0.0943 - val_acc: 0.9662\n",
            "Epoch 2810/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0660 - acc: 0.9730 - val_loss: 0.0914 - val_acc: 0.9706\n",
            "Epoch 2811/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0654 - acc: 0.9730 - val_loss: 0.0905 - val_acc: 0.9701\n",
            "Epoch 2812/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0646 - acc: 0.9742 - val_loss: 0.0930 - val_acc: 0.9687\n",
            "Epoch 2813/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0599 - acc: 0.9756 - val_loss: 0.0890 - val_acc: 0.9726\n",
            "Epoch 2814/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0610 - acc: 0.9749 - val_loss: 0.0889 - val_acc: 0.9706\n",
            "Epoch 2815/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0622 - acc: 0.9751 - val_loss: 0.0845 - val_acc: 0.9716\n",
            "Epoch 2816/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0612 - acc: 0.9754 - val_loss: 0.0851 - val_acc: 0.9726\n",
            "Epoch 2817/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0642 - acc: 0.9742 - val_loss: 0.0947 - val_acc: 0.9687\n",
            "Epoch 2818/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0643 - acc: 0.9742 - val_loss: 0.0923 - val_acc: 0.9667\n",
            "Epoch 2819/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0660 - acc: 0.9724 - val_loss: 0.0891 - val_acc: 0.9677\n",
            "Epoch 2820/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0609 - acc: 0.9752 - val_loss: 0.0827 - val_acc: 0.9731\n",
            "Epoch 2821/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9749 - val_loss: 0.0894 - val_acc: 0.9696\n",
            "Epoch 2822/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0630 - acc: 0.9747 - val_loss: 0.0843 - val_acc: 0.9716\n",
            "Epoch 2823/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0636 - acc: 0.9747 - val_loss: 0.0883 - val_acc: 0.9716\n",
            "Epoch 2824/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0601 - acc: 0.9769 - val_loss: 0.0863 - val_acc: 0.9716\n",
            "Epoch 2825/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0625 - acc: 0.9747 - val_loss: 0.0837 - val_acc: 0.9711\n",
            "Epoch 2826/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0646 - acc: 0.9725 - val_loss: 0.0887 - val_acc: 0.9691\n",
            "Epoch 2827/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0623 - acc: 0.9754 - val_loss: 0.0908 - val_acc: 0.9701\n",
            "Epoch 2828/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0645 - acc: 0.9733 - val_loss: 0.0789 - val_acc: 0.9726\n",
            "Epoch 2829/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0627 - acc: 0.9745 - val_loss: 0.0964 - val_acc: 0.9628\n",
            "Epoch 2830/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0621 - acc: 0.9753 - val_loss: 0.0860 - val_acc: 0.9667\n",
            "Epoch 2831/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0629 - acc: 0.9734 - val_loss: 0.0853 - val_acc: 0.9731\n",
            "Epoch 2832/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0621 - acc: 0.9752 - val_loss: 0.0867 - val_acc: 0.9706\n",
            "Epoch 2833/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0631 - acc: 0.9742 - val_loss: 0.0841 - val_acc: 0.9706\n",
            "Epoch 2834/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0593 - acc: 0.9760 - val_loss: 0.0902 - val_acc: 0.9711\n",
            "Epoch 2835/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0615 - acc: 0.9750 - val_loss: 0.0878 - val_acc: 0.9701\n",
            "Epoch 2836/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0586 - acc: 0.9761 - val_loss: 0.0832 - val_acc: 0.9750\n",
            "Epoch 2837/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0633 - acc: 0.9726 - val_loss: 0.0981 - val_acc: 0.9677\n",
            "Epoch 2838/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0634 - acc: 0.9737 - val_loss: 0.0863 - val_acc: 0.9711\n",
            "Epoch 2839/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0635 - acc: 0.9734 - val_loss: 0.0841 - val_acc: 0.9706\n",
            "Epoch 2840/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0623 - acc: 0.9736 - val_loss: 0.0924 - val_acc: 0.9687\n",
            "Epoch 2841/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0622 - acc: 0.9757 - val_loss: 0.0884 - val_acc: 0.9726\n",
            "Epoch 2842/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0656 - acc: 0.9742 - val_loss: 0.1002 - val_acc: 0.9647\n",
            "Epoch 2843/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0643 - acc: 0.9749 - val_loss: 0.0824 - val_acc: 0.9711\n",
            "Epoch 2844/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0630 - acc: 0.9758 - val_loss: 0.0837 - val_acc: 0.9731\n",
            "Epoch 2845/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0590 - acc: 0.9741 - val_loss: 0.0861 - val_acc: 0.9701\n",
            "Epoch 2846/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0611 - acc: 0.9752 - val_loss: 0.0875 - val_acc: 0.9687\n",
            "Epoch 2847/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0652 - acc: 0.9734 - val_loss: 0.0832 - val_acc: 0.9706\n",
            "Epoch 2848/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0619 - acc: 0.9761 - val_loss: 0.0854 - val_acc: 0.9706\n",
            "Epoch 2849/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0640 - acc: 0.9756 - val_loss: 0.0917 - val_acc: 0.9667\n",
            "Epoch 2850/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0599 - acc: 0.9751 - val_loss: 0.0869 - val_acc: 0.9691\n",
            "Epoch 2851/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9749 - val_loss: 0.0861 - val_acc: 0.9687\n",
            "Epoch 2852/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9761 - val_loss: 0.0868 - val_acc: 0.9716\n",
            "Epoch 2853/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9737 - val_loss: 0.0893 - val_acc: 0.9691\n",
            "Epoch 2854/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0616 - acc: 0.9757 - val_loss: 0.0878 - val_acc: 0.9706\n",
            "Epoch 2855/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0661 - acc: 0.9730 - val_loss: 0.0870 - val_acc: 0.9736\n",
            "Epoch 2856/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0650 - acc: 0.9742 - val_loss: 0.0950 - val_acc: 0.9677\n",
            "Epoch 2857/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0664 - acc: 0.9719 - val_loss: 0.0928 - val_acc: 0.9657\n",
            "Epoch 2858/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0650 - acc: 0.9734 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 2859/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0635 - acc: 0.9763 - val_loss: 0.0900 - val_acc: 0.9662\n",
            "Epoch 2860/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0645 - acc: 0.9724 - val_loss: 0.0913 - val_acc: 0.9687\n",
            "Epoch 2861/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0677 - acc: 0.9717 - val_loss: 0.0879 - val_acc: 0.9662\n",
            "Epoch 2862/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0645 - acc: 0.9743 - val_loss: 0.0954 - val_acc: 0.9672\n",
            "Epoch 2863/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0632 - acc: 0.9744 - val_loss: 0.0853 - val_acc: 0.9706\n",
            "Epoch 2864/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9738 - val_loss: 0.0849 - val_acc: 0.9657\n",
            "Epoch 2865/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9751 - val_loss: 0.0835 - val_acc: 0.9726\n",
            "Epoch 2866/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0636 - acc: 0.9736 - val_loss: 0.0863 - val_acc: 0.9677\n",
            "Epoch 2867/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9750 - val_loss: 0.0907 - val_acc: 0.9662\n",
            "Epoch 2868/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0631 - acc: 0.9738 - val_loss: 0.0919 - val_acc: 0.9672\n",
            "Epoch 2869/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0628 - acc: 0.9744 - val_loss: 0.0814 - val_acc: 0.9745\n",
            "Epoch 2870/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0623 - acc: 0.9741 - val_loss: 0.1018 - val_acc: 0.9662\n",
            "Epoch 2871/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0640 - acc: 0.9742 - val_loss: 0.0850 - val_acc: 0.9740\n",
            "Epoch 2872/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9750 - val_loss: 0.1246 - val_acc: 0.9569\n",
            "Epoch 2873/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0647 - acc: 0.9728 - val_loss: 0.0869 - val_acc: 0.9682\n",
            "Epoch 2874/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0642 - acc: 0.9734 - val_loss: 0.0845 - val_acc: 0.9726\n",
            "Epoch 2875/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0667 - acc: 0.9723 - val_loss: 0.0871 - val_acc: 0.9662\n",
            "Epoch 2876/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0587 - acc: 0.9760 - val_loss: 0.0879 - val_acc: 0.9652\n",
            "Epoch 2877/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0602 - acc: 0.9752 - val_loss: 0.0875 - val_acc: 0.9696\n",
            "Epoch 2878/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0625 - acc: 0.9744 - val_loss: 0.0882 - val_acc: 0.9687\n",
            "Epoch 2879/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0612 - acc: 0.9750 - val_loss: 0.0874 - val_acc: 0.9691\n",
            "Epoch 2880/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0645 - acc: 0.9747 - val_loss: 0.0829 - val_acc: 0.9701\n",
            "Epoch 2881/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9753 - val_loss: 0.0843 - val_acc: 0.9706\n",
            "Epoch 2882/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0598 - acc: 0.9758 - val_loss: 0.0918 - val_acc: 0.9716\n",
            "Epoch 2883/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0652 - acc: 0.9726 - val_loss: 0.0806 - val_acc: 0.9721\n",
            "Epoch 2884/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0585 - acc: 0.9775 - val_loss: 0.0880 - val_acc: 0.9687\n",
            "Epoch 2885/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9759 - val_loss: 0.0840 - val_acc: 0.9721\n",
            "Epoch 2886/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9762 - val_loss: 0.0870 - val_acc: 0.9706\n",
            "Epoch 2887/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0627 - acc: 0.9734 - val_loss: 0.0858 - val_acc: 0.9711\n",
            "Epoch 2888/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0580 - acc: 0.9763 - val_loss: 0.0951 - val_acc: 0.9677\n",
            "Epoch 2889/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0622 - acc: 0.9760 - val_loss: 0.0973 - val_acc: 0.9657\n",
            "Epoch 2890/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0633 - acc: 0.9742 - val_loss: 0.0961 - val_acc: 0.9701\n",
            "Epoch 2891/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0618 - acc: 0.9742 - val_loss: 0.0914 - val_acc: 0.9652\n",
            "Epoch 2892/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0654 - acc: 0.9741 - val_loss: 0.0871 - val_acc: 0.9721\n",
            "Epoch 2893/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0618 - acc: 0.9748 - val_loss: 0.0935 - val_acc: 0.9628\n",
            "Epoch 2894/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9747 - val_loss: 0.0907 - val_acc: 0.9647\n",
            "Epoch 2895/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0639 - acc: 0.9739 - val_loss: 0.0934 - val_acc: 0.9667\n",
            "Epoch 2896/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0634 - acc: 0.9737 - val_loss: 0.0885 - val_acc: 0.9677\n",
            "Epoch 2897/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0611 - acc: 0.9753 - val_loss: 0.0852 - val_acc: 0.9696\n",
            "Epoch 2898/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0613 - acc: 0.9739 - val_loss: 0.0967 - val_acc: 0.9662\n",
            "Epoch 2899/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0631 - acc: 0.9744 - val_loss: 0.0957 - val_acc: 0.9677\n",
            "Epoch 2900/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9765 - val_loss: 0.0906 - val_acc: 0.9696\n",
            "Epoch 2901/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0605 - acc: 0.9745 - val_loss: 0.0804 - val_acc: 0.9740\n",
            "Epoch 2902/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0624 - acc: 0.9752 - val_loss: 0.0944 - val_acc: 0.9667\n",
            "Epoch 2903/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0626 - acc: 0.9734 - val_loss: 0.0896 - val_acc: 0.9731\n",
            "Epoch 2904/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0640 - acc: 0.9740 - val_loss: 0.0905 - val_acc: 0.9701\n",
            "Epoch 2905/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9750 - val_loss: 0.0915 - val_acc: 0.9721\n",
            "Epoch 2906/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0623 - acc: 0.9730 - val_loss: 0.1015 - val_acc: 0.9623\n",
            "Epoch 2907/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0626 - acc: 0.9758 - val_loss: 0.0911 - val_acc: 0.9677\n",
            "Epoch 2908/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0605 - acc: 0.9752 - val_loss: 0.0907 - val_acc: 0.9662\n",
            "Epoch 2909/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0612 - acc: 0.9753 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 2910/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9757 - val_loss: 0.0957 - val_acc: 0.9667\n",
            "Epoch 2911/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0626 - acc: 0.9740 - val_loss: 0.0837 - val_acc: 0.9726\n",
            "Epoch 2912/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0627 - acc: 0.9746 - val_loss: 0.0932 - val_acc: 0.9682\n",
            "Epoch 2913/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0620 - acc: 0.9745 - val_loss: 0.0995 - val_acc: 0.9647\n",
            "Epoch 2914/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0640 - acc: 0.9754 - val_loss: 0.0970 - val_acc: 0.9687\n",
            "Epoch 2915/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9760 - val_loss: 0.0929 - val_acc: 0.9691\n",
            "Epoch 2916/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9752 - val_loss: 0.0868 - val_acc: 0.9691\n",
            "Epoch 2917/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0597 - acc: 0.9756 - val_loss: 0.0916 - val_acc: 0.9677\n",
            "Epoch 2918/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0615 - acc: 0.9747 - val_loss: 0.0886 - val_acc: 0.9691\n",
            "Epoch 2919/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0618 - acc: 0.9746 - val_loss: 0.0908 - val_acc: 0.9682\n",
            "Epoch 2920/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0636 - acc: 0.9747 - val_loss: 0.0887 - val_acc: 0.9701\n",
            "Epoch 2921/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9749 - val_loss: 0.0887 - val_acc: 0.9682\n",
            "Epoch 2922/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0594 - acc: 0.9758 - val_loss: 0.0880 - val_acc: 0.9691\n",
            "Epoch 2923/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0619 - acc: 0.9750 - val_loss: 0.0970 - val_acc: 0.9657\n",
            "Epoch 2924/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0603 - acc: 0.9759 - val_loss: 0.0963 - val_acc: 0.9647\n",
            "Epoch 2925/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0654 - acc: 0.9741 - val_loss: 0.0895 - val_acc: 0.9696\n",
            "Epoch 2926/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0610 - acc: 0.9744 - val_loss: 0.0962 - val_acc: 0.9682\n",
            "Epoch 2927/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0595 - acc: 0.9764 - val_loss: 0.0927 - val_acc: 0.9667\n",
            "Epoch 2928/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9753 - val_loss: 0.0911 - val_acc: 0.9682\n",
            "Epoch 2929/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0624 - acc: 0.9753 - val_loss: 0.0824 - val_acc: 0.9740\n",
            "Epoch 2930/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0611 - acc: 0.9754 - val_loss: 0.1066 - val_acc: 0.9638\n",
            "Epoch 2931/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0610 - acc: 0.9741 - val_loss: 0.0899 - val_acc: 0.9691\n",
            "Epoch 2932/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9755 - val_loss: 0.0920 - val_acc: 0.9701\n",
            "Epoch 2933/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0590 - acc: 0.9761 - val_loss: 0.0892 - val_acc: 0.9711\n",
            "Epoch 2934/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9749 - val_loss: 0.0881 - val_acc: 0.9677\n",
            "Epoch 2935/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0627 - acc: 0.9741 - val_loss: 0.0815 - val_acc: 0.9726\n",
            "Epoch 2936/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9755 - val_loss: 0.0840 - val_acc: 0.9711\n",
            "Epoch 2937/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0603 - acc: 0.9746 - val_loss: 0.0947 - val_acc: 0.9667\n",
            "Epoch 2938/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0613 - acc: 0.9762 - val_loss: 0.0869 - val_acc: 0.9711\n",
            "Epoch 2939/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0573 - acc: 0.9780 - val_loss: 0.0833 - val_acc: 0.9750\n",
            "Epoch 2940/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0576 - acc: 0.9771 - val_loss: 0.0919 - val_acc: 0.9677\n",
            "Epoch 2941/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0624 - acc: 0.9745 - val_loss: 0.0883 - val_acc: 0.9691\n",
            "Epoch 2942/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9769 - val_loss: 0.0960 - val_acc: 0.9677\n",
            "Epoch 2943/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0611 - acc: 0.9757 - val_loss: 0.0917 - val_acc: 0.9696\n",
            "Epoch 2944/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9745 - val_loss: 0.0994 - val_acc: 0.9706\n",
            "Epoch 2945/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0621 - acc: 0.9740 - val_loss: 0.0968 - val_acc: 0.9706\n",
            "Epoch 2946/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0604 - acc: 0.9744 - val_loss: 0.0879 - val_acc: 0.9696\n",
            "Epoch 2947/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0603 - acc: 0.9753 - val_loss: 0.0924 - val_acc: 0.9657\n",
            "Epoch 2948/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0612 - acc: 0.9750 - val_loss: 0.0925 - val_acc: 0.9687\n",
            "Epoch 2949/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0598 - acc: 0.9760 - val_loss: 0.0896 - val_acc: 0.9701\n",
            "Epoch 2950/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0605 - acc: 0.9756 - val_loss: 0.0909 - val_acc: 0.9706\n",
            "Epoch 2951/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0603 - acc: 0.9755 - val_loss: 0.0901 - val_acc: 0.9691\n",
            "Epoch 2952/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0604 - acc: 0.9752 - val_loss: 0.0931 - val_acc: 0.9691\n",
            "Epoch 2953/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9760 - val_loss: 0.0950 - val_acc: 0.9667\n",
            "Epoch 2954/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0602 - acc: 0.9758 - val_loss: 0.0903 - val_acc: 0.9706\n",
            "Epoch 2955/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0622 - acc: 0.9755 - val_loss: 0.0944 - val_acc: 0.9657\n",
            "Epoch 2956/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0597 - acc: 0.9755 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 2957/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0613 - acc: 0.9751 - val_loss: 0.0915 - val_acc: 0.9721\n",
            "Epoch 2958/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0607 - acc: 0.9746 - val_loss: 0.0906 - val_acc: 0.9691\n",
            "Epoch 2959/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0614 - acc: 0.9743 - val_loss: 0.0876 - val_acc: 0.9677\n",
            "Epoch 2960/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0614 - acc: 0.9746 - val_loss: 0.0850 - val_acc: 0.9701\n",
            "Epoch 2961/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0604 - acc: 0.9754 - val_loss: 0.0878 - val_acc: 0.9716\n",
            "Epoch 2962/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9765 - val_loss: 0.0863 - val_acc: 0.9677\n",
            "Epoch 2963/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9764 - val_loss: 0.0845 - val_acc: 0.9691\n",
            "Epoch 2964/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9758 - val_loss: 0.0844 - val_acc: 0.9711\n",
            "Epoch 2965/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0611 - acc: 0.9747 - val_loss: 0.0865 - val_acc: 0.9706\n",
            "Epoch 2966/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9753 - val_loss: 0.0807 - val_acc: 0.9755\n",
            "Epoch 2967/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0594 - acc: 0.9789 - val_loss: 0.0841 - val_acc: 0.9706\n",
            "Epoch 2968/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0578 - acc: 0.9774 - val_loss: 0.0810 - val_acc: 0.9736\n",
            "Epoch 2969/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0611 - acc: 0.9750 - val_loss: 0.0880 - val_acc: 0.9696\n",
            "Epoch 2970/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0588 - acc: 0.9775 - val_loss: 0.0915 - val_acc: 0.9682\n",
            "Epoch 2971/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9744 - val_loss: 0.0912 - val_acc: 0.9701\n",
            "Epoch 2972/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0599 - acc: 0.9755 - val_loss: 0.0880 - val_acc: 0.9736\n",
            "Epoch 2973/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0605 - acc: 0.9759 - val_loss: 0.0914 - val_acc: 0.9701\n",
            "Epoch 2974/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0641 - acc: 0.9721 - val_loss: 0.0885 - val_acc: 0.9701\n",
            "Epoch 2975/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9752 - val_loss: 0.0874 - val_acc: 0.9691\n",
            "Epoch 2976/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9787 - val_loss: 0.0878 - val_acc: 0.9706\n",
            "Epoch 2977/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0581 - acc: 0.9763 - val_loss: 0.0978 - val_acc: 0.9667\n",
            "Epoch 2978/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0618 - acc: 0.9760 - val_loss: 0.0842 - val_acc: 0.9726\n",
            "Epoch 2979/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0607 - acc: 0.9749 - val_loss: 0.0940 - val_acc: 0.9657\n",
            "Epoch 2980/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9766 - val_loss: 0.0882 - val_acc: 0.9687\n",
            "Epoch 2981/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0624 - acc: 0.9742 - val_loss: 0.0901 - val_acc: 0.9687\n",
            "Epoch 2982/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9748 - val_loss: 0.0893 - val_acc: 0.9706\n",
            "Epoch 2983/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0589 - acc: 0.9761 - val_loss: 0.0913 - val_acc: 0.9657\n",
            "Epoch 2984/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0559 - acc: 0.9784 - val_loss: 0.0897 - val_acc: 0.9701\n",
            "Epoch 2985/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0596 - acc: 0.9762 - val_loss: 0.0931 - val_acc: 0.9721\n",
            "Epoch 2986/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0588 - acc: 0.9756 - val_loss: 0.0864 - val_acc: 0.9711\n",
            "Epoch 2987/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0616 - acc: 0.9755 - val_loss: 0.0957 - val_acc: 0.9672\n",
            "Epoch 2988/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9766 - val_loss: 0.0979 - val_acc: 0.9682\n",
            "Epoch 2989/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0639 - acc: 0.9737 - val_loss: 0.1052 - val_acc: 0.9598\n",
            "Epoch 2990/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0647 - acc: 0.9742 - val_loss: 0.0868 - val_acc: 0.9706\n",
            "Epoch 2991/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0621 - acc: 0.9738 - val_loss: 0.0858 - val_acc: 0.9716\n",
            "Epoch 2992/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9768 - val_loss: 0.0916 - val_acc: 0.9691\n",
            "Epoch 2993/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0575 - acc: 0.9764 - val_loss: 0.0865 - val_acc: 0.9731\n",
            "Epoch 2994/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0609 - acc: 0.9744 - val_loss: 0.0856 - val_acc: 0.9740\n",
            "Epoch 2995/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9757 - val_loss: 0.0932 - val_acc: 0.9677\n",
            "Epoch 2996/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0583 - acc: 0.9761 - val_loss: 0.0869 - val_acc: 0.9701\n",
            "Epoch 2997/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0632 - acc: 0.9733 - val_loss: 0.0932 - val_acc: 0.9711\n",
            "Epoch 2998/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0561 - acc: 0.9776 - val_loss: 0.0910 - val_acc: 0.9682\n",
            "Epoch 2999/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0582 - acc: 0.9767 - val_loss: 0.0873 - val_acc: 0.9687\n",
            "Epoch 3000/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0575 - acc: 0.9775 - val_loss: 0.0878 - val_acc: 0.9682\n",
            "Epoch 3001/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0648 - acc: 0.9734 - val_loss: 0.0914 - val_acc: 0.9706\n",
            "Epoch 3002/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0618 - acc: 0.9760 - val_loss: 0.0867 - val_acc: 0.9706\n",
            "Epoch 3003/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0605 - acc: 0.9760 - val_loss: 0.0902 - val_acc: 0.9711\n",
            "Epoch 3004/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0605 - acc: 0.9756 - val_loss: 0.0937 - val_acc: 0.9696\n",
            "Epoch 3005/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0635 - acc: 0.9740 - val_loss: 0.0960 - val_acc: 0.9687\n",
            "Epoch 3006/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9750 - val_loss: 0.0914 - val_acc: 0.9687\n",
            "Epoch 3007/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0606 - acc: 0.9754 - val_loss: 0.0917 - val_acc: 0.9687\n",
            "Epoch 3008/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9760 - val_loss: 0.0842 - val_acc: 0.9711\n",
            "Epoch 3009/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0577 - acc: 0.9769 - val_loss: 0.0944 - val_acc: 0.9687\n",
            "Epoch 3010/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0605 - acc: 0.9758 - val_loss: 0.0891 - val_acc: 0.9716\n",
            "Epoch 3011/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0620 - acc: 0.9748 - val_loss: 0.1002 - val_acc: 0.9657\n",
            "Epoch 3012/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0574 - acc: 0.9769 - val_loss: 0.0908 - val_acc: 0.9672\n",
            "Epoch 3013/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0582 - acc: 0.9762 - val_loss: 0.0867 - val_acc: 0.9696\n",
            "Epoch 3014/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0620 - acc: 0.9742 - val_loss: 0.0972 - val_acc: 0.9647\n",
            "Epoch 3015/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0615 - acc: 0.9757 - val_loss: 0.0846 - val_acc: 0.9745\n",
            "Epoch 3016/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9765 - val_loss: 0.0920 - val_acc: 0.9682\n",
            "Epoch 3017/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0587 - acc: 0.9778 - val_loss: 0.0858 - val_acc: 0.9672\n",
            "Epoch 3018/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0607 - acc: 0.9750 - val_loss: 0.0988 - val_acc: 0.9696\n",
            "Epoch 3019/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0592 - acc: 0.9755 - val_loss: 0.0914 - val_acc: 0.9677\n",
            "Epoch 3020/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0603 - acc: 0.9769 - val_loss: 0.0913 - val_acc: 0.9672\n",
            "Epoch 3021/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0618 - acc: 0.9749 - val_loss: 0.0866 - val_acc: 0.9687\n",
            "Epoch 3022/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9750 - val_loss: 0.0998 - val_acc: 0.9633\n",
            "Epoch 3023/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0607 - acc: 0.9763 - val_loss: 0.0987 - val_acc: 0.9667\n",
            "Epoch 3024/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0565 - acc: 0.9772 - val_loss: 0.0984 - val_acc: 0.9623\n",
            "Epoch 3025/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0605 - acc: 0.9745 - val_loss: 0.0981 - val_acc: 0.9643\n",
            "Epoch 3026/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9767 - val_loss: 0.0838 - val_acc: 0.9711\n",
            "Epoch 3027/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9756 - val_loss: 0.0995 - val_acc: 0.9667\n",
            "Epoch 3028/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9768 - val_loss: 0.0860 - val_acc: 0.9706\n",
            "Epoch 3029/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0584 - acc: 0.9757 - val_loss: 0.0919 - val_acc: 0.9706\n",
            "Epoch 3030/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0590 - acc: 0.9766 - val_loss: 0.0842 - val_acc: 0.9691\n",
            "Epoch 3031/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0586 - acc: 0.9756 - val_loss: 0.0855 - val_acc: 0.9691\n",
            "Epoch 3032/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0590 - acc: 0.9765 - val_loss: 0.0902 - val_acc: 0.9687\n",
            "Epoch 3033/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0560 - acc: 0.9783 - val_loss: 0.0833 - val_acc: 0.9721\n",
            "Epoch 3034/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0549 - acc: 0.9792 - val_loss: 0.0909 - val_acc: 0.9667\n",
            "Epoch 3035/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0581 - acc: 0.9766 - val_loss: 0.0895 - val_acc: 0.9701\n",
            "Epoch 3036/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0576 - acc: 0.9763 - val_loss: 0.0880 - val_acc: 0.9677\n",
            "Epoch 3037/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0584 - acc: 0.9774 - val_loss: 0.0910 - val_acc: 0.9696\n",
            "Epoch 3038/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0587 - acc: 0.9763 - val_loss: 0.0881 - val_acc: 0.9701\n",
            "Epoch 3039/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0580 - acc: 0.9769 - val_loss: 0.0904 - val_acc: 0.9672\n",
            "Epoch 3040/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0626 - acc: 0.9740 - val_loss: 0.0838 - val_acc: 0.9750\n",
            "Epoch 3041/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9745 - val_loss: 0.0899 - val_acc: 0.9667\n",
            "Epoch 3042/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9769 - val_loss: 0.1000 - val_acc: 0.9628\n",
            "Epoch 3043/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0558 - acc: 0.9775 - val_loss: 0.0928 - val_acc: 0.9657\n",
            "Epoch 3044/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9775 - val_loss: 0.0940 - val_acc: 0.9652\n",
            "Epoch 3045/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0637 - acc: 0.9739 - val_loss: 0.0987 - val_acc: 0.9633\n",
            "Epoch 3046/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0627 - acc: 0.9747 - val_loss: 0.0942 - val_acc: 0.9672\n",
            "Epoch 3047/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0608 - acc: 0.9750 - val_loss: 0.0847 - val_acc: 0.9716\n",
            "Epoch 3048/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0618 - acc: 0.9734 - val_loss: 0.0890 - val_acc: 0.9701\n",
            "Epoch 3049/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9769 - val_loss: 0.0915 - val_acc: 0.9696\n",
            "Epoch 3050/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9774 - val_loss: 0.0803 - val_acc: 0.9711\n",
            "Epoch 3051/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0583 - acc: 0.9758 - val_loss: 0.0887 - val_acc: 0.9657\n",
            "Epoch 3052/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0550 - acc: 0.9775 - val_loss: 0.0876 - val_acc: 0.9696\n",
            "Epoch 3053/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0582 - acc: 0.9767 - val_loss: 0.0925 - val_acc: 0.9696\n",
            "Epoch 3054/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0590 - acc: 0.9782 - val_loss: 0.0955 - val_acc: 0.9687\n",
            "Epoch 3055/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0582 - acc: 0.9769 - val_loss: 0.0856 - val_acc: 0.9731\n",
            "Epoch 3056/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9771 - val_loss: 0.0871 - val_acc: 0.9706\n",
            "Epoch 3057/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0602 - acc: 0.9760 - val_loss: 0.0893 - val_acc: 0.9721\n",
            "Epoch 3058/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9742 - val_loss: 0.0839 - val_acc: 0.9706\n",
            "Epoch 3059/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0618 - acc: 0.9749 - val_loss: 0.0861 - val_acc: 0.9696\n",
            "Epoch 3060/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0610 - acc: 0.9759 - val_loss: 0.0856 - val_acc: 0.9677\n",
            "Epoch 3061/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0607 - acc: 0.9747 - val_loss: 0.0807 - val_acc: 0.9721\n",
            "Epoch 3062/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9764 - val_loss: 0.0926 - val_acc: 0.9647\n",
            "Epoch 3063/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9767 - val_loss: 0.0888 - val_acc: 0.9696\n",
            "Epoch 3064/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0583 - acc: 0.9757 - val_loss: 0.1035 - val_acc: 0.9647\n",
            "Epoch 3065/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0576 - acc: 0.9755 - val_loss: 0.0886 - val_acc: 0.9696\n",
            "Epoch 3066/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9767 - val_loss: 0.1005 - val_acc: 0.9643\n",
            "Epoch 3067/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9746 - val_loss: 0.0890 - val_acc: 0.9716\n",
            "Epoch 3068/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9757 - val_loss: 0.0851 - val_acc: 0.9706\n",
            "Epoch 3069/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0564 - acc: 0.9772 - val_loss: 0.0892 - val_acc: 0.9711\n",
            "Epoch 3070/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9756 - val_loss: 0.0912 - val_acc: 0.9691\n",
            "Epoch 3071/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0593 - acc: 0.9761 - val_loss: 0.1023 - val_acc: 0.9633\n",
            "Epoch 3072/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0585 - acc: 0.9769 - val_loss: 0.0904 - val_acc: 0.9701\n",
            "Epoch 3073/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9760 - val_loss: 0.0924 - val_acc: 0.9667\n",
            "Epoch 3074/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9761 - val_loss: 0.0876 - val_acc: 0.9721\n",
            "Epoch 3075/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0592 - acc: 0.9754 - val_loss: 0.0879 - val_acc: 0.9706\n",
            "Epoch 3076/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0586 - acc: 0.9763 - val_loss: 0.0868 - val_acc: 0.9662\n",
            "Epoch 3077/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0570 - acc: 0.9764 - val_loss: 0.0912 - val_acc: 0.9687\n",
            "Epoch 3078/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9766 - val_loss: 0.0865 - val_acc: 0.9701\n",
            "Epoch 3079/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0629 - acc: 0.9735 - val_loss: 0.0894 - val_acc: 0.9682\n",
            "Epoch 3080/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0602 - acc: 0.9753 - val_loss: 0.0880 - val_acc: 0.9716\n",
            "Epoch 3081/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0567 - acc: 0.9774 - val_loss: 0.0866 - val_acc: 0.9691\n",
            "Epoch 3082/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0588 - acc: 0.9760 - val_loss: 0.0952 - val_acc: 0.9701\n",
            "Epoch 3083/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9758 - val_loss: 0.0976 - val_acc: 0.9687\n",
            "Epoch 3084/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9752 - val_loss: 0.0864 - val_acc: 0.9716\n",
            "Epoch 3085/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0598 - acc: 0.9761 - val_loss: 0.0812 - val_acc: 0.9711\n",
            "Epoch 3086/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0585 - acc: 0.9771 - val_loss: 0.0839 - val_acc: 0.9687\n",
            "Epoch 3087/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0604 - acc: 0.9756 - val_loss: 0.0946 - val_acc: 0.9677\n",
            "Epoch 3088/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0617 - acc: 0.9760 - val_loss: 0.1044 - val_acc: 0.9672\n",
            "Epoch 3089/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0596 - acc: 0.9766 - val_loss: 0.0940 - val_acc: 0.9672\n",
            "Epoch 3090/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9766 - val_loss: 0.0874 - val_acc: 0.9691\n",
            "Epoch 3091/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0586 - acc: 0.9764 - val_loss: 0.0835 - val_acc: 0.9691\n",
            "Epoch 3092/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0569 - acc: 0.9766 - val_loss: 0.0857 - val_acc: 0.9701\n",
            "Epoch 3093/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0595 - acc: 0.9759 - val_loss: 0.0885 - val_acc: 0.9701\n",
            "Epoch 3094/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9779 - val_loss: 0.0805 - val_acc: 0.9711\n",
            "Epoch 3095/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9755 - val_loss: 0.0940 - val_acc: 0.9667\n",
            "Epoch 3096/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0601 - acc: 0.9774 - val_loss: 0.0848 - val_acc: 0.9736\n",
            "Epoch 3097/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9774 - val_loss: 0.0850 - val_acc: 0.9716\n",
            "Epoch 3098/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0572 - acc: 0.9767 - val_loss: 0.0828 - val_acc: 0.9696\n",
            "Epoch 3099/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0559 - acc: 0.9760 - val_loss: 0.0921 - val_acc: 0.9701\n",
            "Epoch 3100/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0622 - acc: 0.9733 - val_loss: 0.0981 - val_acc: 0.9667\n",
            "Epoch 3101/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0574 - acc: 0.9763 - val_loss: 0.0890 - val_acc: 0.9701\n",
            "Epoch 3102/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0593 - acc: 0.9759 - val_loss: 0.1049 - val_acc: 0.9647\n",
            "Epoch 3103/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0611 - acc: 0.9744 - val_loss: 0.0868 - val_acc: 0.9691\n",
            "Epoch 3104/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0588 - acc: 0.9769 - val_loss: 0.0926 - val_acc: 0.9682\n",
            "Epoch 3105/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0612 - acc: 0.9753 - val_loss: 0.0919 - val_acc: 0.9691\n",
            "Epoch 3106/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0594 - acc: 0.9760 - val_loss: 0.0854 - val_acc: 0.9726\n",
            "Epoch 3107/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0596 - acc: 0.9769 - val_loss: 0.0906 - val_acc: 0.9667\n",
            "Epoch 3108/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0556 - acc: 0.9764 - val_loss: 0.0845 - val_acc: 0.9696\n",
            "Epoch 3109/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9763 - val_loss: 0.0984 - val_acc: 0.9667\n",
            "Epoch 3110/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0603 - acc: 0.9758 - val_loss: 0.0915 - val_acc: 0.9687\n",
            "Epoch 3111/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0614 - acc: 0.9756 - val_loss: 0.0954 - val_acc: 0.9662\n",
            "Epoch 3112/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0590 - acc: 0.9761 - val_loss: 0.0896 - val_acc: 0.9691\n",
            "Epoch 3113/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0605 - acc: 0.9758 - val_loss: 0.0908 - val_acc: 0.9701\n",
            "Epoch 3114/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0595 - acc: 0.9763 - val_loss: 0.0832 - val_acc: 0.9711\n",
            "Epoch 3115/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0597 - acc: 0.9764 - val_loss: 0.0996 - val_acc: 0.9682\n",
            "Epoch 3116/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9757 - val_loss: 0.0854 - val_acc: 0.9721\n",
            "Epoch 3117/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0548 - acc: 0.9783 - val_loss: 0.1003 - val_acc: 0.9667\n",
            "Epoch 3118/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0585 - acc: 0.9763 - val_loss: 0.0798 - val_acc: 0.9736\n",
            "Epoch 3119/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0613 - acc: 0.9757 - val_loss: 0.0923 - val_acc: 0.9706\n",
            "Epoch 3120/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0575 - acc: 0.9766 - val_loss: 0.0833 - val_acc: 0.9736\n",
            "Epoch 3121/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0551 - acc: 0.9770 - val_loss: 0.0928 - val_acc: 0.9672\n",
            "Epoch 3122/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0556 - acc: 0.9774 - val_loss: 0.0889 - val_acc: 0.9682\n",
            "Epoch 3123/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0578 - acc: 0.9763 - val_loss: 0.0956 - val_acc: 0.9662\n",
            "Epoch 3124/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0582 - acc: 0.9760 - val_loss: 0.0946 - val_acc: 0.9677\n",
            "Epoch 3125/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9745 - val_loss: 0.0912 - val_acc: 0.9672\n",
            "Epoch 3126/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0593 - acc: 0.9762 - val_loss: 0.0964 - val_acc: 0.9706\n",
            "Epoch 3127/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9746 - val_loss: 0.0958 - val_acc: 0.9652\n",
            "Epoch 3128/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0584 - acc: 0.9768 - val_loss: 0.0876 - val_acc: 0.9706\n",
            "Epoch 3129/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0613 - acc: 0.9751 - val_loss: 0.0841 - val_acc: 0.9696\n",
            "Epoch 3130/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0597 - acc: 0.9767 - val_loss: 0.0919 - val_acc: 0.9682\n",
            "Epoch 3131/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0569 - acc: 0.9785 - val_loss: 0.0971 - val_acc: 0.9633\n",
            "Epoch 3132/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0582 - acc: 0.9778 - val_loss: 0.0850 - val_acc: 0.9701\n",
            "Epoch 3133/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0544 - acc: 0.9790 - val_loss: 0.0924 - val_acc: 0.9687\n",
            "Epoch 3134/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0587 - acc: 0.9749 - val_loss: 0.0928 - val_acc: 0.9652\n",
            "Epoch 3135/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0551 - acc: 0.9777 - val_loss: 0.0992 - val_acc: 0.9672\n",
            "Epoch 3136/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0587 - acc: 0.9755 - val_loss: 0.0896 - val_acc: 0.9691\n",
            "Epoch 3137/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9778 - val_loss: 0.0916 - val_acc: 0.9696\n",
            "Epoch 3138/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0602 - acc: 0.9748 - val_loss: 0.0967 - val_acc: 0.9687\n",
            "Epoch 3139/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0597 - acc: 0.9764 - val_loss: 0.0917 - val_acc: 0.9726\n",
            "Epoch 3140/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0628 - acc: 0.9734 - val_loss: 0.0970 - val_acc: 0.9667\n",
            "Epoch 3141/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0606 - acc: 0.9749 - val_loss: 0.0846 - val_acc: 0.9716\n",
            "Epoch 3142/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0550 - acc: 0.9780 - val_loss: 0.0870 - val_acc: 0.9711\n",
            "Epoch 3143/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9780 - val_loss: 0.0966 - val_acc: 0.9682\n",
            "Epoch 3144/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0554 - acc: 0.9780 - val_loss: 0.0852 - val_acc: 0.9736\n",
            "Epoch 3145/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0575 - acc: 0.9774 - val_loss: 0.0992 - val_acc: 0.9647\n",
            "Epoch 3146/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0599 - acc: 0.9752 - val_loss: 0.0980 - val_acc: 0.9667\n",
            "Epoch 3147/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0586 - acc: 0.9772 - val_loss: 0.0907 - val_acc: 0.9701\n",
            "Epoch 3148/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9774 - val_loss: 0.0956 - val_acc: 0.9672\n",
            "Epoch 3149/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9771 - val_loss: 0.0940 - val_acc: 0.9677\n",
            "Epoch 3150/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0588 - acc: 0.9763 - val_loss: 0.0942 - val_acc: 0.9677\n",
            "Epoch 3151/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0587 - acc: 0.9763 - val_loss: 0.0931 - val_acc: 0.9687\n",
            "Epoch 3152/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0613 - acc: 0.9755 - val_loss: 0.0950 - val_acc: 0.9672\n",
            "Epoch 3153/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0595 - acc: 0.9752 - val_loss: 0.0837 - val_acc: 0.9721\n",
            "Epoch 3154/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0580 - acc: 0.9756 - val_loss: 0.0924 - val_acc: 0.9677\n",
            "Epoch 3155/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9775 - val_loss: 0.0857 - val_acc: 0.9696\n",
            "Epoch 3156/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9755 - val_loss: 0.0944 - val_acc: 0.9682\n",
            "Epoch 3157/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0598 - acc: 0.9760 - val_loss: 0.1006 - val_acc: 0.9677\n",
            "Epoch 3158/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0602 - acc: 0.9761 - val_loss: 0.0963 - val_acc: 0.9687\n",
            "Epoch 3159/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9765 - val_loss: 0.0912 - val_acc: 0.9677\n",
            "Epoch 3160/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0610 - acc: 0.9737 - val_loss: 0.0850 - val_acc: 0.9701\n",
            "Epoch 3161/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0585 - acc: 0.9761 - val_loss: 0.0846 - val_acc: 0.9706\n",
            "Epoch 3162/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0597 - acc: 0.9756 - val_loss: 0.0908 - val_acc: 0.9687\n",
            "Epoch 3163/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0594 - acc: 0.9750 - val_loss: 0.0835 - val_acc: 0.9711\n",
            "Epoch 3164/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0587 - acc: 0.9756 - val_loss: 0.0909 - val_acc: 0.9687\n",
            "Epoch 3165/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9767 - val_loss: 0.0947 - val_acc: 0.9677\n",
            "Epoch 3166/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0542 - acc: 0.9777 - val_loss: 0.0933 - val_acc: 0.9696\n",
            "Epoch 3167/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0561 - acc: 0.9772 - val_loss: 0.0919 - val_acc: 0.9696\n",
            "Epoch 3168/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0540 - acc: 0.9798 - val_loss: 0.0898 - val_acc: 0.9706\n",
            "Epoch 3169/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0566 - acc: 0.9769 - val_loss: 0.0917 - val_acc: 0.9677\n",
            "Epoch 3170/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0576 - acc: 0.9774 - val_loss: 0.0921 - val_acc: 0.9716\n",
            "Epoch 3171/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0593 - acc: 0.9769 - val_loss: 0.0853 - val_acc: 0.9691\n",
            "Epoch 3172/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0558 - acc: 0.9780 - val_loss: 0.0885 - val_acc: 0.9716\n",
            "Epoch 3173/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0556 - acc: 0.9791 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 3174/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0619 - acc: 0.9755 - val_loss: 0.0888 - val_acc: 0.9677\n",
            "Epoch 3175/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0567 - acc: 0.9771 - val_loss: 0.0918 - val_acc: 0.9701\n",
            "Epoch 3176/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9778 - val_loss: 0.0902 - val_acc: 0.9701\n",
            "Epoch 3177/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0551 - acc: 0.9786 - val_loss: 0.0863 - val_acc: 0.9711\n",
            "Epoch 3178/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9781 - val_loss: 0.0913 - val_acc: 0.9701\n",
            "Epoch 3179/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0583 - acc: 0.9773 - val_loss: 0.0955 - val_acc: 0.9687\n",
            "Epoch 3180/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0564 - acc: 0.9770 - val_loss: 0.0880 - val_acc: 0.9731\n",
            "Epoch 3181/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9774 - val_loss: 0.0910 - val_acc: 0.9701\n",
            "Epoch 3182/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9774 - val_loss: 0.0940 - val_acc: 0.9687\n",
            "Epoch 3183/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9770 - val_loss: 0.0826 - val_acc: 0.9711\n",
            "Epoch 3184/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0559 - acc: 0.9784 - val_loss: 0.0974 - val_acc: 0.9647\n",
            "Epoch 3185/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9772 - val_loss: 0.0939 - val_acc: 0.9682\n",
            "Epoch 3186/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9774 - val_loss: 0.0952 - val_acc: 0.9691\n",
            "Epoch 3187/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0581 - acc: 0.9762 - val_loss: 0.0889 - val_acc: 0.9711\n",
            "Epoch 3188/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0571 - acc: 0.9767 - val_loss: 0.0981 - val_acc: 0.9672\n",
            "Epoch 3189/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0585 - acc: 0.9771 - val_loss: 0.0957 - val_acc: 0.9672\n",
            "Epoch 3190/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0565 - acc: 0.9774 - val_loss: 0.0949 - val_acc: 0.9652\n",
            "Epoch 3191/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9761 - val_loss: 0.0945 - val_acc: 0.9682\n",
            "Epoch 3192/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9767 - val_loss: 0.0849 - val_acc: 0.9721\n",
            "Epoch 3193/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0549 - acc: 0.9774 - val_loss: 0.0918 - val_acc: 0.9721\n",
            "Epoch 3194/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9766 - val_loss: 0.0868 - val_acc: 0.9716\n",
            "Epoch 3195/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0587 - acc: 0.9761 - val_loss: 0.0832 - val_acc: 0.9716\n",
            "Epoch 3196/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0575 - acc: 0.9768 - val_loss: 0.0865 - val_acc: 0.9706\n",
            "Epoch 3197/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0572 - acc: 0.9774 - val_loss: 0.0890 - val_acc: 0.9706\n",
            "Epoch 3198/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0568 - acc: 0.9779 - val_loss: 0.0886 - val_acc: 0.9721\n",
            "Epoch 3199/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9794 - val_loss: 0.0891 - val_acc: 0.9706\n",
            "Epoch 3200/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0574 - acc: 0.9779 - val_loss: 0.0836 - val_acc: 0.9726\n",
            "Epoch 3201/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0569 - acc: 0.9772 - val_loss: 0.0871 - val_acc: 0.9701\n",
            "Epoch 3202/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0580 - acc: 0.9772 - val_loss: 0.0906 - val_acc: 0.9682\n",
            "Epoch 3203/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0589 - acc: 0.9763 - val_loss: 0.0898 - val_acc: 0.9682\n",
            "Epoch 3204/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0572 - acc: 0.9762 - val_loss: 0.0849 - val_acc: 0.9721\n",
            "Epoch 3205/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0590 - acc: 0.9752 - val_loss: 0.0916 - val_acc: 0.9682\n",
            "Epoch 3206/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0569 - acc: 0.9762 - val_loss: 0.0912 - val_acc: 0.9662\n",
            "Epoch 3207/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0549 - acc: 0.9786 - val_loss: 0.0886 - val_acc: 0.9701\n",
            "Epoch 3208/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0591 - acc: 0.9765 - val_loss: 0.0843 - val_acc: 0.9711\n",
            "Epoch 3209/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0600 - acc: 0.9749 - val_loss: 0.0915 - val_acc: 0.9687\n",
            "Epoch 3210/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0568 - acc: 0.9775 - val_loss: 0.0873 - val_acc: 0.9706\n",
            "Epoch 3211/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0576 - acc: 0.9761 - val_loss: 0.0909 - val_acc: 0.9687\n",
            "Epoch 3212/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0543 - acc: 0.9789 - val_loss: 0.0940 - val_acc: 0.9667\n",
            "Epoch 3213/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0579 - acc: 0.9760 - val_loss: 0.0896 - val_acc: 0.9706\n",
            "Epoch 3214/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9774 - val_loss: 0.0906 - val_acc: 0.9711\n",
            "Epoch 3215/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0574 - acc: 0.9770 - val_loss: 0.0904 - val_acc: 0.9691\n",
            "Epoch 3216/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0576 - acc: 0.9774 - val_loss: 0.0904 - val_acc: 0.9677\n",
            "Epoch 3217/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0562 - acc: 0.9786 - val_loss: 0.0897 - val_acc: 0.9736\n",
            "Epoch 3218/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0566 - acc: 0.9772 - val_loss: 0.0879 - val_acc: 0.9716\n",
            "Epoch 3219/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0592 - acc: 0.9764 - val_loss: 0.0884 - val_acc: 0.9696\n",
            "Epoch 3220/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9767 - val_loss: 0.0870 - val_acc: 0.9711\n",
            "Epoch 3221/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9757 - val_loss: 0.0924 - val_acc: 0.9691\n",
            "Epoch 3222/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9772 - val_loss: 0.0903 - val_acc: 0.9687\n",
            "Epoch 3223/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0567 - acc: 0.9772 - val_loss: 0.0906 - val_acc: 0.9711\n",
            "Epoch 3224/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0595 - acc: 0.9765 - val_loss: 0.1063 - val_acc: 0.9594\n",
            "Epoch 3225/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0582 - acc: 0.9766 - val_loss: 0.1044 - val_acc: 0.9677\n",
            "Epoch 3226/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0578 - acc: 0.9761 - val_loss: 0.1003 - val_acc: 0.9677\n",
            "Epoch 3227/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0570 - acc: 0.9774 - val_loss: 0.0823 - val_acc: 0.9731\n",
            "Epoch 3228/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9763 - val_loss: 0.0999 - val_acc: 0.9672\n",
            "Epoch 3229/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9773 - val_loss: 0.0976 - val_acc: 0.9667\n",
            "Epoch 3230/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9785 - val_loss: 0.0846 - val_acc: 0.9740\n",
            "Epoch 3231/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9767 - val_loss: 0.0924 - val_acc: 0.9682\n",
            "Epoch 3232/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0584 - acc: 0.9762 - val_loss: 0.0901 - val_acc: 0.9716\n",
            "Epoch 3233/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0564 - acc: 0.9769 - val_loss: 0.0909 - val_acc: 0.9691\n",
            "Epoch 3234/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0552 - acc: 0.9787 - val_loss: 0.0908 - val_acc: 0.9691\n",
            "Epoch 3235/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0568 - acc: 0.9780 - val_loss: 0.0890 - val_acc: 0.9716\n",
            "Epoch 3236/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0581 - acc: 0.9757 - val_loss: 0.0857 - val_acc: 0.9706\n",
            "Epoch 3237/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0605 - acc: 0.9764 - val_loss: 0.0913 - val_acc: 0.9701\n",
            "Epoch 3238/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0598 - acc: 0.9765 - val_loss: 0.0876 - val_acc: 0.9726\n",
            "Epoch 3239/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0556 - acc: 0.9780 - val_loss: 0.0891 - val_acc: 0.9711\n",
            "Epoch 3240/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9778 - val_loss: 0.0878 - val_acc: 0.9691\n",
            "Epoch 3241/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0560 - acc: 0.9785 - val_loss: 0.0911 - val_acc: 0.9662\n",
            "Epoch 3242/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0550 - acc: 0.9790 - val_loss: 0.0837 - val_acc: 0.9726\n",
            "Epoch 3243/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0528 - acc: 0.9789 - val_loss: 0.0939 - val_acc: 0.9677\n",
            "Epoch 3244/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0568 - acc: 0.9763 - val_loss: 0.0966 - val_acc: 0.9682\n",
            "Epoch 3245/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0571 - acc: 0.9775 - val_loss: 0.0870 - val_acc: 0.9731\n",
            "Epoch 3246/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9772 - val_loss: 0.0901 - val_acc: 0.9701\n",
            "Epoch 3247/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0564 - acc: 0.9774 - val_loss: 0.0864 - val_acc: 0.9701\n",
            "Epoch 3248/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0569 - acc: 0.9774 - val_loss: 0.0834 - val_acc: 0.9750\n",
            "Epoch 3249/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0575 - acc: 0.9764 - val_loss: 0.0931 - val_acc: 0.9682\n",
            "Epoch 3250/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9780 - val_loss: 0.0928 - val_acc: 0.9672\n",
            "Epoch 3251/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9766 - val_loss: 0.0867 - val_acc: 0.9721\n",
            "Epoch 3252/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9790 - val_loss: 0.0816 - val_acc: 0.9731\n",
            "Epoch 3253/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0557 - acc: 0.9775 - val_loss: 0.0915 - val_acc: 0.9696\n",
            "Epoch 3254/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0548 - acc: 0.9775 - val_loss: 0.0974 - val_acc: 0.9667\n",
            "Epoch 3255/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0524 - acc: 0.9780 - val_loss: 0.0812 - val_acc: 0.9721\n",
            "Epoch 3256/4096\n",
            "16342/16342 [==============================] - 0s 17us/step - loss: 0.0534 - acc: 0.9779 - val_loss: 0.0987 - val_acc: 0.9672\n",
            "Epoch 3257/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0572 - acc: 0.9778 - val_loss: 0.1023 - val_acc: 0.9613\n",
            "Epoch 3258/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0552 - acc: 0.9782 - val_loss: 0.0869 - val_acc: 0.9691\n",
            "Epoch 3259/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0573 - acc: 0.9764 - val_loss: 0.0919 - val_acc: 0.9667\n",
            "Epoch 3260/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0583 - acc: 0.9763 - val_loss: 0.0885 - val_acc: 0.9696\n",
            "Epoch 3261/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0562 - acc: 0.9768 - val_loss: 0.0921 - val_acc: 0.9687\n",
            "Epoch 3262/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0588 - acc: 0.9763 - val_loss: 0.0889 - val_acc: 0.9706\n",
            "Epoch 3263/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0588 - acc: 0.9773 - val_loss: 0.1019 - val_acc: 0.9638\n",
            "Epoch 3264/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0573 - acc: 0.9768 - val_loss: 0.0882 - val_acc: 0.9677\n",
            "Epoch 3265/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0589 - acc: 0.9754 - val_loss: 0.1026 - val_acc: 0.9667\n",
            "Epoch 3266/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0576 - acc: 0.9775 - val_loss: 0.0927 - val_acc: 0.9687\n",
            "Epoch 3267/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0539 - acc: 0.9791 - val_loss: 0.0892 - val_acc: 0.9721\n",
            "Epoch 3268/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0575 - acc: 0.9772 - val_loss: 0.0909 - val_acc: 0.9701\n",
            "Epoch 3269/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0529 - acc: 0.9785 - val_loss: 0.0842 - val_acc: 0.9740\n",
            "Epoch 3270/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0560 - acc: 0.9769 - val_loss: 0.0894 - val_acc: 0.9706\n",
            "Epoch 3271/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0556 - acc: 0.9778 - val_loss: 0.0878 - val_acc: 0.9706\n",
            "Epoch 3272/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0588 - acc: 0.9762 - val_loss: 0.0887 - val_acc: 0.9687\n",
            "Epoch 3273/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0558 - acc: 0.9782 - val_loss: 0.0943 - val_acc: 0.9687\n",
            "Epoch 3274/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0562 - acc: 0.9766 - val_loss: 0.0886 - val_acc: 0.9701\n",
            "Epoch 3275/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9763 - val_loss: 0.0913 - val_acc: 0.9691\n",
            "Epoch 3276/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0572 - acc: 0.9766 - val_loss: 0.0986 - val_acc: 0.9623\n",
            "Epoch 3277/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0579 - acc: 0.9767 - val_loss: 0.0940 - val_acc: 0.9706\n",
            "Epoch 3278/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0532 - acc: 0.9793 - val_loss: 0.0874 - val_acc: 0.9701\n",
            "Epoch 3279/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9781 - val_loss: 0.0915 - val_acc: 0.9701\n",
            "Epoch 3280/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0549 - acc: 0.9775 - val_loss: 0.0852 - val_acc: 0.9726\n",
            "Epoch 3281/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0557 - acc: 0.9774 - val_loss: 0.1044 - val_acc: 0.9657\n",
            "Epoch 3282/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0552 - acc: 0.9781 - val_loss: 0.0946 - val_acc: 0.9696\n",
            "Epoch 3283/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9775 - val_loss: 0.0934 - val_acc: 0.9701\n",
            "Epoch 3284/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0532 - acc: 0.9785 - val_loss: 0.0883 - val_acc: 0.9682\n",
            "Epoch 3285/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0545 - acc: 0.9780 - val_loss: 0.0855 - val_acc: 0.9736\n",
            "Epoch 3286/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0546 - acc: 0.9783 - val_loss: 0.0913 - val_acc: 0.9682\n",
            "Epoch 3287/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0550 - acc: 0.9785 - val_loss: 0.0923 - val_acc: 0.9691\n",
            "Epoch 3288/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9768 - val_loss: 0.0917 - val_acc: 0.9726\n",
            "Epoch 3289/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9780 - val_loss: 0.0979 - val_acc: 0.9696\n",
            "Epoch 3290/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0563 - acc: 0.9777 - val_loss: 0.0935 - val_acc: 0.9706\n",
            "Epoch 3291/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0543 - acc: 0.9788 - val_loss: 0.0865 - val_acc: 0.9711\n",
            "Epoch 3292/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0581 - acc: 0.9760 - val_loss: 0.0942 - val_acc: 0.9662\n",
            "Epoch 3293/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0585 - acc: 0.9771 - val_loss: 0.0937 - val_acc: 0.9667\n",
            "Epoch 3294/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9771 - val_loss: 0.0832 - val_acc: 0.9721\n",
            "Epoch 3295/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9762 - val_loss: 0.0929 - val_acc: 0.9711\n",
            "Epoch 3296/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0583 - acc: 0.9761 - val_loss: 0.0842 - val_acc: 0.9726\n",
            "Epoch 3297/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9763 - val_loss: 0.0846 - val_acc: 0.9721\n",
            "Epoch 3298/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9790 - val_loss: 0.1000 - val_acc: 0.9677\n",
            "Epoch 3299/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0557 - acc: 0.9771 - val_loss: 0.1090 - val_acc: 0.9623\n",
            "Epoch 3300/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0578 - acc: 0.9764 - val_loss: 0.0912 - val_acc: 0.9687\n",
            "Epoch 3301/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0616 - acc: 0.9739 - val_loss: 0.0916 - val_acc: 0.9711\n",
            "Epoch 3302/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0588 - acc: 0.9758 - val_loss: 0.0941 - val_acc: 0.9677\n",
            "Epoch 3303/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9782 - val_loss: 0.0894 - val_acc: 0.9711\n",
            "Epoch 3304/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0607 - acc: 0.9758 - val_loss: 0.0996 - val_acc: 0.9682\n",
            "Epoch 3305/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9782 - val_loss: 0.0927 - val_acc: 0.9672\n",
            "Epoch 3306/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0597 - acc: 0.9767 - val_loss: 0.0888 - val_acc: 0.9696\n",
            "Epoch 3307/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9790 - val_loss: 0.0934 - val_acc: 0.9706\n",
            "Epoch 3308/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0589 - acc: 0.9761 - val_loss: 0.0852 - val_acc: 0.9726\n",
            "Epoch 3309/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0539 - acc: 0.9786 - val_loss: 0.0883 - val_acc: 0.9687\n",
            "Epoch 3310/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0530 - acc: 0.9796 - val_loss: 0.0885 - val_acc: 0.9691\n",
            "Epoch 3311/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0566 - acc: 0.9772 - val_loss: 0.0910 - val_acc: 0.9701\n",
            "Epoch 3312/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0579 - acc: 0.9756 - val_loss: 0.0924 - val_acc: 0.9687\n",
            "Epoch 3313/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0559 - acc: 0.9767 - val_loss: 0.0926 - val_acc: 0.9696\n",
            "Epoch 3314/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0556 - acc: 0.9772 - val_loss: 0.0917 - val_acc: 0.9701\n",
            "Epoch 3315/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0534 - acc: 0.9778 - val_loss: 0.0864 - val_acc: 0.9706\n",
            "Epoch 3316/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0563 - acc: 0.9771 - val_loss: 0.0819 - val_acc: 0.9750\n",
            "Epoch 3317/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0558 - acc: 0.9769 - val_loss: 0.0872 - val_acc: 0.9716\n",
            "Epoch 3318/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0577 - acc: 0.9763 - val_loss: 0.0913 - val_acc: 0.9706\n",
            "Epoch 3319/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0612 - acc: 0.9752 - val_loss: 0.0932 - val_acc: 0.9687\n",
            "Epoch 3320/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0530 - acc: 0.9796 - val_loss: 0.0863 - val_acc: 0.9711\n",
            "Epoch 3321/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0575 - acc: 0.9763 - val_loss: 0.0806 - val_acc: 0.9716\n",
            "Epoch 3322/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0567 - acc: 0.9767 - val_loss: 0.0894 - val_acc: 0.9696\n",
            "Epoch 3323/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0540 - acc: 0.9789 - val_loss: 0.0902 - val_acc: 0.9706\n",
            "Epoch 3324/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9781 - val_loss: 0.0874 - val_acc: 0.9726\n",
            "Epoch 3325/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0545 - acc: 0.9783 - val_loss: 0.0885 - val_acc: 0.9740\n",
            "Epoch 3326/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9777 - val_loss: 0.0906 - val_acc: 0.9682\n",
            "Epoch 3327/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0560 - acc: 0.9769 - val_loss: 0.0942 - val_acc: 0.9682\n",
            "Epoch 3328/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0586 - acc: 0.9760 - val_loss: 0.0880 - val_acc: 0.9726\n",
            "Epoch 3329/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0558 - acc: 0.9774 - val_loss: 0.0898 - val_acc: 0.9701\n",
            "Epoch 3330/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0538 - acc: 0.9788 - val_loss: 0.0933 - val_acc: 0.9652\n",
            "Epoch 3331/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0567 - acc: 0.9785 - val_loss: 0.0953 - val_acc: 0.9701\n",
            "Epoch 3332/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9791 - val_loss: 0.0952 - val_acc: 0.9682\n",
            "Epoch 3333/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0563 - acc: 0.9774 - val_loss: 0.0900 - val_acc: 0.9687\n",
            "Epoch 3334/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0566 - acc: 0.9763 - val_loss: 0.0919 - val_acc: 0.9691\n",
            "Epoch 3335/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0572 - acc: 0.9765 - val_loss: 0.0950 - val_acc: 0.9657\n",
            "Epoch 3336/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0557 - acc: 0.9779 - val_loss: 0.0966 - val_acc: 0.9716\n",
            "Epoch 3337/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0582 - acc: 0.9759 - val_loss: 0.0975 - val_acc: 0.9687\n",
            "Epoch 3338/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0575 - acc: 0.9759 - val_loss: 0.1031 - val_acc: 0.9652\n",
            "Epoch 3339/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0535 - acc: 0.9787 - val_loss: 0.0913 - val_acc: 0.9716\n",
            "Epoch 3340/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0543 - acc: 0.9782 - val_loss: 0.0904 - val_acc: 0.9682\n",
            "Epoch 3341/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0556 - acc: 0.9768 - val_loss: 0.0907 - val_acc: 0.9696\n",
            "Epoch 3342/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9789 - val_loss: 0.0900 - val_acc: 0.9691\n",
            "Epoch 3343/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9786 - val_loss: 0.0918 - val_acc: 0.9711\n",
            "Epoch 3344/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9780 - val_loss: 0.0898 - val_acc: 0.9691\n",
            "Epoch 3345/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0541 - acc: 0.9775 - val_loss: 0.0889 - val_acc: 0.9696\n",
            "Epoch 3346/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0531 - acc: 0.9785 - val_loss: 0.1019 - val_acc: 0.9633\n",
            "Epoch 3347/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0539 - acc: 0.9784 - val_loss: 0.0925 - val_acc: 0.9711\n",
            "Epoch 3348/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0563 - acc: 0.9771 - val_loss: 0.0934 - val_acc: 0.9672\n",
            "Epoch 3349/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0556 - acc: 0.9790 - val_loss: 0.0980 - val_acc: 0.9672\n",
            "Epoch 3350/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9778 - val_loss: 0.0911 - val_acc: 0.9721\n",
            "Epoch 3351/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0553 - acc: 0.9780 - val_loss: 0.0927 - val_acc: 0.9701\n",
            "Epoch 3352/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0560 - acc: 0.9781 - val_loss: 0.0931 - val_acc: 0.9682\n",
            "Epoch 3353/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0541 - acc: 0.9782 - val_loss: 0.0927 - val_acc: 0.9643\n",
            "Epoch 3354/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0583 - acc: 0.9763 - val_loss: 0.0882 - val_acc: 0.9716\n",
            "Epoch 3355/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0595 - acc: 0.9766 - val_loss: 0.0983 - val_acc: 0.9691\n",
            "Epoch 3356/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0586 - acc: 0.9761 - val_loss: 0.0932 - val_acc: 0.9696\n",
            "Epoch 3357/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0529 - acc: 0.9794 - val_loss: 0.0875 - val_acc: 0.9696\n",
            "Epoch 3358/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0545 - acc: 0.9770 - val_loss: 0.0912 - val_acc: 0.9687\n",
            "Epoch 3359/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0577 - acc: 0.9780 - val_loss: 0.0914 - val_acc: 0.9672\n",
            "Epoch 3360/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0569 - acc: 0.9774 - val_loss: 0.0875 - val_acc: 0.9745\n",
            "Epoch 3361/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0549 - acc: 0.9772 - val_loss: 0.0893 - val_acc: 0.9731\n",
            "Epoch 3362/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9791 - val_loss: 0.0895 - val_acc: 0.9687\n",
            "Epoch 3363/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9777 - val_loss: 0.0912 - val_acc: 0.9696\n",
            "Epoch 3364/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0532 - acc: 0.9789 - val_loss: 0.0892 - val_acc: 0.9706\n",
            "Epoch 3365/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0525 - acc: 0.9804 - val_loss: 0.0983 - val_acc: 0.9677\n",
            "Epoch 3366/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9766 - val_loss: 0.0958 - val_acc: 0.9657\n",
            "Epoch 3367/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0568 - acc: 0.9765 - val_loss: 0.0991 - val_acc: 0.9682\n",
            "Epoch 3368/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0546 - acc: 0.9780 - val_loss: 0.0922 - val_acc: 0.9696\n",
            "Epoch 3369/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0537 - acc: 0.9782 - val_loss: 0.0904 - val_acc: 0.9701\n",
            "Epoch 3370/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0553 - acc: 0.9783 - val_loss: 0.0866 - val_acc: 0.9711\n",
            "Epoch 3371/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0531 - acc: 0.9785 - val_loss: 0.0882 - val_acc: 0.9706\n",
            "Epoch 3372/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0515 - acc: 0.9791 - val_loss: 0.0838 - val_acc: 0.9716\n",
            "Epoch 3373/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0531 - acc: 0.9791 - val_loss: 0.0818 - val_acc: 0.9716\n",
            "Epoch 3374/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0563 - acc: 0.9776 - val_loss: 0.0828 - val_acc: 0.9726\n",
            "Epoch 3375/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9779 - val_loss: 0.0831 - val_acc: 0.9731\n",
            "Epoch 3376/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0547 - acc: 0.9777 - val_loss: 0.0860 - val_acc: 0.9716\n",
            "Epoch 3377/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0555 - acc: 0.9764 - val_loss: 0.0903 - val_acc: 0.9716\n",
            "Epoch 3378/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0567 - acc: 0.9766 - val_loss: 0.0948 - val_acc: 0.9667\n",
            "Epoch 3379/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0541 - acc: 0.9793 - val_loss: 0.0919 - val_acc: 0.9711\n",
            "Epoch 3380/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0563 - acc: 0.9778 - val_loss: 0.0912 - val_acc: 0.9687\n",
            "Epoch 3381/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9785 - val_loss: 0.0984 - val_acc: 0.9687\n",
            "Epoch 3382/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0530 - acc: 0.9785 - val_loss: 0.0842 - val_acc: 0.9740\n",
            "Epoch 3383/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0565 - acc: 0.9776 - val_loss: 0.0958 - val_acc: 0.9672\n",
            "Epoch 3384/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0532 - acc: 0.9787 - val_loss: 0.0859 - val_acc: 0.9726\n",
            "Epoch 3385/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0526 - acc: 0.9789 - val_loss: 0.0982 - val_acc: 0.9696\n",
            "Epoch 3386/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0564 - acc: 0.9774 - val_loss: 0.0843 - val_acc: 0.9731\n",
            "Epoch 3387/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9787 - val_loss: 0.0833 - val_acc: 0.9731\n",
            "Epoch 3388/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0548 - acc: 0.9789 - val_loss: 0.0899 - val_acc: 0.9696\n",
            "Epoch 3389/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9758 - val_loss: 0.0989 - val_acc: 0.9657\n",
            "Epoch 3390/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0581 - acc: 0.9770 - val_loss: 0.0893 - val_acc: 0.9706\n",
            "Epoch 3391/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0547 - acc: 0.9780 - val_loss: 0.0870 - val_acc: 0.9682\n",
            "Epoch 3392/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0543 - acc: 0.9782 - val_loss: 0.0997 - val_acc: 0.9677\n",
            "Epoch 3393/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0589 - acc: 0.9760 - val_loss: 0.1049 - val_acc: 0.9618\n",
            "Epoch 3394/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0547 - acc: 0.9777 - val_loss: 0.0841 - val_acc: 0.9731\n",
            "Epoch 3395/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9794 - val_loss: 0.0960 - val_acc: 0.9677\n",
            "Epoch 3396/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0564 - acc: 0.9768 - val_loss: 0.0908 - val_acc: 0.9696\n",
            "Epoch 3397/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9773 - val_loss: 0.0921 - val_acc: 0.9696\n",
            "Epoch 3398/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0513 - acc: 0.9804 - val_loss: 0.0890 - val_acc: 0.9711\n",
            "Epoch 3399/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0564 - acc: 0.9778 - val_loss: 0.0879 - val_acc: 0.9706\n",
            "Epoch 3400/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9779 - val_loss: 0.0826 - val_acc: 0.9731\n",
            "Epoch 3401/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9763 - val_loss: 0.0920 - val_acc: 0.9691\n",
            "Epoch 3402/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0559 - acc: 0.9773 - val_loss: 0.0881 - val_acc: 0.9711\n",
            "Epoch 3403/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0533 - acc: 0.9782 - val_loss: 0.0976 - val_acc: 0.9682\n",
            "Epoch 3404/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0547 - acc: 0.9789 - val_loss: 0.0896 - val_acc: 0.9721\n",
            "Epoch 3405/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0522 - acc: 0.9788 - val_loss: 0.0939 - val_acc: 0.9662\n",
            "Epoch 3406/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9779 - val_loss: 0.0916 - val_acc: 0.9687\n",
            "Epoch 3407/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9774 - val_loss: 0.0859 - val_acc: 0.9726\n",
            "Epoch 3408/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9772 - val_loss: 0.0895 - val_acc: 0.9706\n",
            "Epoch 3409/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0540 - acc: 0.9773 - val_loss: 0.0889 - val_acc: 0.9682\n",
            "Epoch 3410/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0557 - acc: 0.9779 - val_loss: 0.0827 - val_acc: 0.9726\n",
            "Epoch 3411/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0551 - acc: 0.9780 - val_loss: 0.0823 - val_acc: 0.9721\n",
            "Epoch 3412/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9783 - val_loss: 0.1061 - val_acc: 0.9643\n",
            "Epoch 3413/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0555 - acc: 0.9786 - val_loss: 0.0860 - val_acc: 0.9745\n",
            "Epoch 3414/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0543 - acc: 0.9789 - val_loss: 0.0987 - val_acc: 0.9696\n",
            "Epoch 3415/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0550 - acc: 0.9782 - val_loss: 0.0836 - val_acc: 0.9706\n",
            "Epoch 3416/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0525 - acc: 0.9793 - val_loss: 0.0882 - val_acc: 0.9701\n",
            "Epoch 3417/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9783 - val_loss: 0.0944 - val_acc: 0.9672\n",
            "Epoch 3418/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0552 - acc: 0.9768 - val_loss: 0.0875 - val_acc: 0.9711\n",
            "Epoch 3419/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0531 - acc: 0.9792 - val_loss: 0.0885 - val_acc: 0.9682\n",
            "Epoch 3420/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0538 - acc: 0.9778 - val_loss: 0.1065 - val_acc: 0.9633\n",
            "Epoch 3421/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0557 - acc: 0.9769 - val_loss: 0.0910 - val_acc: 0.9701\n",
            "Epoch 3422/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0547 - acc: 0.9778 - val_loss: 0.0896 - val_acc: 0.9691\n",
            "Epoch 3423/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0534 - acc: 0.9787 - val_loss: 0.0896 - val_acc: 0.9691\n",
            "Epoch 3424/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0539 - acc: 0.9783 - val_loss: 0.0905 - val_acc: 0.9696\n",
            "Epoch 3425/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0561 - acc: 0.9771 - val_loss: 0.0946 - val_acc: 0.9687\n",
            "Epoch 3426/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0567 - acc: 0.9765 - val_loss: 0.0955 - val_acc: 0.9682\n",
            "Epoch 3427/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0560 - acc: 0.9779 - val_loss: 0.0926 - val_acc: 0.9711\n",
            "Epoch 3428/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0561 - acc: 0.9772 - val_loss: 0.0859 - val_acc: 0.9726\n",
            "Epoch 3429/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0508 - acc: 0.9801 - val_loss: 0.0848 - val_acc: 0.9740\n",
            "Epoch 3430/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0527 - acc: 0.9795 - val_loss: 0.0931 - val_acc: 0.9691\n",
            "Epoch 3431/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0542 - acc: 0.9771 - val_loss: 0.0948 - val_acc: 0.9667\n",
            "Epoch 3432/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0541 - acc: 0.9781 - val_loss: 0.0931 - val_acc: 0.9691\n",
            "Epoch 3433/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0509 - acc: 0.9792 - val_loss: 0.0948 - val_acc: 0.9687\n",
            "Epoch 3434/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0562 - acc: 0.9775 - val_loss: 0.0836 - val_acc: 0.9721\n",
            "Epoch 3435/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0532 - acc: 0.9788 - val_loss: 0.0944 - val_acc: 0.9711\n",
            "Epoch 3436/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0571 - acc: 0.9781 - val_loss: 0.0914 - val_acc: 0.9701\n",
            "Epoch 3437/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0550 - acc: 0.9780 - val_loss: 0.0782 - val_acc: 0.9760\n",
            "Epoch 3438/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9767 - val_loss: 0.0869 - val_acc: 0.9731\n",
            "Epoch 3439/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0530 - acc: 0.9788 - val_loss: 0.0861 - val_acc: 0.9726\n",
            "Epoch 3440/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0557 - acc: 0.9785 - val_loss: 0.0957 - val_acc: 0.9672\n",
            "Epoch 3441/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0562 - acc: 0.9782 - val_loss: 0.0864 - val_acc: 0.9711\n",
            "Epoch 3442/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9785 - val_loss: 0.0850 - val_acc: 0.9706\n",
            "Epoch 3443/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0548 - acc: 0.9782 - val_loss: 0.0862 - val_acc: 0.9716\n",
            "Epoch 3444/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0518 - acc: 0.9790 - val_loss: 0.0882 - val_acc: 0.9706\n",
            "Epoch 3445/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0568 - acc: 0.9774 - val_loss: 0.0945 - val_acc: 0.9677\n",
            "Epoch 3446/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9801 - val_loss: 0.0927 - val_acc: 0.9677\n",
            "Epoch 3447/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0544 - acc: 0.9786 - val_loss: 0.0943 - val_acc: 0.9687\n",
            "Epoch 3448/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0547 - acc: 0.9785 - val_loss: 0.0893 - val_acc: 0.9691\n",
            "Epoch 3449/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0537 - acc: 0.9781 - val_loss: 0.0893 - val_acc: 0.9687\n",
            "Epoch 3450/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0542 - acc: 0.9779 - val_loss: 0.1054 - val_acc: 0.9672\n",
            "Epoch 3451/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0558 - acc: 0.9774 - val_loss: 0.0897 - val_acc: 0.9687\n",
            "Epoch 3452/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0568 - acc: 0.9777 - val_loss: 0.0849 - val_acc: 0.9736\n",
            "Epoch 3453/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0565 - acc: 0.9773 - val_loss: 0.0936 - val_acc: 0.9687\n",
            "Epoch 3454/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9776 - val_loss: 0.0928 - val_acc: 0.9691\n",
            "Epoch 3455/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0525 - acc: 0.9790 - val_loss: 0.0898 - val_acc: 0.9716\n",
            "Epoch 3456/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9780 - val_loss: 0.1096 - val_acc: 0.9628\n",
            "Epoch 3457/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0571 - acc: 0.9771 - val_loss: 0.0940 - val_acc: 0.9691\n",
            "Epoch 3458/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0547 - acc: 0.9785 - val_loss: 0.0926 - val_acc: 0.9687\n",
            "Epoch 3459/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0558 - acc: 0.9772 - val_loss: 0.0827 - val_acc: 0.9736\n",
            "Epoch 3460/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9791 - val_loss: 0.0969 - val_acc: 0.9643\n",
            "Epoch 3461/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0571 - acc: 0.9774 - val_loss: 0.0925 - val_acc: 0.9687\n",
            "Epoch 3462/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0531 - acc: 0.9804 - val_loss: 0.0970 - val_acc: 0.9696\n",
            "Epoch 3463/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9784 - val_loss: 0.0912 - val_acc: 0.9701\n",
            "Epoch 3464/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0538 - acc: 0.9783 - val_loss: 0.0855 - val_acc: 0.9736\n",
            "Epoch 3465/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9795 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 3466/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0530 - acc: 0.9786 - val_loss: 0.0860 - val_acc: 0.9711\n",
            "Epoch 3467/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0502 - acc: 0.9805 - val_loss: 0.0883 - val_acc: 0.9696\n",
            "Epoch 3468/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0505 - acc: 0.9804 - val_loss: 0.0903 - val_acc: 0.9696\n",
            "Epoch 3469/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0548 - acc: 0.9786 - val_loss: 0.0912 - val_acc: 0.9706\n",
            "Epoch 3470/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9778 - val_loss: 0.0911 - val_acc: 0.9691\n",
            "Epoch 3471/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0556 - acc: 0.9767 - val_loss: 0.0904 - val_acc: 0.9721\n",
            "Epoch 3472/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9786 - val_loss: 0.0955 - val_acc: 0.9701\n",
            "Epoch 3473/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9796 - val_loss: 0.0905 - val_acc: 0.9750\n",
            "Epoch 3474/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9789 - val_loss: 0.0942 - val_acc: 0.9701\n",
            "Epoch 3475/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0540 - acc: 0.9793 - val_loss: 0.0948 - val_acc: 0.9716\n",
            "Epoch 3476/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0542 - acc: 0.9771 - val_loss: 0.0914 - val_acc: 0.9726\n",
            "Epoch 3477/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9786 - val_loss: 0.0865 - val_acc: 0.9731\n",
            "Epoch 3478/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0558 - acc: 0.9779 - val_loss: 0.0943 - val_acc: 0.9696\n",
            "Epoch 3479/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0564 - acc: 0.9771 - val_loss: 0.0875 - val_acc: 0.9736\n",
            "Epoch 3480/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9798 - val_loss: 0.0963 - val_acc: 0.9677\n",
            "Epoch 3481/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9788 - val_loss: 0.0911 - val_acc: 0.9691\n",
            "Epoch 3482/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0544 - acc: 0.9768 - val_loss: 0.0962 - val_acc: 0.9682\n",
            "Epoch 3483/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9794 - val_loss: 0.1009 - val_acc: 0.9667\n",
            "Epoch 3484/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0531 - acc: 0.9775 - val_loss: 0.0913 - val_acc: 0.9755\n",
            "Epoch 3485/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0585 - acc: 0.9774 - val_loss: 0.0864 - val_acc: 0.9711\n",
            "Epoch 3486/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0563 - acc: 0.9775 - val_loss: 0.0910 - val_acc: 0.9736\n",
            "Epoch 3487/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9798 - val_loss: 0.0891 - val_acc: 0.9721\n",
            "Epoch 3488/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0531 - acc: 0.9783 - val_loss: 0.0952 - val_acc: 0.9691\n",
            "Epoch 3489/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0553 - acc: 0.9786 - val_loss: 0.0950 - val_acc: 0.9706\n",
            "Epoch 3490/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9788 - val_loss: 0.0909 - val_acc: 0.9726\n",
            "Epoch 3491/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0526 - acc: 0.9788 - val_loss: 0.0878 - val_acc: 0.9687\n",
            "Epoch 3492/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9783 - val_loss: 0.0857 - val_acc: 0.9731\n",
            "Epoch 3493/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0544 - acc: 0.9782 - val_loss: 0.0891 - val_acc: 0.9716\n",
            "Epoch 3494/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0533 - acc: 0.9791 - val_loss: 0.0940 - val_acc: 0.9691\n",
            "Epoch 3495/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0547 - acc: 0.9785 - val_loss: 0.0879 - val_acc: 0.9701\n",
            "Epoch 3496/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9791 - val_loss: 0.0905 - val_acc: 0.9672\n",
            "Epoch 3497/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0555 - acc: 0.9783 - val_loss: 0.0905 - val_acc: 0.9726\n",
            "Epoch 3498/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9791 - val_loss: 0.0926 - val_acc: 0.9721\n",
            "Epoch 3499/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9793 - val_loss: 0.0963 - val_acc: 0.9662\n",
            "Epoch 3500/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0533 - acc: 0.9786 - val_loss: 0.0858 - val_acc: 0.9721\n",
            "Epoch 3501/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9784 - val_loss: 0.0967 - val_acc: 0.9677\n",
            "Epoch 3502/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9780 - val_loss: 0.0860 - val_acc: 0.9696\n",
            "Epoch 3503/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0534 - acc: 0.9789 - val_loss: 0.0936 - val_acc: 0.9701\n",
            "Epoch 3504/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9777 - val_loss: 0.0923 - val_acc: 0.9706\n",
            "Epoch 3505/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0548 - acc: 0.9776 - val_loss: 0.0885 - val_acc: 0.9687\n",
            "Epoch 3506/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0499 - acc: 0.9809 - val_loss: 0.0899 - val_acc: 0.9716\n",
            "Epoch 3507/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0533 - acc: 0.9781 - val_loss: 0.0918 - val_acc: 0.9701\n",
            "Epoch 3508/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0514 - acc: 0.9796 - val_loss: 0.0855 - val_acc: 0.9677\n",
            "Epoch 3509/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0529 - acc: 0.9796 - val_loss: 0.0870 - val_acc: 0.9731\n",
            "Epoch 3510/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0498 - acc: 0.9801 - val_loss: 0.0988 - val_acc: 0.9682\n",
            "Epoch 3511/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9788 - val_loss: 0.0939 - val_acc: 0.9701\n",
            "Epoch 3512/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0548 - acc: 0.9784 - val_loss: 0.0865 - val_acc: 0.9711\n",
            "Epoch 3513/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0523 - acc: 0.9803 - val_loss: 0.0918 - val_acc: 0.9677\n",
            "Epoch 3514/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9793 - val_loss: 0.0912 - val_acc: 0.9726\n",
            "Epoch 3515/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0540 - acc: 0.9779 - val_loss: 0.0956 - val_acc: 0.9696\n",
            "Epoch 3516/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0574 - acc: 0.9775 - val_loss: 0.0877 - val_acc: 0.9721\n",
            "Epoch 3517/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0530 - acc: 0.9794 - val_loss: 0.0922 - val_acc: 0.9691\n",
            "Epoch 3518/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9787 - val_loss: 0.0894 - val_acc: 0.9701\n",
            "Epoch 3519/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0560 - acc: 0.9767 - val_loss: 0.0955 - val_acc: 0.9706\n",
            "Epoch 3520/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0533 - acc: 0.9791 - val_loss: 0.0904 - val_acc: 0.9706\n",
            "Epoch 3521/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0520 - acc: 0.9790 - val_loss: 0.0982 - val_acc: 0.9657\n",
            "Epoch 3522/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9783 - val_loss: 0.0895 - val_acc: 0.9716\n",
            "Epoch 3523/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0524 - acc: 0.9783 - val_loss: 0.0904 - val_acc: 0.9731\n",
            "Epoch 3524/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9781 - val_loss: 0.0933 - val_acc: 0.9696\n",
            "Epoch 3525/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9797 - val_loss: 0.0965 - val_acc: 0.9662\n",
            "Epoch 3526/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0535 - acc: 0.9792 - val_loss: 0.0926 - val_acc: 0.9716\n",
            "Epoch 3527/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0561 - acc: 0.9778 - val_loss: 0.0903 - val_acc: 0.9701\n",
            "Epoch 3528/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0526 - acc: 0.9793 - val_loss: 0.1044 - val_acc: 0.9618\n",
            "Epoch 3529/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9795 - val_loss: 0.1115 - val_acc: 0.9633\n",
            "Epoch 3530/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0545 - acc: 0.9771 - val_loss: 0.0910 - val_acc: 0.9711\n",
            "Epoch 3531/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0539 - acc: 0.9785 - val_loss: 0.0916 - val_acc: 0.9687\n",
            "Epoch 3532/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0533 - acc: 0.9778 - val_loss: 0.0897 - val_acc: 0.9706\n",
            "Epoch 3533/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0523 - acc: 0.9796 - val_loss: 0.0902 - val_acc: 0.9677\n",
            "Epoch 3534/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0545 - acc: 0.9783 - val_loss: 0.0877 - val_acc: 0.9716\n",
            "Epoch 3535/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0530 - acc: 0.9790 - val_loss: 0.0928 - val_acc: 0.9687\n",
            "Epoch 3536/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9789 - val_loss: 0.0917 - val_acc: 0.9687\n",
            "Epoch 3537/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0550 - acc: 0.9782 - val_loss: 0.0925 - val_acc: 0.9716\n",
            "Epoch 3538/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0496 - acc: 0.9808 - val_loss: 0.0958 - val_acc: 0.9682\n",
            "Epoch 3539/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0538 - acc: 0.9778 - val_loss: 0.0864 - val_acc: 0.9716\n",
            "Epoch 3540/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0564 - acc: 0.9778 - val_loss: 0.0878 - val_acc: 0.9691\n",
            "Epoch 3541/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0534 - acc: 0.9780 - val_loss: 0.0874 - val_acc: 0.9711\n",
            "Epoch 3542/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0533 - acc: 0.9794 - val_loss: 0.0945 - val_acc: 0.9677\n",
            "Epoch 3543/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0550 - acc: 0.9778 - val_loss: 0.0918 - val_acc: 0.9701\n",
            "Epoch 3544/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0555 - acc: 0.9782 - val_loss: 0.0910 - val_acc: 0.9706\n",
            "Epoch 3545/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9777 - val_loss: 0.0868 - val_acc: 0.9721\n",
            "Epoch 3546/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0565 - acc: 0.9780 - val_loss: 0.0882 - val_acc: 0.9706\n",
            "Epoch 3547/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9794 - val_loss: 0.0910 - val_acc: 0.9721\n",
            "Epoch 3548/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9812 - val_loss: 0.0846 - val_acc: 0.9721\n",
            "Epoch 3549/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0525 - acc: 0.9795 - val_loss: 0.0938 - val_acc: 0.9701\n",
            "Epoch 3550/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9791 - val_loss: 0.0884 - val_acc: 0.9740\n",
            "Epoch 3551/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0508 - acc: 0.9812 - val_loss: 0.0940 - val_acc: 0.9721\n",
            "Epoch 3552/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0498 - acc: 0.9803 - val_loss: 0.0886 - val_acc: 0.9736\n",
            "Epoch 3553/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0504 - acc: 0.9813 - val_loss: 0.1017 - val_acc: 0.9643\n",
            "Epoch 3554/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0546 - acc: 0.9783 - val_loss: 0.0943 - val_acc: 0.9687\n",
            "Epoch 3555/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0539 - acc: 0.9778 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 3556/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0538 - acc: 0.9793 - val_loss: 0.0937 - val_acc: 0.9691\n",
            "Epoch 3557/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0517 - acc: 0.9797 - val_loss: 0.0942 - val_acc: 0.9696\n",
            "Epoch 3558/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9791 - val_loss: 0.0919 - val_acc: 0.9706\n",
            "Epoch 3559/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0534 - acc: 0.9785 - val_loss: 0.0982 - val_acc: 0.9706\n",
            "Epoch 3560/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0517 - acc: 0.9791 - val_loss: 0.0948 - val_acc: 0.9696\n",
            "Epoch 3561/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0526 - acc: 0.9783 - val_loss: 0.0872 - val_acc: 0.9721\n",
            "Epoch 3562/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9802 - val_loss: 0.0953 - val_acc: 0.9667\n",
            "Epoch 3563/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0522 - acc: 0.9791 - val_loss: 0.0857 - val_acc: 0.9711\n",
            "Epoch 3564/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0550 - acc: 0.9778 - val_loss: 0.0861 - val_acc: 0.9716\n",
            "Epoch 3565/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0535 - acc: 0.9793 - val_loss: 0.0866 - val_acc: 0.9726\n",
            "Epoch 3566/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0555 - acc: 0.9760 - val_loss: 0.0910 - val_acc: 0.9706\n",
            "Epoch 3567/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0506 - acc: 0.9804 - val_loss: 0.0880 - val_acc: 0.9701\n",
            "Epoch 3568/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9783 - val_loss: 0.0971 - val_acc: 0.9687\n",
            "Epoch 3569/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9801 - val_loss: 0.0905 - val_acc: 0.9701\n",
            "Epoch 3570/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9782 - val_loss: 0.0908 - val_acc: 0.9731\n",
            "Epoch 3571/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9808 - val_loss: 0.1017 - val_acc: 0.9672\n",
            "Epoch 3572/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0547 - acc: 0.9779 - val_loss: 0.0916 - val_acc: 0.9711\n",
            "Epoch 3573/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0516 - acc: 0.9797 - val_loss: 0.0939 - val_acc: 0.9696\n",
            "Epoch 3574/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0498 - acc: 0.9806 - val_loss: 0.0919 - val_acc: 0.9731\n",
            "Epoch 3575/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0507 - acc: 0.9796 - val_loss: 0.1002 - val_acc: 0.9652\n",
            "Epoch 3576/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9785 - val_loss: 0.0897 - val_acc: 0.9721\n",
            "Epoch 3577/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0518 - acc: 0.9784 - val_loss: 0.0936 - val_acc: 0.9682\n",
            "Epoch 3578/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0517 - acc: 0.9797 - val_loss: 0.0919 - val_acc: 0.9701\n",
            "Epoch 3579/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9792 - val_loss: 0.0944 - val_acc: 0.9706\n",
            "Epoch 3580/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9784 - val_loss: 0.0964 - val_acc: 0.9691\n",
            "Epoch 3581/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0519 - acc: 0.9792 - val_loss: 0.0930 - val_acc: 0.9711\n",
            "Epoch 3582/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0515 - acc: 0.9795 - val_loss: 0.0919 - val_acc: 0.9716\n",
            "Epoch 3583/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9810 - val_loss: 0.0881 - val_acc: 0.9721\n",
            "Epoch 3584/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0517 - acc: 0.9794 - val_loss: 0.0934 - val_acc: 0.9711\n",
            "Epoch 3585/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9816 - val_loss: 0.0897 - val_acc: 0.9696\n",
            "Epoch 3586/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0506 - acc: 0.9801 - val_loss: 0.0879 - val_acc: 0.9696\n",
            "Epoch 3587/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9788 - val_loss: 0.0937 - val_acc: 0.9682\n",
            "Epoch 3588/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0506 - acc: 0.9799 - val_loss: 0.0871 - val_acc: 0.9716\n",
            "Epoch 3589/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0508 - acc: 0.9805 - val_loss: 0.0939 - val_acc: 0.9716\n",
            "Epoch 3590/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0511 - acc: 0.9799 - val_loss: 0.0912 - val_acc: 0.9706\n",
            "Epoch 3591/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0564 - acc: 0.9777 - val_loss: 0.0885 - val_acc: 0.9721\n",
            "Epoch 3592/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0528 - acc: 0.9796 - val_loss: 0.0906 - val_acc: 0.9696\n",
            "Epoch 3593/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9799 - val_loss: 0.0870 - val_acc: 0.9706\n",
            "Epoch 3594/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9798 - val_loss: 0.0900 - val_acc: 0.9711\n",
            "Epoch 3595/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0514 - acc: 0.9793 - val_loss: 0.0925 - val_acc: 0.9682\n",
            "Epoch 3596/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9794 - val_loss: 0.1050 - val_acc: 0.9706\n",
            "Epoch 3597/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0573 - acc: 0.9772 - val_loss: 0.0959 - val_acc: 0.9691\n",
            "Epoch 3598/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0556 - acc: 0.9777 - val_loss: 0.0974 - val_acc: 0.9672\n",
            "Epoch 3599/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9795 - val_loss: 0.0852 - val_acc: 0.9716\n",
            "Epoch 3600/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9808 - val_loss: 0.0895 - val_acc: 0.9716\n",
            "Epoch 3601/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9791 - val_loss: 0.0923 - val_acc: 0.9696\n",
            "Epoch 3602/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9784 - val_loss: 0.0886 - val_acc: 0.9696\n",
            "Epoch 3603/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9799 - val_loss: 0.0880 - val_acc: 0.9711\n",
            "Epoch 3604/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9801 - val_loss: 0.0891 - val_acc: 0.9687\n",
            "Epoch 3605/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9784 - val_loss: 0.0906 - val_acc: 0.9716\n",
            "Epoch 3606/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9799 - val_loss: 0.0879 - val_acc: 0.9726\n",
            "Epoch 3607/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0564 - acc: 0.9775 - val_loss: 0.0938 - val_acc: 0.9701\n",
            "Epoch 3608/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9794 - val_loss: 0.0935 - val_acc: 0.9711\n",
            "Epoch 3609/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9782 - val_loss: 0.0841 - val_acc: 0.9721\n",
            "Epoch 3610/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0553 - acc: 0.9772 - val_loss: 0.0848 - val_acc: 0.9736\n",
            "Epoch 3611/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0548 - acc: 0.9783 - val_loss: 0.0854 - val_acc: 0.9755\n",
            "Epoch 3612/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9793 - val_loss: 0.0935 - val_acc: 0.9711\n",
            "Epoch 3613/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0544 - acc: 0.9777 - val_loss: 0.0912 - val_acc: 0.9701\n",
            "Epoch 3614/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9814 - val_loss: 0.0866 - val_acc: 0.9711\n",
            "Epoch 3615/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0499 - acc: 0.9793 - val_loss: 0.0881 - val_acc: 0.9745\n",
            "Epoch 3616/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0521 - acc: 0.9792 - val_loss: 0.0963 - val_acc: 0.9691\n",
            "Epoch 3617/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9814 - val_loss: 0.0876 - val_acc: 0.9711\n",
            "Epoch 3618/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0514 - acc: 0.9793 - val_loss: 0.0941 - val_acc: 0.9687\n",
            "Epoch 3619/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9778 - val_loss: 0.0861 - val_acc: 0.9711\n",
            "Epoch 3620/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0495 - acc: 0.9799 - val_loss: 0.0952 - val_acc: 0.9682\n",
            "Epoch 3621/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0515 - acc: 0.9797 - val_loss: 0.0831 - val_acc: 0.9750\n",
            "Epoch 3622/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0540 - acc: 0.9783 - val_loss: 0.0841 - val_acc: 0.9726\n",
            "Epoch 3623/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9797 - val_loss: 0.0932 - val_acc: 0.9701\n",
            "Epoch 3624/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9811 - val_loss: 0.0903 - val_acc: 0.9716\n",
            "Epoch 3625/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9799 - val_loss: 0.0849 - val_acc: 0.9721\n",
            "Epoch 3626/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0522 - acc: 0.9806 - val_loss: 0.0889 - val_acc: 0.9740\n",
            "Epoch 3627/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9782 - val_loss: 0.0888 - val_acc: 0.9696\n",
            "Epoch 3628/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9799 - val_loss: 0.0856 - val_acc: 0.9701\n",
            "Epoch 3629/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9804 - val_loss: 0.0880 - val_acc: 0.9726\n",
            "Epoch 3630/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0518 - acc: 0.9789 - val_loss: 0.0913 - val_acc: 0.9691\n",
            "Epoch 3631/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0491 - acc: 0.9812 - val_loss: 0.0957 - val_acc: 0.9687\n",
            "Epoch 3632/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9813 - val_loss: 0.0875 - val_acc: 0.9706\n",
            "Epoch 3633/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9798 - val_loss: 0.0829 - val_acc: 0.9736\n",
            "Epoch 3634/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9789 - val_loss: 0.0927 - val_acc: 0.9701\n",
            "Epoch 3635/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9799 - val_loss: 0.0948 - val_acc: 0.9716\n",
            "Epoch 3636/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0549 - acc: 0.9778 - val_loss: 0.0874 - val_acc: 0.9701\n",
            "Epoch 3637/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9797 - val_loss: 0.0933 - val_acc: 0.9706\n",
            "Epoch 3638/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0531 - acc: 0.9791 - val_loss: 0.0921 - val_acc: 0.9711\n",
            "Epoch 3639/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0525 - acc: 0.9796 - val_loss: 0.1050 - val_acc: 0.9638\n",
            "Epoch 3640/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0517 - acc: 0.9796 - val_loss: 0.0889 - val_acc: 0.9726\n",
            "Epoch 3641/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0529 - acc: 0.9794 - val_loss: 0.0908 - val_acc: 0.9701\n",
            "Epoch 3642/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0524 - acc: 0.9792 - val_loss: 0.0884 - val_acc: 0.9716\n",
            "Epoch 3643/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9799 - val_loss: 0.0917 - val_acc: 0.9716\n",
            "Epoch 3644/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9771 - val_loss: 0.0924 - val_acc: 0.9687\n",
            "Epoch 3645/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0499 - acc: 0.9802 - val_loss: 0.0842 - val_acc: 0.9726\n",
            "Epoch 3646/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0499 - acc: 0.9808 - val_loss: 0.0943 - val_acc: 0.9691\n",
            "Epoch 3647/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9802 - val_loss: 0.0865 - val_acc: 0.9706\n",
            "Epoch 3648/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0503 - acc: 0.9802 - val_loss: 0.0968 - val_acc: 0.9682\n",
            "Epoch 3649/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9796 - val_loss: 0.1009 - val_acc: 0.9687\n",
            "Epoch 3650/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9803 - val_loss: 0.0881 - val_acc: 0.9711\n",
            "Epoch 3651/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0516 - acc: 0.9797 - val_loss: 0.0905 - val_acc: 0.9701\n",
            "Epoch 3652/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0541 - acc: 0.9788 - val_loss: 0.0925 - val_acc: 0.9691\n",
            "Epoch 3653/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0540 - acc: 0.9799 - val_loss: 0.0887 - val_acc: 0.9701\n",
            "Epoch 3654/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0529 - acc: 0.9797 - val_loss: 0.0901 - val_acc: 0.9706\n",
            "Epoch 3655/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0509 - acc: 0.9810 - val_loss: 0.0939 - val_acc: 0.9696\n",
            "Epoch 3656/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9791 - val_loss: 0.0863 - val_acc: 0.9716\n",
            "Epoch 3657/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9810 - val_loss: 0.0907 - val_acc: 0.9716\n",
            "Epoch 3658/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9798 - val_loss: 0.0862 - val_acc: 0.9736\n",
            "Epoch 3659/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0501 - acc: 0.9813 - val_loss: 0.0909 - val_acc: 0.9711\n",
            "Epoch 3660/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0514 - acc: 0.9791 - val_loss: 0.1011 - val_acc: 0.9672\n",
            "Epoch 3661/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0479 - acc: 0.9808 - val_loss: 0.0923 - val_acc: 0.9716\n",
            "Epoch 3662/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0489 - acc: 0.9817 - val_loss: 0.0908 - val_acc: 0.9691\n",
            "Epoch 3663/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0509 - acc: 0.9788 - val_loss: 0.0997 - val_acc: 0.9716\n",
            "Epoch 3664/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9790 - val_loss: 0.0880 - val_acc: 0.9716\n",
            "Epoch 3665/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0487 - acc: 0.9804 - val_loss: 0.0946 - val_acc: 0.9672\n",
            "Epoch 3666/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0508 - acc: 0.9785 - val_loss: 0.0892 - val_acc: 0.9716\n",
            "Epoch 3667/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0480 - acc: 0.9808 - val_loss: 0.0965 - val_acc: 0.9696\n",
            "Epoch 3668/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0464 - acc: 0.9813 - val_loss: 0.0851 - val_acc: 0.9750\n",
            "Epoch 3669/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9809 - val_loss: 0.0926 - val_acc: 0.9696\n",
            "Epoch 3670/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9791 - val_loss: 0.0884 - val_acc: 0.9736\n",
            "Epoch 3671/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9793 - val_loss: 0.0927 - val_acc: 0.9706\n",
            "Epoch 3672/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0507 - acc: 0.9809 - val_loss: 0.0870 - val_acc: 0.9706\n",
            "Epoch 3673/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0479 - acc: 0.9812 - val_loss: 0.0970 - val_acc: 0.9696\n",
            "Epoch 3674/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0527 - acc: 0.9786 - val_loss: 0.0897 - val_acc: 0.9736\n",
            "Epoch 3675/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0514 - acc: 0.9801 - val_loss: 0.0916 - val_acc: 0.9696\n",
            "Epoch 3676/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0505 - acc: 0.9804 - val_loss: 0.0856 - val_acc: 0.9726\n",
            "Epoch 3677/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0479 - acc: 0.9805 - val_loss: 0.0842 - val_acc: 0.9740\n",
            "Epoch 3678/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9806 - val_loss: 0.0982 - val_acc: 0.9687\n",
            "Epoch 3679/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9789 - val_loss: 0.0972 - val_acc: 0.9706\n",
            "Epoch 3680/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9804 - val_loss: 0.0929 - val_acc: 0.9711\n",
            "Epoch 3681/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0468 - acc: 0.9817 - val_loss: 0.0911 - val_acc: 0.9721\n",
            "Epoch 3682/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9801 - val_loss: 0.0886 - val_acc: 0.9726\n",
            "Epoch 3683/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9799 - val_loss: 0.0838 - val_acc: 0.9736\n",
            "Epoch 3684/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0515 - acc: 0.9789 - val_loss: 0.0849 - val_acc: 0.9721\n",
            "Epoch 3685/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9799 - val_loss: 0.0869 - val_acc: 0.9701\n",
            "Epoch 3686/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0526 - acc: 0.9803 - val_loss: 0.0931 - val_acc: 0.9721\n",
            "Epoch 3687/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9791 - val_loss: 0.0912 - val_acc: 0.9701\n",
            "Epoch 3688/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9809 - val_loss: 0.0964 - val_acc: 0.9696\n",
            "Epoch 3689/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0523 - acc: 0.9798 - val_loss: 0.0870 - val_acc: 0.9711\n",
            "Epoch 3690/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0502 - acc: 0.9811 - val_loss: 0.1032 - val_acc: 0.9647\n",
            "Epoch 3691/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0488 - acc: 0.9804 - val_loss: 0.0904 - val_acc: 0.9726\n",
            "Epoch 3692/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9806 - val_loss: 0.0845 - val_acc: 0.9726\n",
            "Epoch 3693/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0509 - acc: 0.9803 - val_loss: 0.0983 - val_acc: 0.9667\n",
            "Epoch 3694/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0505 - acc: 0.9799 - val_loss: 0.0805 - val_acc: 0.9721\n",
            "Epoch 3695/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9805 - val_loss: 0.0864 - val_acc: 0.9682\n",
            "Epoch 3696/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9823 - val_loss: 0.0888 - val_acc: 0.9706\n",
            "Epoch 3697/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9801 - val_loss: 0.0970 - val_acc: 0.9696\n",
            "Epoch 3698/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0514 - acc: 0.9798 - val_loss: 0.0954 - val_acc: 0.9687\n",
            "Epoch 3699/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9794 - val_loss: 0.0911 - val_acc: 0.9731\n",
            "Epoch 3700/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0520 - acc: 0.9799 - val_loss: 0.0900 - val_acc: 0.9711\n",
            "Epoch 3701/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9806 - val_loss: 0.0881 - val_acc: 0.9726\n",
            "Epoch 3702/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0532 - acc: 0.9785 - val_loss: 0.0926 - val_acc: 0.9682\n",
            "Epoch 3703/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9801 - val_loss: 0.0886 - val_acc: 0.9731\n",
            "Epoch 3704/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0503 - acc: 0.9797 - val_loss: 0.0898 - val_acc: 0.9721\n",
            "Epoch 3705/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9806 - val_loss: 0.0938 - val_acc: 0.9691\n",
            "Epoch 3706/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0532 - acc: 0.9791 - val_loss: 0.0922 - val_acc: 0.9706\n",
            "Epoch 3707/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0528 - acc: 0.9797 - val_loss: 0.0900 - val_acc: 0.9721\n",
            "Epoch 3708/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0501 - acc: 0.9785 - val_loss: 0.0939 - val_acc: 0.9687\n",
            "Epoch 3709/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9782 - val_loss: 0.0950 - val_acc: 0.9672\n",
            "Epoch 3710/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9795 - val_loss: 0.0900 - val_acc: 0.9706\n",
            "Epoch 3711/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9791 - val_loss: 0.0823 - val_acc: 0.9745\n",
            "Epoch 3712/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0501 - acc: 0.9807 - val_loss: 0.0858 - val_acc: 0.9736\n",
            "Epoch 3713/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0869 - val_acc: 0.9706\n",
            "Epoch 3714/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9802 - val_loss: 0.0839 - val_acc: 0.9711\n",
            "Epoch 3715/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.0816 - val_acc: 0.9721\n",
            "Epoch 3716/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9810 - val_loss: 0.0908 - val_acc: 0.9701\n",
            "Epoch 3717/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9794 - val_loss: 0.0968 - val_acc: 0.9677\n",
            "Epoch 3718/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0495 - acc: 0.9796 - val_loss: 0.0914 - val_acc: 0.9706\n",
            "Epoch 3719/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0509 - acc: 0.9785 - val_loss: 0.0918 - val_acc: 0.9706\n",
            "Epoch 3720/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9789 - val_loss: 0.0906 - val_acc: 0.9716\n",
            "Epoch 3721/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9796 - val_loss: 0.0941 - val_acc: 0.9682\n",
            "Epoch 3722/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0511 - acc: 0.9797 - val_loss: 0.0936 - val_acc: 0.9716\n",
            "Epoch 3723/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0522 - acc: 0.9797 - val_loss: 0.0935 - val_acc: 0.9711\n",
            "Epoch 3724/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9810 - val_loss: 0.0942 - val_acc: 0.9721\n",
            "Epoch 3725/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0512 - acc: 0.9796 - val_loss: 0.0947 - val_acc: 0.9696\n",
            "Epoch 3726/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0489 - acc: 0.9813 - val_loss: 0.0942 - val_acc: 0.9682\n",
            "Epoch 3727/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0509 - acc: 0.9793 - val_loss: 0.0887 - val_acc: 0.9716\n",
            "Epoch 3728/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9793 - val_loss: 0.0862 - val_acc: 0.9706\n",
            "Epoch 3729/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9785 - val_loss: 0.0854 - val_acc: 0.9701\n",
            "Epoch 3730/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9811 - val_loss: 0.0973 - val_acc: 0.9701\n",
            "Epoch 3731/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9796 - val_loss: 0.0858 - val_acc: 0.9731\n",
            "Epoch 3732/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9808 - val_loss: 0.0881 - val_acc: 0.9721\n",
            "Epoch 3733/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0520 - acc: 0.9795 - val_loss: 0.0951 - val_acc: 0.9677\n",
            "Epoch 3734/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0469 - acc: 0.9829 - val_loss: 0.0900 - val_acc: 0.9721\n",
            "Epoch 3735/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9799 - val_loss: 0.0866 - val_acc: 0.9740\n",
            "Epoch 3736/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9805 - val_loss: 0.0903 - val_acc: 0.9701\n",
            "Epoch 3737/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0494 - acc: 0.9796 - val_loss: 0.0902 - val_acc: 0.9736\n",
            "Epoch 3738/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0515 - acc: 0.9796 - val_loss: 0.0949 - val_acc: 0.9687\n",
            "Epoch 3739/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9808 - val_loss: 0.0865 - val_acc: 0.9721\n",
            "Epoch 3740/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9810 - val_loss: 0.0917 - val_acc: 0.9691\n",
            "Epoch 3741/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9805 - val_loss: 0.0903 - val_acc: 0.9682\n",
            "Epoch 3742/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0537 - acc: 0.9781 - val_loss: 0.0955 - val_acc: 0.9691\n",
            "Epoch 3743/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0517 - acc: 0.9801 - val_loss: 0.0930 - val_acc: 0.9701\n",
            "Epoch 3744/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9804 - val_loss: 0.0914 - val_acc: 0.9711\n",
            "Epoch 3745/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0485 - acc: 0.9810 - val_loss: 0.0979 - val_acc: 0.9721\n",
            "Epoch 3746/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0473 - acc: 0.9813 - val_loss: 0.0933 - val_acc: 0.9701\n",
            "Epoch 3747/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9810 - val_loss: 0.0975 - val_acc: 0.9696\n",
            "Epoch 3748/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9793 - val_loss: 0.0906 - val_acc: 0.9721\n",
            "Epoch 3749/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9814 - val_loss: 0.0883 - val_acc: 0.9740\n",
            "Epoch 3750/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9797 - val_loss: 0.0925 - val_acc: 0.9716\n",
            "Epoch 3751/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0483 - acc: 0.9806 - val_loss: 0.0892 - val_acc: 0.9721\n",
            "Epoch 3752/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0541 - acc: 0.9786 - val_loss: 0.0944 - val_acc: 0.9672\n",
            "Epoch 3753/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0989 - val_acc: 0.9691\n",
            "Epoch 3754/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9808 - val_loss: 0.0931 - val_acc: 0.9721\n",
            "Epoch 3755/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9797 - val_loss: 0.0965 - val_acc: 0.9726\n",
            "Epoch 3756/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9816 - val_loss: 0.0889 - val_acc: 0.9716\n",
            "Epoch 3757/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9809 - val_loss: 0.0868 - val_acc: 0.9716\n",
            "Epoch 3758/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9793 - val_loss: 0.0977 - val_acc: 0.9716\n",
            "Epoch 3759/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0487 - acc: 0.9808 - val_loss: 0.0899 - val_acc: 0.9750\n",
            "Epoch 3760/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0488 - acc: 0.9799 - val_loss: 0.0868 - val_acc: 0.9750\n",
            "Epoch 3761/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0500 - acc: 0.9812 - val_loss: 0.0970 - val_acc: 0.9711\n",
            "Epoch 3762/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0490 - acc: 0.9813 - val_loss: 0.0915 - val_acc: 0.9706\n",
            "Epoch 3763/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0482 - acc: 0.9812 - val_loss: 0.0912 - val_acc: 0.9721\n",
            "Epoch 3764/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9812 - val_loss: 0.0954 - val_acc: 0.9716\n",
            "Epoch 3765/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0452 - acc: 0.9818 - val_loss: 0.0925 - val_acc: 0.9711\n",
            "Epoch 3766/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9812 - val_loss: 0.0917 - val_acc: 0.9716\n",
            "Epoch 3767/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9826 - val_loss: 0.0911 - val_acc: 0.9736\n",
            "Epoch 3768/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0495 - acc: 0.9797 - val_loss: 0.0859 - val_acc: 0.9711\n",
            "Epoch 3769/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9812 - val_loss: 0.0899 - val_acc: 0.9706\n",
            "Epoch 3770/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9799 - val_loss: 0.0929 - val_acc: 0.9701\n",
            "Epoch 3771/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9791 - val_loss: 0.0985 - val_acc: 0.9682\n",
            "Epoch 3772/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0517 - acc: 0.9793 - val_loss: 0.0943 - val_acc: 0.9736\n",
            "Epoch 3773/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9799 - val_loss: 0.0979 - val_acc: 0.9682\n",
            "Epoch 3774/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0525 - acc: 0.9789 - val_loss: 0.0945 - val_acc: 0.9706\n",
            "Epoch 3775/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0507 - acc: 0.9803 - val_loss: 0.0955 - val_acc: 0.9657\n",
            "Epoch 3776/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9801 - val_loss: 0.0880 - val_acc: 0.9721\n",
            "Epoch 3777/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0497 - acc: 0.9794 - val_loss: 0.0954 - val_acc: 0.9736\n",
            "Epoch 3778/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9793 - val_loss: 0.0930 - val_acc: 0.9662\n",
            "Epoch 3779/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9810 - val_loss: 0.1018 - val_acc: 0.9662\n",
            "Epoch 3780/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0515 - acc: 0.9807 - val_loss: 0.1029 - val_acc: 0.9691\n",
            "Epoch 3781/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0463 - acc: 0.9818 - val_loss: 0.0909 - val_acc: 0.9736\n",
            "Epoch 3782/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0505 - acc: 0.9805 - val_loss: 0.0991 - val_acc: 0.9716\n",
            "Epoch 3783/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0506 - acc: 0.9802 - val_loss: 0.0898 - val_acc: 0.9672\n",
            "Epoch 3784/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0536 - acc: 0.9785 - val_loss: 0.0877 - val_acc: 0.9740\n",
            "Epoch 3785/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9802 - val_loss: 0.0876 - val_acc: 0.9736\n",
            "Epoch 3786/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9801 - val_loss: 0.0938 - val_acc: 0.9706\n",
            "Epoch 3787/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9815 - val_loss: 0.0980 - val_acc: 0.9701\n",
            "Epoch 3788/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9799 - val_loss: 0.0913 - val_acc: 0.9696\n",
            "Epoch 3789/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0514 - acc: 0.9789 - val_loss: 0.0898 - val_acc: 0.9691\n",
            "Epoch 3790/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9800 - val_loss: 0.0907 - val_acc: 0.9672\n",
            "Epoch 3791/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0503 - acc: 0.9793 - val_loss: 0.0915 - val_acc: 0.9716\n",
            "Epoch 3792/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9813 - val_loss: 0.0963 - val_acc: 0.9682\n",
            "Epoch 3793/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0533 - acc: 0.9784 - val_loss: 0.0946 - val_acc: 0.9691\n",
            "Epoch 3794/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9801 - val_loss: 0.0857 - val_acc: 0.9736\n",
            "Epoch 3795/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9808 - val_loss: 0.1004 - val_acc: 0.9672\n",
            "Epoch 3796/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0473 - acc: 0.9809 - val_loss: 0.0873 - val_acc: 0.9721\n",
            "Epoch 3797/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0526 - acc: 0.9790 - val_loss: 0.0888 - val_acc: 0.9736\n",
            "Epoch 3798/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9791 - val_loss: 0.0898 - val_acc: 0.9721\n",
            "Epoch 3799/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0490 - acc: 0.9804 - val_loss: 0.0962 - val_acc: 0.9691\n",
            "Epoch 3800/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9809 - val_loss: 0.0928 - val_acc: 0.9701\n",
            "Epoch 3801/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9808 - val_loss: 0.0936 - val_acc: 0.9687\n",
            "Epoch 3802/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0518 - acc: 0.9786 - val_loss: 0.0967 - val_acc: 0.9667\n",
            "Epoch 3803/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0518 - acc: 0.9780 - val_loss: 0.0890 - val_acc: 0.9696\n",
            "Epoch 3804/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0466 - acc: 0.9812 - val_loss: 0.0969 - val_acc: 0.9701\n",
            "Epoch 3805/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9797 - val_loss: 0.1017 - val_acc: 0.9691\n",
            "Epoch 3806/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0506 - acc: 0.9789 - val_loss: 0.0984 - val_acc: 0.9667\n",
            "Epoch 3807/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9815 - val_loss: 0.0977 - val_acc: 0.9701\n",
            "Epoch 3808/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0480 - acc: 0.9816 - val_loss: 0.0934 - val_acc: 0.9721\n",
            "Epoch 3809/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9808 - val_loss: 0.0852 - val_acc: 0.9731\n",
            "Epoch 3810/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9810 - val_loss: 0.0937 - val_acc: 0.9721\n",
            "Epoch 3811/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9801 - val_loss: 0.0833 - val_acc: 0.9726\n",
            "Epoch 3812/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0500 - acc: 0.9807 - val_loss: 0.0888 - val_acc: 0.9711\n",
            "Epoch 3813/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0475 - acc: 0.9808 - val_loss: 0.0830 - val_acc: 0.9731\n",
            "Epoch 3814/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9803 - val_loss: 0.0886 - val_acc: 0.9721\n",
            "Epoch 3815/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0467 - acc: 0.9814 - val_loss: 0.1025 - val_acc: 0.9662\n",
            "Epoch 3816/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9810 - val_loss: 0.0947 - val_acc: 0.9711\n",
            "Epoch 3817/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0526 - acc: 0.9802 - val_loss: 0.1019 - val_acc: 0.9682\n",
            "Epoch 3818/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9792 - val_loss: 0.0908 - val_acc: 0.9696\n",
            "Epoch 3819/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9801 - val_loss: 0.0883 - val_acc: 0.9716\n",
            "Epoch 3820/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0513 - acc: 0.9796 - val_loss: 0.0950 - val_acc: 0.9706\n",
            "Epoch 3821/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9808 - val_loss: 0.1016 - val_acc: 0.9672\n",
            "Epoch 3822/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9807 - val_loss: 0.0906 - val_acc: 0.9721\n",
            "Epoch 3823/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0485 - acc: 0.9798 - val_loss: 0.0924 - val_acc: 0.9706\n",
            "Epoch 3824/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0504 - acc: 0.9796 - val_loss: 0.0950 - val_acc: 0.9716\n",
            "Epoch 3825/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0491 - acc: 0.9812 - val_loss: 0.0916 - val_acc: 0.9672\n",
            "Epoch 3826/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0519 - acc: 0.9800 - val_loss: 0.0908 - val_acc: 0.9726\n",
            "Epoch 3827/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9800 - val_loss: 0.0909 - val_acc: 0.9687\n",
            "Epoch 3828/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9809 - val_loss: 0.0867 - val_acc: 0.9745\n",
            "Epoch 3829/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0464 - acc: 0.9812 - val_loss: 0.0930 - val_acc: 0.9691\n",
            "Epoch 3830/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0509 - acc: 0.9802 - val_loss: 0.1139 - val_acc: 0.9647\n",
            "Epoch 3831/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0480 - acc: 0.9807 - val_loss: 0.0869 - val_acc: 0.9755\n",
            "Epoch 3832/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0455 - acc: 0.9826 - val_loss: 0.0920 - val_acc: 0.9721\n",
            "Epoch 3833/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0503 - acc: 0.9792 - val_loss: 0.0949 - val_acc: 0.9711\n",
            "Epoch 3834/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0503 - acc: 0.9800 - val_loss: 0.0911 - val_acc: 0.9706\n",
            "Epoch 3835/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9796 - val_loss: 0.0905 - val_acc: 0.9701\n",
            "Epoch 3836/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0539 - acc: 0.9784 - val_loss: 0.0918 - val_acc: 0.9706\n",
            "Epoch 3837/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0518 - acc: 0.9791 - val_loss: 0.0976 - val_acc: 0.9682\n",
            "Epoch 3838/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0536 - acc: 0.9796 - val_loss: 0.0935 - val_acc: 0.9726\n",
            "Epoch 3839/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0526 - acc: 0.9784 - val_loss: 0.0942 - val_acc: 0.9716\n",
            "Epoch 3840/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0487 - acc: 0.9805 - val_loss: 0.0947 - val_acc: 0.9677\n",
            "Epoch 3841/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0460 - acc: 0.9827 - val_loss: 0.0930 - val_acc: 0.9711\n",
            "Epoch 3842/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9804 - val_loss: 0.0868 - val_acc: 0.9740\n",
            "Epoch 3843/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0495 - acc: 0.9793 - val_loss: 0.0869 - val_acc: 0.9711\n",
            "Epoch 3844/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9816 - val_loss: 0.0850 - val_acc: 0.9726\n",
            "Epoch 3845/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9803 - val_loss: 0.0875 - val_acc: 0.9721\n",
            "Epoch 3846/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9811 - val_loss: 0.0898 - val_acc: 0.9731\n",
            "Epoch 3847/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0496 - acc: 0.9805 - val_loss: 0.0923 - val_acc: 0.9726\n",
            "Epoch 3848/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9803 - val_loss: 0.0857 - val_acc: 0.9726\n",
            "Epoch 3849/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0494 - acc: 0.9808 - val_loss: 0.0880 - val_acc: 0.9716\n",
            "Epoch 3850/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9805 - val_loss: 0.0889 - val_acc: 0.9711\n",
            "Epoch 3851/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9799 - val_loss: 0.0962 - val_acc: 0.9687\n",
            "Epoch 3852/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9816 - val_loss: 0.0965 - val_acc: 0.9677\n",
            "Epoch 3853/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0519 - acc: 0.9793 - val_loss: 0.0890 - val_acc: 0.9745\n",
            "Epoch 3854/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0502 - acc: 0.9809 - val_loss: 0.0926 - val_acc: 0.9731\n",
            "Epoch 3855/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0491 - acc: 0.9809 - val_loss: 0.0967 - val_acc: 0.9691\n",
            "Epoch 3856/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9821 - val_loss: 0.0932 - val_acc: 0.9701\n",
            "Epoch 3857/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0498 - acc: 0.9803 - val_loss: 0.0968 - val_acc: 0.9677\n",
            "Epoch 3858/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0500 - acc: 0.9791 - val_loss: 0.0962 - val_acc: 0.9726\n",
            "Epoch 3859/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0462 - acc: 0.9813 - val_loss: 0.0847 - val_acc: 0.9736\n",
            "Epoch 3860/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0459 - acc: 0.9810 - val_loss: 0.0943 - val_acc: 0.9696\n",
            "Epoch 3861/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9816 - val_loss: 0.0876 - val_acc: 0.9721\n",
            "Epoch 3862/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0498 - acc: 0.9806 - val_loss: 0.0930 - val_acc: 0.9696\n",
            "Epoch 3863/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9815 - val_loss: 0.0929 - val_acc: 0.9677\n",
            "Epoch 3864/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9810 - val_loss: 0.1011 - val_acc: 0.9691\n",
            "Epoch 3865/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0475 - acc: 0.9815 - val_loss: 0.0964 - val_acc: 0.9731\n",
            "Epoch 3866/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9815 - val_loss: 0.1154 - val_acc: 0.9662\n",
            "Epoch 3867/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0461 - acc: 0.9816 - val_loss: 0.0916 - val_acc: 0.9721\n",
            "Epoch 3868/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0488 - acc: 0.9800 - val_loss: 0.0891 - val_acc: 0.9736\n",
            "Epoch 3869/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9808 - val_loss: 0.1031 - val_acc: 0.9672\n",
            "Epoch 3870/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0521 - acc: 0.9793 - val_loss: 0.1031 - val_acc: 0.9662\n",
            "Epoch 3871/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0494 - acc: 0.9796 - val_loss: 0.1179 - val_acc: 0.9657\n",
            "Epoch 3872/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0466 - acc: 0.9818 - val_loss: 0.0911 - val_acc: 0.9726\n",
            "Epoch 3873/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0468 - acc: 0.9828 - val_loss: 0.0914 - val_acc: 0.9731\n",
            "Epoch 3874/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0516 - acc: 0.9802 - val_loss: 0.0908 - val_acc: 0.9731\n",
            "Epoch 3875/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9801 - val_loss: 0.1012 - val_acc: 0.9647\n",
            "Epoch 3876/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0486 - acc: 0.9804 - val_loss: 0.0989 - val_acc: 0.9701\n",
            "Epoch 3877/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0499 - acc: 0.9810 - val_loss: 0.0904 - val_acc: 0.9745\n",
            "Epoch 3878/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9821 - val_loss: 0.0895 - val_acc: 0.9716\n",
            "Epoch 3879/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9814 - val_loss: 0.0926 - val_acc: 0.9716\n",
            "Epoch 3880/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0512 - acc: 0.9792 - val_loss: 0.0958 - val_acc: 0.9687\n",
            "Epoch 3881/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0483 - acc: 0.9807 - val_loss: 0.0915 - val_acc: 0.9716\n",
            "Epoch 3882/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0537 - acc: 0.9780 - val_loss: 0.0971 - val_acc: 0.9677\n",
            "Epoch 3883/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0491 - acc: 0.9807 - val_loss: 0.0891 - val_acc: 0.9736\n",
            "Epoch 3884/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0457 - acc: 0.9818 - val_loss: 0.0960 - val_acc: 0.9691\n",
            "Epoch 3885/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9812 - val_loss: 0.0918 - val_acc: 0.9701\n",
            "Epoch 3886/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9823 - val_loss: 0.0832 - val_acc: 0.9770\n",
            "Epoch 3887/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9813 - val_loss: 0.0875 - val_acc: 0.9726\n",
            "Epoch 3888/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9797 - val_loss: 0.0948 - val_acc: 0.9706\n",
            "Epoch 3889/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0491 - acc: 0.9805 - val_loss: 0.0986 - val_acc: 0.9711\n",
            "Epoch 3890/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0509 - acc: 0.9794 - val_loss: 0.0939 - val_acc: 0.9716\n",
            "Epoch 3891/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0490 - acc: 0.9812 - val_loss: 0.0870 - val_acc: 0.9731\n",
            "Epoch 3892/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9812 - val_loss: 0.1002 - val_acc: 0.9687\n",
            "Epoch 3893/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0561 - acc: 0.9785 - val_loss: 0.0944 - val_acc: 0.9716\n",
            "Epoch 3894/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0524 - acc: 0.9788 - val_loss: 0.0921 - val_acc: 0.9731\n",
            "Epoch 3895/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0480 - acc: 0.9815 - val_loss: 0.0910 - val_acc: 0.9721\n",
            "Epoch 3896/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0446 - acc: 0.9821 - val_loss: 0.0884 - val_acc: 0.9726\n",
            "Epoch 3897/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0482 - acc: 0.9803 - val_loss: 0.1013 - val_acc: 0.9677\n",
            "Epoch 3898/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9812 - val_loss: 0.0877 - val_acc: 0.9711\n",
            "Epoch 3899/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9797 - val_loss: 0.0968 - val_acc: 0.9701\n",
            "Epoch 3900/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0506 - acc: 0.9791 - val_loss: 0.1030 - val_acc: 0.9696\n",
            "Epoch 3901/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0522 - acc: 0.9777 - val_loss: 0.0858 - val_acc: 0.9716\n",
            "Epoch 3902/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9816 - val_loss: 0.0967 - val_acc: 0.9701\n",
            "Epoch 3903/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9816 - val_loss: 0.0891 - val_acc: 0.9731\n",
            "Epoch 3904/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0527 - acc: 0.9796 - val_loss: 0.0960 - val_acc: 0.9711\n",
            "Epoch 3905/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9812 - val_loss: 0.0923 - val_acc: 0.9726\n",
            "Epoch 3906/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9808 - val_loss: 0.1166 - val_acc: 0.9613\n",
            "Epoch 3907/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9802 - val_loss: 0.0932 - val_acc: 0.9691\n",
            "Epoch 3908/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0485 - acc: 0.9798 - val_loss: 0.0997 - val_acc: 0.9677\n",
            "Epoch 3909/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9808 - val_loss: 0.0917 - val_acc: 0.9731\n",
            "Epoch 3910/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9793 - val_loss: 0.0879 - val_acc: 0.9696\n",
            "Epoch 3911/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0451 - acc: 0.9829 - val_loss: 0.0998 - val_acc: 0.9701\n",
            "Epoch 3912/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9819 - val_loss: 0.1028 - val_acc: 0.9662\n",
            "Epoch 3913/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0494 - acc: 0.9809 - val_loss: 0.0883 - val_acc: 0.9706\n",
            "Epoch 3914/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9801 - val_loss: 0.0908 - val_acc: 0.9696\n",
            "Epoch 3915/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9808 - val_loss: 0.0887 - val_acc: 0.9721\n",
            "Epoch 3916/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9813 - val_loss: 0.0949 - val_acc: 0.9711\n",
            "Epoch 3917/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0478 - acc: 0.9817 - val_loss: 0.0954 - val_acc: 0.9687\n",
            "Epoch 3918/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0477 - acc: 0.9811 - val_loss: 0.0923 - val_acc: 0.9706\n",
            "Epoch 3919/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.0923 - val_acc: 0.9731\n",
            "Epoch 3920/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0443 - acc: 0.9826 - val_loss: 0.0939 - val_acc: 0.9691\n",
            "Epoch 3921/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0437 - acc: 0.9822 - val_loss: 0.1132 - val_acc: 0.9687\n",
            "Epoch 3922/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0484 - acc: 0.9813 - val_loss: 0.0904 - val_acc: 0.9721\n",
            "Epoch 3923/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0485 - acc: 0.9803 - val_loss: 0.0936 - val_acc: 0.9716\n",
            "Epoch 3924/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0475 - acc: 0.9821 - val_loss: 0.1030 - val_acc: 0.9691\n",
            "Epoch 3925/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9807 - val_loss: 0.1060 - val_acc: 0.9701\n",
            "Epoch 3926/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0440 - acc: 0.9835 - val_loss: 0.0958 - val_acc: 0.9691\n",
            "Epoch 3927/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0496 - acc: 0.9803 - val_loss: 0.1023 - val_acc: 0.9701\n",
            "Epoch 3928/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0490 - acc: 0.9816 - val_loss: 0.0981 - val_acc: 0.9657\n",
            "Epoch 3929/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9808 - val_loss: 0.0969 - val_acc: 0.9691\n",
            "Epoch 3930/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0492 - acc: 0.9813 - val_loss: 0.0965 - val_acc: 0.9721\n",
            "Epoch 3931/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0458 - acc: 0.9825 - val_loss: 0.0947 - val_acc: 0.9716\n",
            "Epoch 3932/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9822 - val_loss: 0.0952 - val_acc: 0.9706\n",
            "Epoch 3933/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9801 - val_loss: 0.0974 - val_acc: 0.9726\n",
            "Epoch 3934/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0473 - acc: 0.9811 - val_loss: 0.0928 - val_acc: 0.9711\n",
            "Epoch 3935/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9812 - val_loss: 0.0931 - val_acc: 0.9716\n",
            "Epoch 3936/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0460 - acc: 0.9818 - val_loss: 0.0898 - val_acc: 0.9706\n",
            "Epoch 3937/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9802 - val_loss: 0.0970 - val_acc: 0.9701\n",
            "Epoch 3938/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9832 - val_loss: 0.1074 - val_acc: 0.9672\n",
            "Epoch 3939/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0477 - acc: 0.9812 - val_loss: 0.1067 - val_acc: 0.9677\n",
            "Epoch 3940/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9826 - val_loss: 0.0863 - val_acc: 0.9760\n",
            "Epoch 3941/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0494 - acc: 0.9812 - val_loss: 0.0942 - val_acc: 0.9721\n",
            "Epoch 3942/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9816 - val_loss: 0.0986 - val_acc: 0.9706\n",
            "Epoch 3943/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9790 - val_loss: 0.0917 - val_acc: 0.9731\n",
            "Epoch 3944/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0491 - acc: 0.9805 - val_loss: 0.0946 - val_acc: 0.9726\n",
            "Epoch 3945/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0484 - acc: 0.9808 - val_loss: 0.0961 - val_acc: 0.9711\n",
            "Epoch 3946/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9813 - val_loss: 0.0946 - val_acc: 0.9691\n",
            "Epoch 3947/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0476 - acc: 0.9821 - val_loss: 0.1032 - val_acc: 0.9672\n",
            "Epoch 3948/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0497 - acc: 0.9807 - val_loss: 0.0894 - val_acc: 0.9731\n",
            "Epoch 3949/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0485 - acc: 0.9809 - val_loss: 0.1034 - val_acc: 0.9701\n",
            "Epoch 3950/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0475 - acc: 0.9810 - val_loss: 0.0962 - val_acc: 0.9716\n",
            "Epoch 3951/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0469 - acc: 0.9813 - val_loss: 0.0950 - val_acc: 0.9711\n",
            "Epoch 3952/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0504 - acc: 0.9809 - val_loss: 0.0922 - val_acc: 0.9721\n",
            "Epoch 3953/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9810 - val_loss: 0.0929 - val_acc: 0.9696\n",
            "Epoch 3954/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9815 - val_loss: 0.0921 - val_acc: 0.9711\n",
            "Epoch 3955/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9825 - val_loss: 0.0921 - val_acc: 0.9721\n",
            "Epoch 3956/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9816 - val_loss: 0.0932 - val_acc: 0.9701\n",
            "Epoch 3957/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0444 - acc: 0.9829 - val_loss: 0.1096 - val_acc: 0.9662\n",
            "Epoch 3958/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9801 - val_loss: 0.1018 - val_acc: 0.9687\n",
            "Epoch 3959/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0496 - acc: 0.9802 - val_loss: 0.0937 - val_acc: 0.9706\n",
            "Epoch 3960/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9823 - val_loss: 0.1042 - val_acc: 0.9687\n",
            "Epoch 3961/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9810 - val_loss: 0.0926 - val_acc: 0.9706\n",
            "Epoch 3962/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9824 - val_loss: 0.0945 - val_acc: 0.9687\n",
            "Epoch 3963/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0502 - acc: 0.9792 - val_loss: 0.0958 - val_acc: 0.9711\n",
            "Epoch 3964/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9818 - val_loss: 0.0996 - val_acc: 0.9701\n",
            "Epoch 3965/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0473 - acc: 0.9812 - val_loss: 0.0938 - val_acc: 0.9721\n",
            "Epoch 3966/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0451 - acc: 0.9832 - val_loss: 0.0868 - val_acc: 0.9740\n",
            "Epoch 3967/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9812 - val_loss: 0.1067 - val_acc: 0.9682\n",
            "Epoch 3968/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9810 - val_loss: 0.0905 - val_acc: 0.9726\n",
            "Epoch 3969/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9815 - val_loss: 0.0895 - val_acc: 0.9701\n",
            "Epoch 3970/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9813 - val_loss: 0.0923 - val_acc: 0.9711\n",
            "Epoch 3971/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9802 - val_loss: 0.0892 - val_acc: 0.9736\n",
            "Epoch 3972/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9794 - val_loss: 0.0968 - val_acc: 0.9706\n",
            "Epoch 3973/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0438 - acc: 0.9829 - val_loss: 0.0954 - val_acc: 0.9726\n",
            "Epoch 3974/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9806 - val_loss: 0.0921 - val_acc: 0.9687\n",
            "Epoch 3975/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0477 - acc: 0.9808 - val_loss: 0.0928 - val_acc: 0.9736\n",
            "Epoch 3976/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0479 - acc: 0.9810 - val_loss: 0.0919 - val_acc: 0.9711\n",
            "Epoch 3977/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0489 - acc: 0.9802 - val_loss: 0.0875 - val_acc: 0.9731\n",
            "Epoch 3978/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0510 - acc: 0.9794 - val_loss: 0.0916 - val_acc: 0.9711\n",
            "Epoch 3979/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9815 - val_loss: 0.0970 - val_acc: 0.9687\n",
            "Epoch 3980/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0458 - acc: 0.9822 - val_loss: 0.0904 - val_acc: 0.9711\n",
            "Epoch 3981/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9818 - val_loss: 0.0942 - val_acc: 0.9721\n",
            "Epoch 3982/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0460 - acc: 0.9818 - val_loss: 0.0932 - val_acc: 0.9706\n",
            "Epoch 3983/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0451 - acc: 0.9809 - val_loss: 0.0932 - val_acc: 0.9721\n",
            "Epoch 3984/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0462 - acc: 0.9810 - val_loss: 0.1023 - val_acc: 0.9662\n",
            "Epoch 3985/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0448 - acc: 0.9823 - val_loss: 0.0936 - val_acc: 0.9731\n",
            "Epoch 3986/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0433 - acc: 0.9837 - val_loss: 0.0945 - val_acc: 0.9716\n",
            "Epoch 3987/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0486 - acc: 0.9809 - val_loss: 0.0989 - val_acc: 0.9701\n",
            "Epoch 3988/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0457 - acc: 0.9820 - val_loss: 0.0924 - val_acc: 0.9721\n",
            "Epoch 3989/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9819 - val_loss: 0.0955 - val_acc: 0.9706\n",
            "Epoch 3990/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9814 - val_loss: 0.1035 - val_acc: 0.9691\n",
            "Epoch 3991/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0450 - acc: 0.9823 - val_loss: 0.0913 - val_acc: 0.9731\n",
            "Epoch 3992/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0528 - acc: 0.9792 - val_loss: 0.0965 - val_acc: 0.9711\n",
            "Epoch 3993/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0479 - acc: 0.9805 - val_loss: 0.0977 - val_acc: 0.9711\n",
            "Epoch 3994/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0507 - acc: 0.9805 - val_loss: 0.0927 - val_acc: 0.9696\n",
            "Epoch 3995/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0455 - acc: 0.9820 - val_loss: 0.0874 - val_acc: 0.9721\n",
            "Epoch 3996/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0481 - acc: 0.9799 - val_loss: 0.0945 - val_acc: 0.9706\n",
            "Epoch 3997/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0479 - acc: 0.9807 - val_loss: 0.0950 - val_acc: 0.9706\n",
            "Epoch 3998/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0465 - acc: 0.9826 - val_loss: 0.0933 - val_acc: 0.9721\n",
            "Epoch 3999/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9813 - val_loss: 0.0902 - val_acc: 0.9711\n",
            "Epoch 4000/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9804 - val_loss: 0.0984 - val_acc: 0.9696\n",
            "Epoch 4001/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9821 - val_loss: 0.0890 - val_acc: 0.9687\n",
            "Epoch 4002/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9810 - val_loss: 0.0920 - val_acc: 0.9721\n",
            "Epoch 4003/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0441 - acc: 0.9823 - val_loss: 0.0909 - val_acc: 0.9711\n",
            "Epoch 4004/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9819 - val_loss: 0.0960 - val_acc: 0.9726\n",
            "Epoch 4005/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9815 - val_loss: 0.0904 - val_acc: 0.9721\n",
            "Epoch 4006/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0504 - acc: 0.9802 - val_loss: 0.1022 - val_acc: 0.9677\n",
            "Epoch 4007/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0511 - acc: 0.9789 - val_loss: 0.0962 - val_acc: 0.9657\n",
            "Epoch 4008/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0483 - acc: 0.9810 - val_loss: 0.0947 - val_acc: 0.9696\n",
            "Epoch 4009/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0465 - acc: 0.9825 - val_loss: 0.0986 - val_acc: 0.9731\n",
            "Epoch 4010/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0437 - acc: 0.9827 - val_loss: 0.0905 - val_acc: 0.9716\n",
            "Epoch 4011/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9803 - val_loss: 0.0984 - val_acc: 0.9716\n",
            "Epoch 4012/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0461 - acc: 0.9813 - val_loss: 0.0965 - val_acc: 0.9721\n",
            "Epoch 4013/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0466 - acc: 0.9811 - val_loss: 0.0917 - val_acc: 0.9691\n",
            "Epoch 4014/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0425 - acc: 0.9838 - val_loss: 0.0918 - val_acc: 0.9740\n",
            "Epoch 4015/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9815 - val_loss: 0.0888 - val_acc: 0.9716\n",
            "Epoch 4016/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9813 - val_loss: 0.0892 - val_acc: 0.9740\n",
            "Epoch 4017/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0452 - acc: 0.9824 - val_loss: 0.0904 - val_acc: 0.9731\n",
            "Epoch 4018/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9826 - val_loss: 0.0900 - val_acc: 0.9745\n",
            "Epoch 4019/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0448 - acc: 0.9818 - val_loss: 0.0924 - val_acc: 0.9736\n",
            "Epoch 4020/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0472 - acc: 0.9808 - val_loss: 0.0953 - val_acc: 0.9706\n",
            "Epoch 4021/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9812 - val_loss: 0.0907 - val_acc: 0.9701\n",
            "Epoch 4022/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9821 - val_loss: 0.1058 - val_acc: 0.9701\n",
            "Epoch 4023/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9824 - val_loss: 0.0947 - val_acc: 0.9706\n",
            "Epoch 4024/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0444 - acc: 0.9826 - val_loss: 0.1016 - val_acc: 0.9682\n",
            "Epoch 4025/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9815 - val_loss: 0.0893 - val_acc: 0.9731\n",
            "Epoch 4026/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0468 - acc: 0.9815 - val_loss: 0.0876 - val_acc: 0.9731\n",
            "Epoch 4027/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9821 - val_loss: 0.0947 - val_acc: 0.9677\n",
            "Epoch 4028/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0482 - acc: 0.9809 - val_loss: 0.0983 - val_acc: 0.9706\n",
            "Epoch 4029/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0494 - acc: 0.9797 - val_loss: 0.0961 - val_acc: 0.9711\n",
            "Epoch 4030/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0448 - acc: 0.9818 - val_loss: 0.0982 - val_acc: 0.9731\n",
            "Epoch 4031/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0479 - acc: 0.9805 - val_loss: 0.0922 - val_acc: 0.9711\n",
            "Epoch 4032/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0455 - acc: 0.9826 - val_loss: 0.0906 - val_acc: 0.9731\n",
            "Epoch 4033/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9811 - val_loss: 0.0975 - val_acc: 0.9696\n",
            "Epoch 4034/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0477 - acc: 0.9821 - val_loss: 0.0926 - val_acc: 0.9716\n",
            "Epoch 4035/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0476 - acc: 0.9819 - val_loss: 0.0951 - val_acc: 0.9687\n",
            "Epoch 4036/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0481 - acc: 0.9807 - val_loss: 0.0886 - val_acc: 0.9731\n",
            "Epoch 4037/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0463 - acc: 0.9825 - val_loss: 0.0894 - val_acc: 0.9706\n",
            "Epoch 4038/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0478 - acc: 0.9811 - val_loss: 0.1012 - val_acc: 0.9667\n",
            "Epoch 4039/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0508 - acc: 0.9801 - val_loss: 0.0997 - val_acc: 0.9696\n",
            "Epoch 4040/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0447 - acc: 0.9823 - val_loss: 0.0914 - val_acc: 0.9726\n",
            "Epoch 4041/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.1024 - val_acc: 0.9677\n",
            "Epoch 4042/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0467 - acc: 0.9817 - val_loss: 0.0927 - val_acc: 0.9706\n",
            "Epoch 4043/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0447 - acc: 0.9818 - val_loss: 0.0899 - val_acc: 0.9745\n",
            "Epoch 4044/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0446 - acc: 0.9821 - val_loss: 0.0980 - val_acc: 0.9711\n",
            "Epoch 4045/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9805 - val_loss: 0.0965 - val_acc: 0.9716\n",
            "Epoch 4046/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9822 - val_loss: 0.0874 - val_acc: 0.9736\n",
            "Epoch 4047/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0469 - acc: 0.9807 - val_loss: 0.0902 - val_acc: 0.9696\n",
            "Epoch 4048/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0442 - acc: 0.9834 - val_loss: 0.1107 - val_acc: 0.9691\n",
            "Epoch 4049/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0478 - acc: 0.9817 - val_loss: 0.0939 - val_acc: 0.9731\n",
            "Epoch 4050/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0477 - acc: 0.9807 - val_loss: 0.0949 - val_acc: 0.9711\n",
            "Epoch 4051/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0507 - acc: 0.9799 - val_loss: 0.0948 - val_acc: 0.9736\n",
            "Epoch 4052/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0493 - acc: 0.9806 - val_loss: 0.0913 - val_acc: 0.9755\n",
            "Epoch 4053/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0482 - acc: 0.9826 - val_loss: 0.0889 - val_acc: 0.9731\n",
            "Epoch 4054/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0453 - acc: 0.9825 - val_loss: 0.0946 - val_acc: 0.9711\n",
            "Epoch 4055/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0495 - acc: 0.9810 - val_loss: 0.1057 - val_acc: 0.9633\n",
            "Epoch 4056/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9802 - val_loss: 0.0964 - val_acc: 0.9677\n",
            "Epoch 4057/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0458 - acc: 0.9825 - val_loss: 0.0876 - val_acc: 0.9745\n",
            "Epoch 4058/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0489 - acc: 0.9801 - val_loss: 0.0964 - val_acc: 0.9711\n",
            "Epoch 4059/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0469 - acc: 0.9818 - val_loss: 0.0951 - val_acc: 0.9711\n",
            "Epoch 4060/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0489 - acc: 0.9809 - val_loss: 0.0886 - val_acc: 0.9721\n",
            "Epoch 4061/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9814 - val_loss: 0.0894 - val_acc: 0.9687\n",
            "Epoch 4062/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9804 - val_loss: 0.0927 - val_acc: 0.9716\n",
            "Epoch 4063/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9812 - val_loss: 0.0917 - val_acc: 0.9682\n",
            "Epoch 4064/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0483 - acc: 0.9804 - val_loss: 0.0879 - val_acc: 0.9745\n",
            "Epoch 4065/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0473 - acc: 0.9815 - val_loss: 0.1016 - val_acc: 0.9677\n",
            "Epoch 4066/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0490 - acc: 0.9805 - val_loss: 0.0877 - val_acc: 0.9745\n",
            "Epoch 4067/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0456 - acc: 0.9820 - val_loss: 0.0955 - val_acc: 0.9706\n",
            "Epoch 4068/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0461 - acc: 0.9813 - val_loss: 0.1013 - val_acc: 0.9696\n",
            "Epoch 4069/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0451 - acc: 0.9824 - val_loss: 0.0964 - val_acc: 0.9731\n",
            "Epoch 4070/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0447 - acc: 0.9823 - val_loss: 0.0874 - val_acc: 0.9736\n",
            "Epoch 4071/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0500 - acc: 0.9808 - val_loss: 0.0920 - val_acc: 0.9706\n",
            "Epoch 4072/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0434 - acc: 0.9828 - val_loss: 0.0946 - val_acc: 0.9716\n",
            "Epoch 4073/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9814 - val_loss: 0.0990 - val_acc: 0.9706\n",
            "Epoch 4074/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0472 - acc: 0.9813 - val_loss: 0.0894 - val_acc: 0.9736\n",
            "Epoch 4075/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0441 - acc: 0.9830 - val_loss: 0.0945 - val_acc: 0.9721\n",
            "Epoch 4076/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0476 - acc: 0.9806 - val_loss: 0.1018 - val_acc: 0.9701\n",
            "Epoch 4077/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0487 - acc: 0.9812 - val_loss: 0.0918 - val_acc: 0.9726\n",
            "Epoch 4078/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0452 - acc: 0.9818 - val_loss: 0.1001 - val_acc: 0.9701\n",
            "Epoch 4079/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9811 - val_loss: 0.0913 - val_acc: 0.9721\n",
            "Epoch 4080/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0479 - acc: 0.9803 - val_loss: 0.1032 - val_acc: 0.9687\n",
            "Epoch 4081/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0462 - acc: 0.9813 - val_loss: 0.0974 - val_acc: 0.9711\n",
            "Epoch 4082/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0471 - acc: 0.9811 - val_loss: 0.0945 - val_acc: 0.9711\n",
            "Epoch 4083/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9810 - val_loss: 0.0973 - val_acc: 0.9711\n",
            "Epoch 4084/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0448 - acc: 0.9830 - val_loss: 0.1062 - val_acc: 0.9687\n",
            "Epoch 4085/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0454 - acc: 0.9813 - val_loss: 0.0943 - val_acc: 0.9731\n",
            "Epoch 4086/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0474 - acc: 0.9816 - val_loss: 0.0928 - val_acc: 0.9731\n",
            "Epoch 4087/4096\n",
            "16342/16342 [==============================] - 0s 13us/step - loss: 0.0485 - acc: 0.9799 - val_loss: 0.0891 - val_acc: 0.9731\n",
            "Epoch 4088/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0501 - acc: 0.9802 - val_loss: 0.0975 - val_acc: 0.9672\n",
            "Epoch 4089/4096\n",
            "16342/16342 [==============================] - 0s 16us/step - loss: 0.0477 - acc: 0.9809 - val_loss: 0.0908 - val_acc: 0.9740\n",
            "Epoch 4090/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0495 - acc: 0.9796 - val_loss: 0.0915 - val_acc: 0.9691\n",
            "Epoch 4091/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0492 - acc: 0.9795 - val_loss: 0.0959 - val_acc: 0.9701\n",
            "Epoch 4092/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0474 - acc: 0.9802 - val_loss: 0.1003 - val_acc: 0.9687\n",
            "Epoch 4093/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0455 - acc: 0.9826 - val_loss: 0.0960 - val_acc: 0.9687\n",
            "Epoch 4094/4096\n",
            "16342/16342 [==============================] - 0s 15us/step - loss: 0.0469 - acc: 0.9807 - val_loss: 0.1014 - val_acc: 0.9696\n",
            "Epoch 4095/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0467 - acc: 0.9818 - val_loss: 0.0985 - val_acc: 0.9721\n",
            "Epoch 4096/4096\n",
            "16342/16342 [==============================] - 0s 14us/step - loss: 0.0475 - acc: 0.9805 - val_loss: 0.0919 - val_acc: 0.9726\n",
            "ffNN took 0.08613157272338867 seconds\n",
            "Test loss: 0.07980699877121619 - Accuracy: 0.9726027399593137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJqvLx_3-thY",
        "colab_type": "code",
        "outputId": "2cebb50e-d553-409b-83e7-570ea6ff1e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "source": [
        "plt.plot(data.history['acc'])\n",
        "plt.plot(data.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(data.history['loss'])\n",
        "plt.plot(data.history['val_loss'])\n",
        "plt.title('Mean Log Loss')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "labels = tf.argmax(test_labels, axis = 1)\n",
        "predictions=mlp.predict_classes(test_attributes)\n",
        "confusion_matrix = tf.confusion_matrix(labels=labels, predictions=predictions, num_classes=num_classes)\n",
        "with tf.Session() as sess:\n",
        "    print(confusion_matrix.eval())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCEREEk6BQEQk4RQIREQSToFARCTh/h/kSqVFrK9iWQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN07DEfEbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[903   8   1  10]\n",
            " [ 10 615   1   0]\n",
            " [  2   0 223   0]\n",
            " [ 16   0   6 249]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}